<documents><document index="14">
<source>.github/ISSUE_TEMPLATE/bug_report.md</source>
<document_content>
---
name: Bug Report
about: Bug – behavior that contradicts the platform's documented or intended design
labels:
  - bug
---

# Bug Report

Use this template only for issues that fit the **Bug** definition.

| Term                          | Definition |
|-------------------------------|------------|
| **Bug**                       | Behavior that contradicts the platform’s documented or intended design as per code, docs, or specs. (i.e., the implementation is incorrect.) |
| **Expectation&nbsp;mismatch** | Behavior that follows the platform’s documented or intended design but differs from what you expected. (i.e., the design/spec might be the problem.) |
| **Enhancement request**       | A request for new functionality or behavior that is not implied by existing design. (i.e., *“It would be great if the platform could…”*) |

**Note:**

- Submitting this issue automatically applies the `bug` label.
- `bug`-labeled issues are triaged with higher priority because they require corrective implementation work.
- **Expectation mismatches** and design-level concerns should be opened as [Discussions](https://github.com/nautechsystems/nautilus_trader/discussions), or RFCs instead, where they can be validated and discussed to consensus before any work is scheduled.
- The absence of a feature is typically not an expectation mismatch, and should be filed as an enhancement request.

## Confirmation

**Before opening a bug report, please confirm:**

- [ ] I’ve re-read the relevant sections of the documentation.
- [ ] I’ve searched existing issues and discussions to avoid duplicates.
- [ ] I’ve reviewed or skimmed the source code (or examples) to confirm the behavior is not by design.
- [ ] I’ve tested this issue using a recent *development* wheel (`dev` develop or `a` nightly) and can still reproduce it.

Checking a recent development wheel can save time because the issue may already have been fixed.
You can install a development wheel by running:

```bash
pip install -U nautilus_trader --pre --index-url https://packages.nautechsystems.io/simple
```

See the [development-wheels](https://github.com/nautechsystems/nautilus_trader#development-wheels) section for more details.

### Expected Behavior

Add here...

### Actual Behavior

Add here...

### Steps to Reproduce the Problem

1.
2.
3.

### Code Snippets or Logs

<!-- If applicable, provide relevant code snippets, error logs, or stack traces. Use code blocks for clarity. -->

<!-- Consider starting from our Minimal Reproducible Example template: -->
<!-- https://github.com/nautechsystems/nautilus_trader/tree/develop/examples/other/minimal_reproducible_example -->

### Specifications

- OS platform:
- Python version:
- `nautilus_trader` version:

</document_content>
</document>
<document index="16">
<source>.github/ISSUE_TEMPLATE/feature_request.md</source>
<document_content>
---
name: Feature Request
about: Request a new feature to be added here
labels:
  - enhancement
---

# Feature Request

## Problem Statement

What problem are you trying to solve? What limitations exist in the current implementation?

### Proposed Solution

Detailed description of the feature you'd like to see implemented.

### Example Usage

```python
# Show how the feature would be used
```

### Alternatives Considered

What alternatives have you explored? Why is this solution preferred?

### Additional Context

Any other relevant information or references.

</document_content>
</document>
<document index="17">
<source>.github/ISSUE_TEMPLATE/rfc.md</source>
<document_content>
---
name: RFC (Request for Comments)
about: Propose a change or idea for discussion
labels:
  - RFC
---

# RFC: [Title]

## What is an RFC?

An RFC (Request for Comments) is a proposal for significant changes or additions to the project,
such as new features, major refactorings, or process improvements. RFCs are meant for ideas that
could have a broad impact and benefit from wider community discussion.

## Before you proceed

- Please search existing issues and discussions to see if your idea has already been proposed or is under consideration.
- To maintain a focused and manageable discussion space, we kindly ask that you limit opening multiple RFCs within a short period (days or weeks). This helps ensure each proposal receives the attention it deserves and prevents overwhelming the community and maintainers.

## Context

What would you like to propose? This could be improvements, refinements, optimizations, process changes, or other significant topics.

### Considerations

What should we keep in mind? Include relevant context, such as tradeoffs (e.g., performance vs. complexity), technical feasibility, user impact, or other concerns.

</document_content>
</document>
<document index="18">
<source>.github/OVERVIEW.md</source>
<document_content>
<!--
  README for the .github directory: composite actions and workflow definitions.
-->
# GitHub Actions Overview

This directory contains reusable composite actions and workflow definitions for
CI/CD, testing, publishing, and automation within the NautilusTrader repository.

## Composite actions (`.github/actions`)

- **common-setup**: prepares the environment (OS packages, Rust toolchain, Python, sccache, pre-commit).
- **common-test-data**: caches large test data under `tests/test_data/large`.
- **common-wheel-build**: builds and installs Python wheels across Linux, macOS, and Windows for multiple Python versions.
- **publish-wheels**: publishes built wheels to Cloudflare R2, manages old wheel cleanup and index generation.
- **upload-artifact-wheel**: uploads the latest wheel artifact to GitHub Actions.

## Workflows (`.github/workflows`)

- **build.yml**: runs pre-commit, cargo-deny security checks, Rust tests, Python tests, builds wheels on multiple platforms, and uploads wheel artifacts.
- **build-docs.yml**: dispatches a repository event to trigger the documentation build on `master` and `nightly` pushes.
- **codeql-analysis.yml**: schedules and runs CodeQL security scans for Python and Rust code on pull requests to develop and periodically via cron.
- **coverage.yml**: (optional) coverage report generation for the `nightly` branch.
- **docker.yml**: builds and pushes Docker images (`nautilus_trader`, `jupyterlab`) for `master` and `nightly` branches using Buildx and QEMU.
- **nightly-merge.yml**: automatically merges `develop` into `nightly` when the latest `develop` workflows succeed.
- **performance.yml**: runs Rust/Python performance benchmarks on the `nightly` branch and reports to CodSpeed.

## Security

- **CODEOWNERS**: Critical infrastructure files (workflows, dependencies, build configs, scripts) require Core team review before merge. This prevents unauthorized supply chain modifications and ensures all sensitive changes receive security review.
- **Branch protection**: The develop branch requires PR reviews with CODEOWNERS enforcement and passing CI checks. External PRs must receive Core team approval before merge, while admin bypass is enabled for maintainer flexibility.
- **cargo-deny**: Rust dependency auditing for security advisories (RUSTSEC/GHSA), license compliance (LGPL-3.0 compatibility), banned crates, and supply chain integrity. Runs in CI to block vulnerable or non-compliant dependencies. Configuration in `deny.toml`.
- **Build attestations**: All published artifacts (wheels and source distributions) include cryptographic SLSA build provenance attestations. These prove artifacts were built by the official GitHub Actions workflow and link each artifact to a specific commit SHA, enabling users to verify authenticity via `gh attestation verify`. Attestations are generated for all releases, nightly builds, and develop builds published to PyPI, GitHub Releases, and the Nautech Systems package index.
- **Code scanning**: CodeQL is enabled for continuous security analysis of Python and Rust code. Scans run on all PRs to develop and weekly via cron schedule.
- **Immutable action pinning**: All third-party actions are pinned to specific commit SHAs to guarantee immutability and reproducibility.
- **Hardened runners**: Most workflows employ `step-security/harden-runner` with `egress-policy: audit` to reduce attack surface and monitor outbound traffic.
- **Secret management**: No secrets or credentials are stored in the repo. AWS, PyPI, and other credentials are provided via GitHub Secrets and injected at runtime.
- **Dependency pinning**: Key tools (pre-commit, Python versions, Rust toolchain, cargo-nextest) are locked to fixed versions or SHAs.
- **Least-privilege tokens**: Workflows default the `GITHUB_TOKEN` to
  `contents: read, actions: read` and selectively elevate scopes (e.g.
  `contents: write`) only for the jobs that need to tag a release or upload
  assets. This follows the principle of least privilege and limits blast
  radius if a job is compromised.
- **Caching**: Caches for sccache, pip/site-packages, pre-commit, and test data speed up workflows while preserving hermetic builds.

### Allowed network endpoints

The `step-security/harden-runner` action restricts network access to approved endpoints.
Common endpoints are maintained in the variable `COMMON_ALLOWED_ENDPOINTS`:

```
api.github.com:443                           # GitHub API
github.com:443                               # GitHub main site
artifacts.githubusercontent.com:443          # GitHub Actions artifacts
codeload.github.com:443                      # GitHub code downloads
raw.githubusercontent.com:443                # Raw file access
uploads.github.com:443                       # GitHub uploads
objects.githubusercontent.com:443            # GitHub objects storage
pipelines.actions.githubusercontent.com:443  # Actions pipelines
tokens.actions.githubusercontent.com:443     # Actions tokens
github-cloud.githubusercontent.com:443       # GitHub cloud content
github-cloud.s3.amazonaws.com:443            # GitHub S3 storage
media.githubusercontent.com:443              # GitHub media content
archive.ubuntu.com:443                       # Ubuntu package archives
security.ubuntu.com:443                      # Ubuntu security updates
azure.archive.ubuntu.com:443                 # Azure Ubuntu mirrors
astral.sh:443                                # UV/Ruff tooling
```

Job-specific endpoints (e.g., `pypi.org:443` for publishing jobs) are added inline within each workflow.

**Action Update Policy**: When updating GitHub Actions, only use versions that have been released for at least 2 weeks.
This allows time for the community to identify potential issues while maintaining security through timely updates.

For updates or changes to actions or workflows, please adhere to the repository's
CONTRIBUTING guidelines and maintain these security best practices.

</document_content>
</document>
<document index="24">
<source>.github/pull_request_template.md</source>
<document_content>
# Pull Request

**NautilusTrader prioritizes correctness and reliability, please follow existing patterns for validation and testing.**

- [ ] I have reviewed the `CONTRIBUTING.md` and followed the established practices

## Summary

<!-- Provide a brief description of *what* changed, *why* it was changed, and the impact on the system or users (2–3 sentences). -->

## Related Issues/PRs

<!-- List any related GitHub issues or PRs (e.g., `Closes #123`, `Related to #456`). -->

## Type of change

<!-- Select all that apply. -->

- [ ] Bug fix (non-breaking)
- [ ] New feature (non-breaking)
- [ ] Improvement (non-breaking)
- [ ] Breaking change (impacts existing behavior)
- [ ] Documentation update
- [ ] Maintenance / chore

## Breaking change details (if applicable)

<!-- If this is a breaking change, describe the impact and any migration steps required for users or developers. -->

## Documentation

- [ ] Documentation changes follow the style guide (`docs/developer_guide/docs.md`)

## Release notes

- [ ] I added a concise entry to `RELEASES.md` that follows the existing conventions (when applicable)

## Testing

**Ensure new or changed logic is covered by tests.**

- [ ] Affected code paths are already covered by the test suite
- [ ] I added/updated tests to cover new or changed logic

<!-- Briefly describe how the changes were tested (e.g., unit tests in `tests/unit/test_file.py`, or *additional* manual testing). -->

</document_content>
</document>
<document index="56">
<source>CLA.md</source>
<document_content>
# CONTRIBUTOR LICENSE Agreement

1. This contributor license agreement (**Agreement**) is between Nautech Systems Pty Ltd (ACN 609 589 237) (**We**, **Us**, **Our**) and the individual contributing to Our open source Software (**You**, **Your**).
2. By submitting a Contribution to Our Software, You accept and agree to be bound by this Agreement.

## Grant of Licence

3. You have agreed to provide Your Contribution to Our Software.
4. We own all rights in the Software. We grant You a non-exclusive, revocable, royalty-free, worldwide, non-sublicensable and non-transferable right and licence to access our Software for the purpose of making Your Contributions.
5. By making Contributions to Our Software, you hereby grant to Us a perpetual, worldwide, non-exclusive, royalty-free, irrevocable, transferable and sub-licensable right and licence to use, reproduce, modify, adapt, publish, translate, commercialise, create derivative works from, distribute, perform, and display the Contributions in any form, medium, or technology.
6. If You have any Moral Rights in any Contributions, you agree to waive those Moral Rights and consent to Our use or infringement of those Moral Rights. This is common for open source projects and helps to streamline software development and usage.
7. You acknowledge and agree that You are submitting Contributions voluntarily and that We are not required to provide any compensation or remuneration for Your Contributions.

## Representations and Warranties

8. You represent and warrant that:
- (i) You have all the necessary rights, power and authority to licence the Contributions to Us;
- (ii) that Our use of the Contributions will not infringe the intellectual property rights of any third party; and
- (iii) You are not aware of any actual or potential conflicts of interest by accepting this Agreement, including at law or under any other instrument binding on You.

## General

9. **Assignment**: You agree that we may assign, novate or deal with the whole or any part the rights and obligations under this Agreement without your prior written consent.
10. **No Obligation**: You acknowledge and agree that We are under no obligation to use or incorporate Your Contributions into the Software. We reserve the right to modify or remove any Contributions at Our sole discretion.
11. **Consequential Loss**: Despite anything to the contrary, to the maximum extent permitted by law, neither party will  be liable under this Agreement for any consequential loss, special or indirect loss, real or anticipated loss of profit, loss of benefit, loss of revenue, loss of business, loss of goodwill, loss of opportunity, loss of savings, loss of reputation, loss of use and/or loss or corruption of data, whether under statute, contract, equity, tort (including negligence), indemnity or otherwise.
12. **Relationship of Parties**: This Agreement is not intended to create a partnership, joint venture, employment or agency relationship between the parties.
13. **Jurisdiction**: This Agreement is governed by the laws of New South Wales. Each Party irrevocably and unconditionally submits to the exclusive jurisdiction of the courts operating in New South Wales and any courts entitled to hear appeals from those courts and waives any right to object to proceedings being brought in those courts.
14. **Dispute Resolution**: In the event of a dispute, You must contact Us and attempt to resolve the dispute in good faith. If the matter can’t be resolved, either party may refer the matter to a mediator. The costs of the mediation will be shared equally between the parties.

## Definitions

15. In this Agreement:
- (i) **Contributions** means any know-how, processes, circuit layouts, software, computer programs, databases, source codes, tools, data, documentation, feedback, information or any other work that You submit, in any form or manner, to Our Software.
- (ii) **Moral Rights** has the meaning given in the _Copyright Act 1968_ (Cth) and includes any similar rights in any jurisdiction in the world.
- (iii) **Software** means Our open source software project licensed under LGPL v3.0, available at https://github.com/nautechsystems/nautilus_trader.
16. **Last updated**: 4th October 2024.

</document_content>
</document>
<document index="57">
<source>CODE_OF_CONDUCT.md</source>
<document_content>
# Contributor Covenant Code of Conduct

## Our Pledge

We as members, contributors, and leaders pledge to make participation in our
community a harassment-free experience for everyone, regardless of age, body
size, visible or invisible disability, ethnicity, sex characteristics, gender
identity and expression, level of experience, education, socio-economic status,
nationality, personal appearance, race, religion, or sexual identity
and orientation.

We pledge to act and interact in ways that contribute to an open, welcoming,
diverse, inclusive, and healthy community.

## Our Standards

Examples of behavior that contributes to a positive environment for our
community include:

- Demonstrating empathy and kindness toward other people
- Being respectful of differing opinions, viewpoints, and experiences
- Giving and gracefully accepting constructive feedback
- Accepting responsibility and apologizing to those affected by our mistakes,
  and learning from the experience
- Focusing on what is best not just for us as individuals, but for the
  overall community

Examples of unacceptable behavior include:

- The use of sexualized language or imagery, and sexual attention or
  advances of any kind
- Trolling, insulting or derogatory comments, and personal or political attacks
- Public or private harassment
- Publishing others' private information, such as a physical or email
  address, without their explicit permission
- Other conduct which could reasonably be considered inappropriate in a
  professional setting

## Enforcement Responsibilities

Community leaders are responsible for clarifying and enforcing our standards of
acceptable behavior and will take appropriate and fair corrective action in
response to any behavior that they deem inappropriate, threatening, offensive,
or harmful.

Community leaders have the right and responsibility to remove, edit, or reject
comments, commits, code, wiki edits, issues, and other contributions that are
not aligned to this Code of Conduct, and will communicate reasons for moderation
decisions when appropriate.

## Scope

This Code of Conduct applies within all community spaces, and also applies when
an individual is officially representing the community in public spaces.
Examples of representing our community include using an official e-mail address,
posting via an official social media account, or acting as an appointed
representative at an online or offline event.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported to the community leaders responsible for enforcement at
<info@nautechsystems.io>.
All complaints will be reviewed and investigated promptly and fairly.

All community leaders are obligated to respect the privacy and security of the
reporter of any incident.

## Enforcement Guidelines

Community leaders will follow these Community Impact Guidelines in determining
the consequences for any action they deem in violation of this Code of Conduct:

### 1. Correction

**Community Impact**: Use of inappropriate language or other behavior deemed
unprofessional or unwelcome in the community.

**Consequence**: A private, written warning from community leaders, providing
clarity around the nature of the violation and an explanation of why the
behavior was inappropriate. A public apology may be requested.

### 2. Warning

**Community Impact**: A violation through a single incident or series
of actions.

**Consequence**: A warning with consequences for continued behavior. No
interaction with the people involved, including unsolicited interaction with
those enforcing the Code of Conduct, for a specified period of time. This
includes avoiding interactions in community spaces as well as external channels
like social media. Violating these terms may lead to a temporary or
permanent ban.

### 3. Temporary Ban

**Community Impact**: A serious violation of community standards, including
sustained inappropriate behavior.

**Consequence**: A temporary ban from any sort of interaction or public
communication with the community for a specified period of time. No public or
private interaction with the people involved, including unsolicited interaction
with those enforcing the Code of Conduct, is allowed during this period.
Violating these terms may lead to a permanent ban.

### 4. Permanent Ban

**Community Impact**: Demonstrating a pattern of violation of community
standards, including sustained inappropriate behavior,  harassment of an
individual, or aggression toward or disparagement of classes of individuals.

**Consequence**: A permanent ban from any sort of public interaction within
the community.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage],
version 2.0, available at
<https://www.contributor-covenant.org/version/2/0/code_of_conduct.html>.

Community Impact Guidelines were inspired by [Mozilla's code of conduct
enforcement ladder](https://github.com/mozilla/diversity).

[homepage]: https://www.contributor-covenant.org

For answers to common questions about this code of conduct, see the FAQ at
<https://www.contributor-covenant.org/faq>. Translations are available at
<https://www.contributor-covenant.org/translations>.

</document_content>
</document>
<document index="58">
<source>CONTRIBUTING.md</source>
<document_content>
# Contributing to NautilusTrader

We highly value involvement from the trading community, and all contributions are greatly appreciated as they help us continually improve NautilusTrader!

> [!NOTE]
>
> **Integrations:**
> New integrations are a major undertaking for the project and therefore require additional discussion and approval before opening any PRs.
> Please see the [ROADMAP: Community-contributed integrations](ROADMAP.md#community-contributed-integrations) for details on the process.

## Steps

To contribute, follow these steps:

1. Open an issue on GitHub to discuss your proposed changes or enhancements.

2. Once everyone is aligned, fork the `develop` branch and ensure your fork is up-to-date by regularly merging any upstream changes.

3. Install and configure [pre-commit](https://pre-commit.com/) on your local machine to automatically run code checks, formatters, and linters before each commit.
   You can install pre-commit with:
    ```bash
    pip install pre-commit
    pre-commit install
    ```

4. Open a pull request (PR) on the `develop` branch with a summary comment and reference to any relevant GitHub issue(s).

5. The CI system will run the full test suite on your code including all unit and integration tests, so include appropriate tests with the PR.

6. Read and understand the Contributor License Agreement (CLA), available at https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md.

7. You will also be required to sign the CLA, which is administered automatically through [CLA Assistant](https://cla-assistant.io/).

8. We will review your code as quickly as possible and provide feedback if any changes are needed before merging.

## Tips

- Follow the established coding practices in the [Developer Guide](https://nautilustrader.io/docs/developer_guide/index.html).
- For documentation changes, follow the style guide in `docs/developer_guide/docs.md` (use sentence case for headings H2 and below).
- Keep PRs small and focused for easier review.
- Reference the relevant GitHub issue(s) in your PR comment.

</document_content>
</document>
<document index="62">
<source>ROADMAP.md</source>
<document_content>
# Roadmap

This document outlines the key priorities and upcoming goals for **NautilusTrader**,
charting its path as a cutting-edge platform for high-performance algorithmic trading.

Given the dynamic nature of the project, priorities may evolve to keep pace with the fast-moving development cycle.
For real-time updates and detailed task tracking, refer to the [NautilusTrader Kanban board](https://github.com/orgs/nautechsystems/projects/3).

**Note**: Bug fixes and roadmap priorities take precedence over feature requests to ensure stability
and progress. However, pull requests (PRs) for improvements and new features are always welcome.
For more details, see the [CONTRIBUTING.md](/CONTRIBUTING.md).

## Vision

To establish NautilusTrader as the standard platform for quantitative algorithmic trading, combining
performance, reliability, usability, and comprehensive documentation for traders and developers alike.

## Priorities

1. **Port core to Rust**

   **Goal**: Leverage Rust's performance and safety features to improve reliability, performance, and scalability.
   - Rewrite performance-critical components in Rust (replacing existing Cython modules).
   - Ensure interoperability between Rust and Python layers using PyO3.
   - Benchmark performance improvements throughout the transition.

2. **Improve documentation and tutorials**

    **Goal**: Lower the learning curve for new users and empower developers with clear, comprehensive guides:
   - Fill gaps in user and developer documentation by adding missing sections.
   - Add additional tutorials and examples.

3. **Improve code ergonomics**

    **Goal**: Simplify the development experience for users and contributors:
   - Enhance type annotations and support for Python import resolution.
   - Standardize naming conventions and refine APIs for greater intuitiveness.
   - Streamline configuration and setup processes to minimize friction.
   - Refactor modules and namespaces to improve readability and maintainability.

## Additional enhancements

As we progress on the top priorities, we also plan to focus on the following enhancements:

- Expand integrations with adapters to support trading venues and data providers.
- Enhance the backtesting engine with additional features.
- Enhance order book execution dynamics with additional features, including user order interactions, persistent book changes, and expanded microstructure simulations.
- Backtest visualization for local single-node workflows, including plots and tear sheets (not full UI dashboards).

## Open-source scope

The NautilusTrader open-source project is purpose-built to empower individual and
small team quantitative traders, enabling strategy research and live trading with efficiency and
reliability on a single node. By explicitly defining what is *in* and *out* of scope,
we set clear expectations, focus community efforts, and support a sustainable open-source ecosystem.

### In scope

- High-performance single-node backtesting that accurately simulates live trading conditions.
- Live trading on single-node infrastructure for streamlined research-to-production workflows.
- [Community-contributed integrations](#community-contributed-integrations) for additional trading venues and data providers.

### Out of scope

- UI dashboards or frontends: focus remains strictly on the core trading engine. Frontend contributions would divert attention from the engine and add unsustainable maintenance burdens.
- Distributed or massively parallel backtesting orchestration: externally orchestrated workflows are technically compatible, but a built-in distributed runner is beyond the project’s current scope.
- Integrated hyper-parameter optimization or built-in AI/ML tooling: users should integrate their own optimization frameworks tailored to their needs.
- Additional external integrations (e.g. cloud services, databases, and monitoring tools): these are not in scope unless explicitly listed.

## Community-contributed integrations

New integrations are a major undertaking for the project. They involve more than just the initial code — documentation, tutorials, maintenance, and ongoing user support are all required to make them viable and sustainable.
Since contributors are not obligated to complete or maintain an integration, we must carefully weigh the long-term impact and commitment before accepting one into the main project.

At present, the project has limited bandwidth to support new official integrations.

To set clearer expectations:

**Step 1 – Open an RFC**

Before opening a PR for a new integration, contributors should first open a Request for Comments (RFC) issue.
This allows discussion of suitability, alignment with the roadmap, and maintenance considerations before any code is written.

**Step 2 – Evaluation**

The maintainers will review the RFC in light of factors such as stability, demand, technical fit, and available bandwidth.
Integrations must also align with NautilusTrader’s professional, performance-focused, and high-reliability philosophy.
Only after agreement at this stage should a PR be considered.

**Step 3 – PR submission (if approved)**

If the RFC is approved, a contributor may proceed with a PR.
Integrations must adhere closely to existing Rust-based adapter implementation patterns to ensure consistency and maintainability.
Even then, inclusion in the official distribution depends on long-term sustainability and available resources.

## Long-term commitment

NautilusTrader is an open-core project. All core trading engine
features land in the public repository first, and we are committed to
continually widening the feature set and improving documentation so that the
community can rely on a modern, high-performance, battle-tested platform.

Feedback and contributions from users directly influence the roadmap; as
real-world requirements evolve, we will steadily raise the ceiling of what can
be achieved with the open-source codebase.

## NautilusTrader v2.0 and beyond

- **Achieving Stable Status**: While NautilusTrader is already successfully used in production, v2.0 represents a significant milestone toward establishing a stable API.
- **Focus Areas**: The v2.0 initiative will prioritize API consistency, long-term maintainability, and meeting the rigorous standards of live trading environments.
- **Formal Deprecations**: v2.0 will introduce formal deprecations, making it easier to adopt changes and new features while maintaining clarity for developers.
- **Python API Commitment**: Despite transitioning the core to Rust, NautilusTrader will continue to provide a user-facing Python API.

## Charting the future

This roadmap builds on NautilusTrader’s strong foundation, driving continuous refinement while
expanding its possibilities and capabilities for algorithmic traders and developers.

</document_content>
</document>
<document index="63">
<source>SECURITY.md</source>
<document_content>
# Security Policy

At NautilusTrader, we take security seriously and appreciate your efforts in
helping us identify and fix any vulnerabilities. If you have discovered a
security vulnerability, follow the guidelines outlined below.

## Reporting a Vulnerability

**Preferred method:** [GitHub Security Advisories](https://github.com/nautechsystems/nautilus_trader/security/advisories/new)

This allows private disclosure and coordination before public release. You'll
receive credit in the security advisory and release notes.

**Alternative:** Email <info@nautechsystems.io>

For sensitive reports via email, you may request our PGP key for encrypted communication.

## Response Timeline

We commit to:

- **Initial response**: Within 48 hours of report submission
- **Status update**: Within 7 days with initial assessment
- **Fix timeline**: Critical vulnerabilities patched within 30 days; other issues within 90 days
- **Coordinated disclosure**: We'll work with you to agree on a public disclosure date

## Responsible Disclosure

We encourage responsible disclosure of any security vulnerabilities you may
discover. Please provide us with a reasonable amount of time to fix the issue
before disclosing it publicly. We will acknowledge your contribution in our
security advisories and release notes unless you prefer to remain anonymous.

## Supported Versions

We only support the latest version of NautilusTrader. If you are using an older
version, it is possible that vulnerabilities may have been fixed in a later
release.

## Bug Bounty Program

At this time, we do not have a formal bug bounty program. We
appreciate any efforts to help us improve the security of our platform and will
do our best to properly recognize and credit your contributions.

## Security Infrastructure

NautilusTrader employs multiple layers of security to protect against supply
chain attacks and vulnerabilities:

- **Dependency auditing**: Automated security scanning via cargo-deny (Rust) and Dependabot alerts (Python)
- **Code scanning**: CodeQL static analysis for Python and Rust code
- **CODEOWNERS**: Critical infrastructure files require Core team review before merge
- **Branch protection**: Develop branch requires PR reviews and passing CI checks
- **Immutable action pinning**: GitHub Actions pinned to commit SHAs for reproducibility
- **Hardened runners**: Network egress monitoring and least-privilege tokens
- **License compliance**: Automated checks ensuring LGPL-3.0 compatibility

For detailed security practices, see [.github/OVERVIEW.md](.github/OVERVIEW.md#security).

</document_content>
</document>
<document index="68">
<source>crates/adapters/bitmex/README.md</source>
<document_content>
# nautilus-bitmex

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-bitmex)](https://docs.rs/nautilus-bitmex/latest/nautilus-bitmex/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-bitmex.svg)](https://crates.io/crates/nautilus-bitmex)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/NautilusTrader)

[NautilusTrader](http://nautilustrader.io) adapter for the [BitMEX](https://bitmex.com) cryptocurrency exchange.

The `nautilus-bitmex` crate provides client bindings (HTTP & WebSocket), data
models and helper utilities that wrap the official **BitMEX API**.

The official BitMEX API reference can be found at <https://www.bitmex.com/app/apiOverview>.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation:

- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).
- `extension-module`: Builds as a Python extension module (used with `python`).

## Documentation

See [the docs](https://docs.rs/nautilus-bitmex) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="120">
<source>crates/adapters/blockchain/README.md</source>
<document_content>
# nautilus-blockchain

A high-performance, universal, extensible adapter for ingesting DeFi data from decentralized exchanges (DEXs),
liquidity pools, and on-chain events. It enables you to power analytics pipelines and trading strategies with real-time and historical on-chain data.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation:

- `hypersync`: Enables the [HyperSync](https://envio.dev/#hypersync) client integration.
- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).
- `extension-module`: Builds as a Python extension module (used with `python`).
- `turmoil`: Enables deterministic network simulation testing with [turmoil](https://github.com/tokio-rs/turmoil).

## Scripts

You can run some example scripts and provide target RPC environment variables. These examples demonstrate how to connect to blockchain nodes and subscribe to various events.

You can configure the required environment variables in two ways:

1. **Using a `.env` file in the project root:**
   Create a file named `.env` in the project root directory with the following content:

   ```
   CHAIN=Ethereum
   RPC_WSS_URL=wss://mainnet.infura.io/ws/v3/YOUR_INFURA_API_KEY
   RPC_HTTP_URL=https://mainnet.infura.io/v3/YOUR_INFURA_API_KEY
   ```

2. **Providing variables directly in the command line:**

   ```
   CHAIN=Ethereum RPC_WSS_URL=wss://your-node-endpoint cargo run --bin live_blocks_rpc
   ```

### Watch live blocks

The scripts will connect to the specified blockchain and log information about each new block received for both the RPC version and only Hypersync.

```
cargo run --bin live_blocks_rpc --features hypersync
```

```
cargo run --bin live_blocks_hypersync --features hypersync
```

For RPC example, the output should be:

```
Running `target/debug/live_blocks_rpc`
2025-04-25T14:54:41.394620000Z [INFO] TRADER-001.nautilus_blockchain::rpc::core: Subscribing to new blocks on chain Ethereum
2025-04-25T14:54:48.951608000Z [INFO] TRADER-001.nautilus_blockchain::data: Block(chain=Ethereum, number=22346765, timestamp=2025-04-25T14:54:47+00:00, hash=0x18a3c9f1e3eec06b45edc1f632565e5c23089dc4ad0892b00fda9e4ffcc9bf91)
2025-04-25T14:55:00.646992000Z [INFO] TRADER-001.nautilus_blockchain::data: Block(chain=Ethereum, number=22346766, timestamp=2025-04-25T14:54:59+00:00, hash=0x110436e41463daeacd1501fe53d38c310573abc136672a12054e1f33797ffeb9)
2025-04-25T14:55:14.369337000Z [INFO] TRADER-001.nautilus_blockchain::data: Block(chain=Ethereum, number=22346767, timestamp=2025-04-25T14:55:11+00:00, hash=0x54e7dbcfc14c058e22c70cbacabe4872e84bd6d3b976258f0d364ae99226b314)
2025-04-25T14:55:38.314022000Z [INFO] TRADER-001.live_blocks: Shutdown signal received, shutting down...

```

### Sync dex, tokens and pool for Uniswap V3 on Ethereum

This script demonstrates how to use the blockchain data client to discover and cache Uniswap V3 pools and their associated tokens. It queries the Ethereum blockchain for pool creation events emitted by the Uniswap V3 factory contract, retrieves token metadata (name, symbol, decimals) for each token in the pools via smart contract calls, and stores everything in a local Postgres database.

```
cargo run --bin sync_tokens_pools --features hypersync
```

## Testing

The crate includes both standard integration tests and deterministic network simulation tests using turmoil.

To run standard tests:

```bash
cargo nextest run -p nautilus-blockchain
```

To run turmoil network simulation tests:

```bash
cargo nextest run -p nautilus-blockchain --features turmoil
```

The turmoil tests simulate various network conditions (reconnections, partitions, etc.) in a deterministic way, allowing reliable testing of network failure scenarios without flakiness.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="212">
<source>crates/adapters/bybit/README.md</source>
<document_content>
# nautilus-bybit

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-bybit)](https://docs.rs/nautilus-bybit/latest/nautilus-bybit/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-bybit.svg)](https://crates.io/crates/nautilus-bybit)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/NautilusTrader)

[NautilusTrader](http://nautilustrader.io) adapter for the [Bybit](https://www.bybit.com/) exchange.

The `nautilus-bybit` crate provides client bindings (HTTP & WebSocket), data models,
and helper utilities that wrap the official **Bybit API**.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation:

- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).
- `extension-module`: Builds as a Python extension module (used with `python`).

## Documentation

See [the docs](https://docs.rs/nautilus-bybit) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="280">
<source>crates/adapters/coinbase_intx/README.md</source>
<document_content>
# nautilus-coinbase-intx

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-coinbase-intx)](https://docs.rs/nautilus-coinbase-intx/latest/nautilus-coinbase-intx/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-coinbase-intx.svg)](https://crates.io/crates/nautilus-coinbase-intx)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/NautilusTrader)

[NautilusTrader](http://nautilustrader.io) adapter for [Coinbase International](https://www.coinbase.com/en/international-exchange) exchange.

The `nautilus-coinbase-intx` crate provides integration with the Coinbase International API for
institutional trading on their derivatives exchange.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation:

- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).
- `extension-module`: Builds as a Python extension module (used with `python`).

## Documentation

See [the docs](https://docs.rs/nautilus-coinbase-intx) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="331">
<source>crates/adapters/databento/README.md</source>
<document_content>
# nautilus-databento

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-databento)](https://docs.rs/nautilus-databento/latest/nautilus-databento/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-databento.svg)](https://crates.io/crates/nautilus-databento)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/NautilusTrader)

[NautilusTrader](http://nautilustrader.io) adapter for [Databento](https://databento.com).

The `nautilus-databento` crate provides a complete integration with the Databento API for
accessing institutional-grade market data feeds across multiple venues and asset classes.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation:

- `live` (default): Enables live data functionality including the `data`, `factories`, and `live` modules.
- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).
- `extension-module`: Builds as a Python extension module (used with `python`).
- `high-precision`: Enables [high-precision mode](https://nautilustrader.io/docs/nightly/getting_started/installation#precision-mode) to use 128-bit value types.

## Documentation

See [the docs](https://docs.rs/nautilus-databento) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="392">
<source>crates/adapters/hyperliquid/README.md</source>
<document_content>
# nautilus-hyperliquid

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-hyperliquid)](https://docs.rs/nautilus-hyperliquid/latest/nautilus-hyperliquid/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-hyperliquid.svg)](https://crates.io/crates/nautilus-hyperliquid)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/NautilusTrader)

[NautilusTrader](http://nautilustrader.io) adapter for the [Hyperliquid](https://hyperliquid.gitbook.io/hyperliquid-docs) decentralized exchange.

The `nautilus-hyperliquid` crate provides client bindings (HTTP & WebSocket), data
models and helper utilities that wrap the official **Hyperliquid API**.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation:

- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).
- `extension-module`: Builds as a Python extension module (used with `python`).

## Documentation

See [the docs](https://docs.rs/nautilus-hyperliquid) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="427">
<source>crates/adapters/hyperliquid/test_data/README.md</source>
<document_content>
# Hyperliquid Test Data

This directory contains real API response samples for testing.

## Files

### HTTP Public Data (No Account Required)

- `http_meta_perp_sample.json` - Perpetuals market metadata (sample of 3 markets)
- `http_meta_spot_sample.json` - Spot market metadata (sample of 3 markets)
- `http_l2_book_btc.json` - BTC order book snapshot (5 levels each side)
- `http_l2_book_snapshot.json` - Existing order book test data

### WebSocket Public Data (No Account Required)

- `ws_trades_sample.json` - Real-time trade message sample
- `ws_l2_book_sample.json` - Order book update message sample
- `ws_book_data.json` - Existing book data test sample

## Capturing New Test Data

### HTTP Data

```bash
cargo run --bin capture-test-data
```

### WebSocket Data

```bash
cargo run --bin capture-ws-test-data
```

## Usage in Tests

```rust
fn load_test_data<T>(filename: &str) -> T
where
    T: serde::de::DeserializeOwned,
{
    let path = format!("test_data/{}", filename);
    let content = std::fs::read_to_string(path).expect("Failed to read test data");
    serde_json::from_str(&content).expect("Failed to parse test data")
}

#[rstest]
fn test_parse_perpetuals_metadata() {
    let meta: PerpMetadata = load_test_data("http_meta_perp_sample.json");
    // assertions...
}
```

## Data Size Policy

- Keep files small (< 50KB each)
- Sample only 3-5 items from large arrays
- Use real mainnet data when possible
- Update files when API response format changes

</document_content>
</document>
<document index="433">
<source>crates/adapters/kraken/README.md</source>
<document_content>
# nautilus-kraken

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-kraken)](https://docs.rs/nautilus-kraken/latest/nautilus-kraken/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-kraken.svg)](https://crates.io/crates/nautilus-kraken)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/NautilusTrader)

[NautilusTrader](http://nautilustrader.io) adapter for the [Kraken](https://www.kraken.com/) exchange.

The `nautilus-kraken` crate provides client bindings (HTTP & WebSocket), data models,
and helper utilities that wrap the official **Kraken API v2**.

The official Kraken API reference can be found at <https://docs.kraken.com/api/>.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Features

- HTTP REST API v2 client for market data.
- WebSocket v2 client for real-time data feeds.
- Support for both Spot and Futures markets.
- Instrument, ticker, trade, orderbook, and OHLC data.
- Prepared for execution support (orders, positions, balances) - WIP.

## Examples

See the `bin/` directory for example usage:

```bash
cargo run --bin kraken-http-raw
cargo run --bin kraken-http-public
cargo run --bin kraken-ws-data
```

## Feature flags

This crate provides feature flags to control source code inclusion during compilation:

- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).
- `extension-module`: Builds as a Python extension module (used with `python`).

## Documentation

See [the docs](https://docs.rs/nautilus-kraken) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="483">
<source>crates/adapters/okx/README.md</source>
<document_content>
# nautilus-okx

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-okx)](https://docs.rs/nautilus-okx/latest/nautilus-okx/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-okx.svg)](https://crates.io/crates/nautilus-okx)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/NautilusTrader)

The `nautilus-okx` crate provides client bindings (HTTP & WebSocket), data
models and helper utilities that wrap the official **OKX v5 API**.

The official OKX API reference can be found at <https://www.okx.com/docs-v5/en/>.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation:

- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).
- `extension-module`: Builds as a Python extension module (used with `python`).

## Documentation

See [the docs](https://docs.rs/nautilus-okx) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="556">
<source>crates/adapters/tardis/README.md</source>
<document_content>
# nautilus-tardis

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-tardis)](https://docs.rs/nautilus-tardis/latest/nautilus-tardis/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-tardis.svg)](https://crates.io/crates/nautilus-tardis)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/NautilusTrader)

[NautilusTrader](http://nautilustrader.io) adapter for [Tardis](https://tardis.dev).

The `nautilus-tardis` crate provides integration with the Tardis API for accessing
normalized historical and real-time market data across multiple exchanges.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation,
depending on the intended use case:

- `replay`: Enables market data replay functionality (enabled by default).
- `extension-module`: Builds the crate as a Python extension module.
- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).

## Documentation

See [the docs](https://docs.rs/nautilus-tardis) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="604">
<source>crates/analysis/README.md</source>
<document_content>
# nautilus-analysis

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-analysis)](https://docs.rs/nautilus-analysis/latest/nautilus-analysis/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-analysis.svg)](https://crates.io/crates/nautilus-analysis)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)

Portfolio analysis and performance metrics for [NautilusTrader](http://nautilustrader.io).

The `nautilus-analysis` crate provides a comprehensive suite of portfolio analysis tools and performance
statistics for evaluating trading strategies and portfolios. This includes return-based metrics,
PnL-based statistics, and risk measurements commonly used in quantitative finance:

- Portfolio analyzer for tracking account states and positions.
- Extensive collection of performance statistics and risk metrics.
- Flexible statistic calculation framework supporting different data sources.
- Support for multi-currency portfolios and unrealized PnL calculations.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation,
depending on the intended use case, i.e. whether to provide Python bindings
for the [nautilus_trader](https://pypi.org/project/nautilus_trader) Python package,
or as part of a Rust only build.

- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).
- `extension-module`: Builds as a Python extension module (used with `python`).

## Documentation

See [the docs](https://docs.rs/nautilus-analysis) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="653">
<source>crates/backtest/README.md</source>
<document_content>
# nautilus-backtest

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-backtest)](https://docs.rs/nautilus-backtest/latest/nautilus-backtest/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-backtest.svg)](https://crates.io/crates/nautilus-backtest)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/NautilusTrader)

Backtest engine for [NautilusTrader](http://nautilustrader.io).

The `nautilus-backtest` crate provides a comprehensive event-driven backtesting framework that allows
quantitative traders to test and validate trading strategies on historical data with high
fidelity market simulation. The system replicates real market conditions including:

- Event-driven backtesting engine with simulated exchanges.
- Market data replay with configurable latency and fill models.
- Order matching engines with realistic execution simulation.
- Multi-venue and multi-asset backtesting capabilities.
- Comprehensive configuration and state management.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation,
depending on the intended use case, i.e. whether to provide Python bindings
for the [nautilus_trader](https://pypi.org/project/nautilus_trader) Python package,
or as part of a Rust only build.

- `ffi`: Enables the C foreign function interface (FFI) from [cbindgen](https://github.com/mozilla/cbindgen).
- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).
- `extension-module`: Builds as a Python extension module (used with `python`).

## Documentation

See [the docs](https://docs.rs/nautilus-backtest) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="668">
<source>crates/cli/README.md</source>
<document_content>
# nautilus-cli

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-cli)](https://docs.rs/nautilus-cli/latest/nautilus-cli/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-cli.svg)](https://crates.io/crates/nautilus-cli)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/NautilusTrader)

Command-line interface and tools for [NautilusTrader](http://nautilustrader.io).

The `nautilus-cli` crate provides a comprehensive command-line interface for managing and
operating NautilusTrader installations. It includes tools for database management,
system configuration, and operational utilities:

- Database initialization and management commands.
- PostgreSQL schema setup and maintenance.
- Configuration validation and setup utilities.
- System administration and operational tools.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation,
depending on the intended use case:

- `defi`: Enables blockchain/DeFi commands including block sync, DEX pool sync, and pool analysis.

## Documentation

See [the docs](https://docs.rs/nautilus-cli) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="678">
<source>crates/common/README.md</source>
<document_content>
# nautilus-common

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-common)](https://docs.rs/nautilus-common/latest/nautilus-common/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-common.svg)](https://crates.io/crates/nautilus-common)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/NautilusTrader)

Common componentry for [NautilusTrader](http://nautilustrader.io).

The `nautilus-common` crate provides shared components and utilities that form the system foundation for
NautilusTrader applications. This includes the actor system, message bus, caching layer, and other
essential services.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation,
depending on the intended use case, i.e. whether to provide Python bindings
for the [nautilus_trader](https://pypi.org/project/nautilus_trader) Python package,
or as part of a Rust only build.

- `ffi`: Enables the C foreign function interface (FFI) from [cbindgen](https://github.com/mozilla/cbindgen).
- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).
- `defi`: Enables DeFi (Decentralized Finance) support.

## Documentation

See [the docs](https://docs.rs/nautilus-common) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="685">
<source>crates/common/examples/greeks.md</source>
<document_content>
# Greeks Calculator Integration with Actor System

This document explains how to use the `GreeksCalculator` with the Nautilus actor system.

## Overview

The `GreeksCalculator` is a utility for calculating option and futures greeks (sensitivities of price moves with respect to market data moves). It has been integrated with the actor system to allow for easy use within actors, including strategies.

## Key Components

1. **Clock**: The `GreeksCalculator` uses the same `Clock` instance as the actor system.
2. **Message Bus**: The `GreeksCalculator` uses the messaging switchboard for publishing and subscribing to messages.

## Using GreeksCalculator in an Actor

### Basic Setup

```rust
use std::cell::RefCell;
use std::rc::Rc;
use std::sync::Arc;

use nautilus_common::{
    actor::{
        data_actor::{DataActor, DataActorConfig, DataActorCore},
        Actor,
    },
    cache::Cache,
    clock::LiveClock,
    greeks::GreeksCalculator,
    msgbus::MessagingSwitchboard,
};

struct MyActor {
    core: DataActorCore,
    greeks_calculator: GreeksCalculator,
}

impl MyActor {
    pub fn new(
        config: DataActorConfig,
        cache: Rc<RefCell<Cache>>,
        clock: Rc<RefCell<LiveClock>>,
        switchboard: Arc<MessagingSwitchboard>,
    ) -> Self {
        let core = DataActorCore::new(config, cache.clone(), clock.clone(), switchboard.clone());

        // Create the GreeksCalculator with the same clock and cache
        let greeks_calculator = GreeksCalculator::new(
            cache,
            clock,
        );

        Self {
            core,
            greeks_calculator,
        }
    }
}
```

### Calculating Greeks

```rust
use nautilus_model::{
    data::greeks::GreeksData,
    identifiers::InstrumentId,
};

impl MyActor {
    pub fn calculate_greeks(&self, instrument_id: InstrumentId) -> anyhow::Result<GreeksData> {
        // Example parameters
        let flat_interest_rate = 0.0425;
        let flat_dividend_yield = None;
        let spot_shock = 0.0;
        let vol_shock = 0.0;
        let time_to_expiry_shock = 0.0;
        let use_cached_greeks = false;
        let cache_greeks = true;
        let publish_greeks = true;
        let ts_event = self.core.clock.borrow().timestamp_ns();
        let position = None;
        let percent_greeks = false;
        let index_instrument_id = None;
        let beta_weights = None;

        // Calculate greeks
        self.greeks_calculator.instrument_greeks(
            instrument_id,
            Some(flat_interest_rate),
            flat_dividend_yield,
            Some(spot_shock),
            Some(vol_shock),
            Some(time_to_expiry_shock),
            Some(use_cached_greeks),
            Some(cache_greeks),
            Some(publish_greeks),
            Some(ts_event),
            position,
            Some(percent_greeks),
            index_instrument_id,
            beta_weights,
        )
    }
}
```

### Subscribing to Greeks Data

```rust
impl MyActor {
    pub fn subscribe_to_greeks(&self, underlying: &str) {
        // Subscribe to greeks data
        self.greeks_calculator.subscribe_greeks(underlying, None);
    }
}

impl DataActor for MyActor {
    fn on_start(&mut self) -> anyhow::Result<()> {
        // Subscribe to greeks data for SPY
        self.subscribe_to_greeks("SPY");
        Ok(())
    }

    fn on_data(&mut self, data: &dyn std::any::Any) -> anyhow::Result<()> {
        // Handle received data
        if let Some(greeks_data) = data.downcast_ref::<GreeksData>() {
            println!("Received greeks data: {:?}", greeks_data);
        }
        Ok(())
    }
}
```

## Full Example

See the complete example in `crates/common/examples/greeks_actor_example.rs` for a working implementation.

## Key Features

1. **Integration with Actor System**: The `GreeksCalculator` uses the same clock and message bus as the actor system.
2. **Message Bus Integration**: Greeks data can be published and subscribed to via the message bus.
3. **Caching**: Greeks calculations can be cached for performance.
4. **Portfolio Greeks**: Calculate greeks for an entire portfolio of positions.

## Notes

- When setting `publish_greeks` to `true`, the calculator will publish the greeks data to the message bus with a topic format of `data.GreeksData.instrument_id={symbol}`.
- When subscribing to greeks data, you can provide a custom handler or use the default handler which caches the received greeks data.

</document_content>
</document>
<document index="767">
<source>crates/core/README.md</source>
<document_content>
# nautilus-core

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-core)](https://docs.rs/nautilus-core/latest/nautilus-core/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-core.svg)](https://crates.io/crates/nautilus-core)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/NautilusTrader)

Core foundational types and utilities for [NautilusTrader](http://nautilustrader.io).

The `nautilus-core` crate is designed to be lightweight, efficient, and to provide zero-cost abstractions
wherever possible. It supplies the essential building blocks used across the NautilusTrader
ecosystem, including:

- Time handling and atomic clock functionality.
- UUID generation and management.
- Mathematical functions and interpolation utilities.
- Correctness validation functions.
- Serialization traits and helpers.
- Cross-platform environment utilities.
- Abstractions over common collections.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation,
depending on the intended use case, i.e. whether to provide Python bindings
for the [nautilus_trader](https://pypi.org/project/nautilus_trader) Python package,
or as part of a Rust only build.

- `ffi`: Enables the C foreign function interface (FFI) from [cbindgen](https://github.com/mozilla/cbindgen).
- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).
- `extension-module`: Builds the crate as a Python extension module.

## Documentation

See [the docs](https://docs.rs/nautilus-core) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="806">
<source>crates/cryptography/README.md</source>
<document_content>
# nautilus-cryptography

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-cryptography)](https://docs.rs/nautilus-cryptography/latest/nautilus-cryptography/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-cryptography.svg)](https://crates.io/crates/nautilus-cryptography)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/NautilusTrader)

Cryptographic utilities and security functions for [NautilusTrader](http://nautilustrader.io).

The `nautilus-cryptography` crate provides essential cryptographic primitives and security utilities
required for secure communication with trading venues and data providers. This includes
digital signing, TLS configuration, and cryptographic provider management:

- HMAC-based message authentication and signing.
- Digital signatures using RSA and Ed25519 algorithms.
- TLS client configuration with platform certificate verification.
- Cryptographic provider management and initialization.
- Secure encoding and decoding utilities.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation,
depending on the intended use case, i.e. whether to provide Python bindings
for the [nautilus_trader](https://pypi.org/project/nautilus_trader) Python package,
or as part of a Rust only build.

- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).

## Documentation

See [the docs](https://docs.rs/nautilus-cryptography) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="814">
<source>crates/data/README.md</source>
<document_content>
# nautilus-data

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-data)](https://docs.rs/nautilus-data/latest/nautilus-data/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-data.svg)](https://crates.io/crates/nautilus-data)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/NautilusTrader)

Data engine and market data processing for [NautilusTrader](http://nautilustrader.io).

The `nautilus-data` crate provides a comprehensive framework for handling market data ingestion,
processing, and aggregation within the NautilusTrader ecosystem. This includes real-time
data streaming, historical data management, and various aggregation methodologies:

- High-performance data engine for orchestrating data operations.
- Data client infrastructure for connecting to market data providers.
- Bar aggregation machinery supporting tick, volume, value, and time-based aggregation.
- Order book management and delta processing capabilities.
- Subscription management and data request handling.
- Configurable data routing and processing pipelines.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation,
depending on the intended use case, i.e. whether to provide Python bindings
for the [nautilus_trader](https://pypi.org/project/nautilus_trader) Python package,
or as part of a Rust only build.

- `ffi`: Enables the C foreign function interface (FFI) from [cbindgen](https://github.com/mozilla/cbindgen).
- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).
- `high-precision`: Enables [high-precision mode](https://nautilustrader.io/docs/nightly/getting_started/installation#precision-mode) to use 128-bit value types.
- `defi`: Enables DeFi (Decentralized Finance) support.
- `extension-module`: Builds as a Python extension module (used with `python`).

## Documentation

See [the docs](https://docs.rs/nautilus-data) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="825">
<source>crates/execution/README.md</source>
<document_content>
# nautilus-execution

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-execution)](https://docs.rs/nautilus-execution/latest/nautilus-execution/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-execution.svg)](https://crates.io/crates/nautilus-execution)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/NautilusTrader)

Order execution engine for [NautilusTrader](http://nautilustrader.io).

The `nautilus-execution` crate provides a comprehensive order execution system that handles the complete
order lifecycle from submission to fill processing. This includes sophisticated order matching,
execution venue integration, and advanced order type emulation:

- **Execution engine**: Central orchestration of order routing and position management.
- **Order matching engine**: High-fidelity market simulation for backtesting and paper trading.
- **Order emulator**: Advanced order types not natively supported by venues (trailing stops, contingent orders).
- **Execution clients**: Abstract interfaces for connecting to trading venues and brokers.
- **Order manager**: Local order lifecycle management and state tracking.
- **Matching core**: Low-level order book and price-time priority matching algorithms.
- **Fee and fill models**: Configurable execution cost simulation and realistic fill behavior.

The crate supports both live trading environments (with real execution clients) and simulated
environments (with matching engines), making it suitable for production trading, strategy
development, and comprehensive backtesting.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation,
depending on the intended use case, i.e. whether to provide Python bindings
for the [nautilus_trader](https://pypi.org/project/nautilus_trader) Python package,
or as part of a Rust only build.

- `ffi`: Enables the C foreign function interface (FFI) from [cbindgen](https://github.com/mozilla/cbindgen).
- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).

## Documentation

See [the docs](https://docs.rs/nautilus-execution) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="850">
<source>crates/indicators/README.md</source>
<document_content>
# nautilus-indicators

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-indicators)](https://docs.rs/nautilus-indicators/latest/nautilus-indicators/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-indicators.svg)](https://crates.io/crates/nautilus-indicators)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/NautilusTrader)

Technical analysis indicators for [NautilusTrader](http://nautilustrader.io).

The `nautilus-indicators` crate provides a comprehensive collection of technical analysis indicators
for quantitative trading and market research. This includes a wide variety of indicators
organized by category, with a unified trait-based architecture for consistent usage:

- **Moving averages**: SMA, EMA, DEMA, HMA, WMA, VWAP, adaptive averages, and linear regression.
- **Momentum indicators**: RSI, MACD, Aroon, Bollinger Bands, CCI, Stochastics, and rate of change.
- **Volatility indicators**: ATR, Donchian Channels, Keltner Channels, and volatility ratios.
- **Ratio analysis**: Efficiency ratios and spread analysis for relative performance.
- **Order book indicators**: Book imbalance ratio for analyzing market microstructure.
- **Common indicator trait**: Unified interface supporting bars, quotes, trades, and order book data.

All indicators are designed for high-performance real-time processing with bounded memory
usage and efficient circular buffer implementations. The crate supports both Rust-native
usage and Python integration for strategy development and backtesting.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation,
depending on the intended use case, i.e. whether to provide Python bindings
for the [nautilus_trader](https://pypi.org/project/nautilus_trader) Python package,
or as part of a Rust only build.

- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).
- `extension-module`: Builds as a Python extension module (used with `python`).

## Documentation

See [the docs](https://docs.rs/nautilus-indicators) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="941">
<source>crates/infrastructure/README.md</source>
<document_content>
# nautilus-infrastructure

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-infrastructure)](https://docs.rs/nautilus-infrastructure/latest/nautilus-infrastructure/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-infrastructure.svg)](https://crates.io/crates/nautilus-infrastructure)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/NautilusTrader)

Database and messaging infrastructure for [NautilusTrader](http://nautilustrader.io).

The `nautilus-infrastructure` crate provides backend database implementations and message bus adapters
that enable NautilusTrader to scale from development to production deployments. This includes
enterprise-grade data persistence and messaging capabilities:

- **Redis integration**: Cache database and message bus implementations using Redis.
- **PostgreSQL integration**: SQL-based cache database with comprehensive data models.
- **Connection management**: Robust connection handling with retry logic and health monitoring.
- **Serialization options**: Support for JSON and MessagePack encoding formats.
- **Python bindings**: PyO3 integration for seamless Python interoperability.

The crate supports multiple database backends through feature flags, allowing users to choose
the appropriate infrastructure components for their specific deployment requirements and scale.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation,
depending on the intended use case, i.e. whether to provide Python bindings
for the [nautilus_trader](https://pypi.org/project/nautilus_trader) Python package,
or as part of a Rust only build.

- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).
- `redis`: Enables the Redis cache database and message bus backing implementations.
- `sql`: Enables the SQL models and cache database.
- `extension-module`: Builds as a Python extension module (used with `python`).

## Documentation

See [the docs](https://docs.rs/nautilus-infrastructure) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="942">
<source>crates/infrastructure/TESTS.md</source>
<document_content>
# Infrastructure Integration Tests

This directory contains infrastructure integration tests that require external services.

## Service requirements

All required services are defined in `.docker/docker-compose.yml`.

The integration tests require the following services to be running:

- PostgreSQL on `localhost:5432`
- Redis on `localhost:6379`

### Service configuration

- **PostgreSQL**: Username `nautilus`, Password `pass`, Database `nautilus`
- **Redis**: Default configuration, no authentication
- **PgAdmin** (Optional): Available at `http://localhost:5051` (<admin@mail.com> / admin)

## Running integration test services

Use the following make targets to manage the services:

### Initial setup

```bash
make init-services  # Start containers and initialize database schema
```

### Managing services

```bash
make stop-services   # Stop development services (preserves data)
make start-services  # Start development services (without reinitializing database)
make purge-services  # Remove everything including data volumes
```

### Typical workflow

1. First time: `make init-services`
2. Stop when done: `make stop-services`
3. Resume work: `make start-services`
4. Clean slate: `make purge-services` then `make init-services`

## Running tests

Once services are running (and NautilusTrader installed by `uv` or `make`):

### Python infrastructure integration tests

```bash
# Run all infrastructure tests
uv run --no-sync pytest tests/integration_tests/infrastructure/

# Run specific test file
uv run --no-sync pytest tests/integration_tests/infrastructure/test_cache_database_redis.py
uv run --no-sync pytest tests/integration_tests/infrastructure/test_cache_database_postgres.py
```

### Rust infrastructure integration tests

The Rust integration tests are located in `crates/infrastructure/tests/` and require the same services.

```bash
# Run all Rust integration tests (includes Redis and PostgreSQL tests)
make cargo-test-crate-nautilus-infrastructure

# Using cargo nextest directly with the standard profile
# Run all infrastructure tests with output visible for debugging
cargo nextest run --lib --no-fail-fast --cargo-profile nextest -p nautilus-infrastructure --features redis,postgres --no-capture

# Run only Redis integration tests
cargo nextest run --lib --no-fail-fast --cargo-profile nextest -p nautilus-infrastructure --features redis,postgres -E 'test(test_cache_redis)'

# Run only PostgreSQL integration tests
cargo nextest run --lib --no-fail-fast --cargo-profile nextest -p nautilus-infrastructure --features redis,postgres -E 'test(test_cache_postgres) or test(test_cache_database_postgres)'

```

**Note**: Both Redis and PostgreSQL feature flags are in given examples to avoid rebuild.
Rust infrastructure integration tests are marked with `#[cfg(target_os = "linux")]` and will only run on Linux.
They use the `serial_test` crate to ensure tests that access the same database don't run concurrently.

</document_content>
</document>
<document index="967">
<source>crates/live/README.md</source>
<document_content>
# nautilus-live

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-live)](https://docs.rs/nautilus-live/latest/nautilus-live/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-live.svg)](https://crates.io/crates/nautilus-live)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/NautilusTrader)

Live system node for [NautilusTrader](http://nautilustrader.io).

The `nautilus-live` crate provides high-level abstractions and infrastructure for running live trading
systems, including data streaming, execution management, and system lifecycle handling.
It builds on top of the system kernel to provide simplified interfaces for live deployment:

- `LiveNode` High-level abstraction for live system nodes.
- `LiveNodeConfig` Configuration for live node deployment.
- `AsyncRunner` for managing system real-time data flow.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation,
depending on the intended use case, i.e. whether to provide Python bindings
for the [nautilus_trader](https://pypi.org/project/nautilus_trader) Python package,
or as part of a Rust only build.

- `ffi`: Enables the C foreign function interface (FFI) from [cbindgen](https://github.com/mozilla/cbindgen).
- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).
- `defi`: Enables DeFi (Decentralized Finance) support.

## Documentation

See [the docs](https://docs.rs/nautilus-live) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="980">
<source>crates/model/README.md</source>
<document_content>
# nautilus-model

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-model)](https://docs.rs/nautilus-model/latest/nautilus-model/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-model.svg)](https://crates.io/crates/nautilus-model)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/NautilusTrader)

Trading domain model for [NautilusTrader](http://nautilustrader.io).

The `nautilus-model` crate provides a type-safe domain model that forms the backbone of the framework
and can serve as the foundation for building algorithmic trading systems.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation,
depending on the intended use case, i.e. whether to provide Python bindings
for the [nautilus_trader](https://pypi.org/project/nautilus_trader) Python package,
or as part of a Rust only build.

- `ffi`: Enables the C foreign function interface (FFI) from [cbindgen](https://github.com/mozilla/cbindgen).
- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).
- `stubs`: Enables type stubs for use in testing scenarios.
- `high-precision`: Enables [high-precision mode](https://nautilustrader.io/docs/nightly/getting_started/installation#precision-mode) to use 128-bit value types.
- `defi`: Enables the DeFi (Decentralized Finance) domain model.
- `extension-module`: Builds as a Python extension module (used with `python`).

## Documentation

See [the docs](https://docs.rs/nautilus-model) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="1275">
<source>crates/network/README.md</source>
<document_content>
# nautilus-network

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-network)](https://docs.rs/nautilus-network/latest/nautilus-network/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-network.svg)](https://crates.io/crates/nautilus-network)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/NautilusTrader)

Network functionality for [NautilusTrader](http://nautilustrader.io).

The `nautilus-network` crate provides networking components including HTTP, WebSocket, and raw TCP socket
clients, rate limiting, backoff strategies, and socket TLS utilities for connecting to
trading venues and data providers.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation,
depending on the intended use case, i.e. whether to provide Python bindings
for the [nautilus_trader](https://pypi.org/project/nautilus_trader) Python package,
or as part of a Rust only build.

- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).
- `extension-module`: Builds the crate as a Python extension module.
- `turmoil`: Enables deterministic network simulation testing with [turmoil](https://github.com/tokio-rs/turmoil).

## Testing

The crate includes both standard integration tests and deterministic network simulation tests using turmoil.

To run standard tests:

```bash
cargo nextest run -p nautilus-network
```

To run turmoil network simulation tests:

```bash
cargo nextest run -p nautilus-network --features turmoil
```

The turmoil tests simulate various network conditions (reconnections, partitions, etc.) in a deterministic way,
allowing reliable testing of network failure scenarios without flakiness.

## Documentation

See [the docs](https://docs.rs/nautilus-network) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="1316">
<source>crates/persistence/README.md</source>
<document_content>
# nautilus-persistence

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-persistence)](https://docs.rs/nautilus-persistence/latest/nautilus-persistence/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-persistence.svg)](https://crates.io/crates/nautilus-persistence)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/NautilusTrader)

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation,
depending on the intended use case, i.e. whether to provide Python bindings
for the [nautilus_trader](https://pypi.org/project/nautilus_trader) Python package,
or as part of a Rust only build.

- `ffi`: Enables the C foreign function interface (FFI) from [cbindgen](https://github.com/mozilla/cbindgen).
- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).
- `high-precision`: Enables [high-precision mode](https://nautilustrader.io/docs/nightly/getting_started/installation#precision-mode) to use 128-bit value types.
- `extension-module`: Builds the crate as a Python extension module.

## Documentation

See [the docs](https://docs.rs/nautilus-persistence) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="1336">
<source>crates/portfolio/README.md</source>
<document_content>
# nautilus-portfolio

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-portfolio)](https://docs.rs/nautilus-portfolio/latest/nautilus-portfolio/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-portfolio.svg)](https://crates.io/crates/nautilus-portfolio)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/NautilusTrader)

Portfolio management and risk analysis for [NautilusTrader](http://nautilustrader.io).

The `nautilus-portfolio` crate provides comprehensive portfolio management capabilities including
real-time position tracking, performance calculations, and risk management. This includes
sophisticated portfolio analytics and multi-currency support:

- **Portfolio tracking**: Real-time portfolio state management with position and balance monitoring.
- **Account management**: Support for cash and margin accounts across multiple venues.
- **Performance calculations**: Real-time unrealized PnL, realized PnL, and mark-to-market valuations.
- **Risk management**: Initial margin calculations, maintenance margin tracking, and exposure monitoring.
- **Multi-currency support**: Currency conversion and cross-currency risk exposure analysis.
- **Configuration options**: Flexible settings for price types, currency conversion, and portfolio behavior.

The crate handles complex portfolio scenarios including multi-venue trading, currency conversions,
and sophisticated margin calculations for both live trading and backtesting environments.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation,
depending on the intended use case, i.e. whether to provide Python bindings
for the [nautilus_trader](https://pypi.org/project/nautilus_trader) Python package,
or as part of a Rust only build.

- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).

## Documentation

See [the docs](https://docs.rs/nautilus-portfolio) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="1340">
<source>crates/pyo3/README.md</source>
<document_content>
# nautilus-pyo3

A temporary crate to provide all Python bindings for the main `nautilus_trader` Python package.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate is primarily intended to be built for Python via
[maturin](https://github.com/PyO3/maturin) and therefore provides a broad set of feature flags
to toggle bindings and optional dependencies:

- `extension-module`: Builds the crate as a Python extension module (automatically enabled by `maturin`).
- `ffi`: Enables the C foreign function interface (FFI) support in dependent crates.
- `high-precision`: Uses 128-bit value types throughout the workspace.
- `cython-compat`: Adjusts the module name so it can be imported from Cython generated code.
- `postgres`: Enables PostgreSQL (sqlx) back-ends in dependent crates.
- `redis`: Enables Redis based infrastructure in dependent crates.
- `hypersync`: Enables hypersync support (fast parallel hash maps) where available.

</document_content>
</document>
<document index="1344">
<source>crates/risk/README.md</source>
<document_content>
# nautilus-risk

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-risk)](https://docs.rs/nautilus-risk/latest/nautilus-risk/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-risk.svg)](https://crates.io/crates/nautilus-risk)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/NautilusTrader)

Risk engine for [NautilusTrader](http://nautilustrader.io).

The `nautilus-risk` crate provides comprehensive risk management capabilities including pre-trade
order validation, position sizing calculations, and trading controls. This system ensures
trading operations remain within defined risk parameters and regulatory constraints:

- **Risk engine**: Central risk management orchestration with configurable trading states.
- **Order validation**: Pre-trade checks for price, quantity, notional limits, and market conditions.
- **Position sizing**: Fixed-risk position sizing calculations with commission and exchange rate support.
- **Trading controls**: Rate limiting, balance validation, and exposure management.
- **Account protection**: Multi-currency balance checks and margin requirement validation.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation,
depending on the intended use case, i.e. whether to provide Python bindings
for the [nautilus_trader](https://pypi.org/project/nautilus_trader) Python package,
or as part of a Rust only build.

- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).
- `extension-module`: Builds as a Python extension module (used with `python`).

## Documentation

See [the docs](https://docs.rs/nautilus-risk) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="1349">
<source>crates/serialization/README.md</source>
<document_content>
# nautilus-serialization

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-serialization)](https://docs.rs/nautilus-serialization/latest/nautilus-serialization/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-serialization.svg)](https://crates.io/crates/nautilus-serialization)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/NautilusTrader)

Data serialization and format conversion for [NautilusTrader](http://nautilustrader.io).

The `nautilus-serialization` crate provides comprehensive data serialization capabilities for converting
trading data between different formats including Apache Arrow, Parquet, and Cap'n Proto.
This enables efficient data storage, retrieval, and interoperability across different systems:

- **Apache Arrow integration**: Schema definitions and encoding/decoding for market data types.
- **Parquet file operations**: High-performance columnar storage for historical data analysis.
- **Record batch processing**: Efficient batch operations for time-series data.
- **Schema management**: Type-safe schema definitions with metadata preservation.
- **Cross-format conversion**: Seamless data interchange between Arrow, Parquet, and native types.
- **Cap'n Proto serialization**: Zero-copy, schema-based serialization for efficient data interchange.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation,
depending on the intended use case, i.e. whether to provide Python bindings
for the [nautilus_trader](https://pypi.org/project/nautilus_trader) Python package,
or as part of a Rust only build.

- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).
- `extension-module`: Builds as a Python extension module (used with `python`).
- `high-precision`: Enables [high-precision mode](https://nautilustrader.io/docs/nightly/getting_started/installation#precision-mode) to use 128-bit value types.
- `capnp`: Enables [Cap'n Proto](https://capnproto.org/) serialization support.

### Building with Cap'n Proto support

To build with Cap'n Proto serialization enabled:

```bash
cargo build -p nautilus-serialization --features capnp
```

The Cap'n Proto compiler can be installed from [capnproto.org](https://capnproto.org/install.html).

## Cap'n Proto schemas

When the `capnp` feature is enabled, this crate provides zero-copy serialization using Cap'n Proto schemas.

### Schema location

Cap'n Proto schemas are bundled with the crate in `schemas/capnp/`:

- `common/identifiers.capnp` - Identifier types (TraderId, InstrumentId, etc.)
- `common/types.capnp` - Value types (Price, Quantity, Money, etc.)
- `common/enums.capnp` - Trading enumerations
- `commands/trading.capnp` - Trading commands
- `commands/data.capnp` - Data subscription/request commands
- `events/order.capnp` - Order events
- `events/position.capnp` - Position events
- `events/account.capnp` - Account events
- `data/market.capnp` - Market data types (quotes, trades, bars, order books)

### Generated modules

During build, schemas are compiled to Rust code and made available as:

- `nautilus_serialization::identifiers_capnp`
- `nautilus_serialization::types_capnp`
- `nautilus_serialization::enums_capnp`
- `nautilus_serialization::trading_capnp`
- `nautilus_serialization::data_capnp`
- `nautilus_serialization::order_capnp`
- `nautilus_serialization::position_capnp`
- `nautilus_serialization::account_capnp`
- `nautilus_serialization::market_capnp`

### Usage example

```rust
use nautilus_model::types::Price;
use nautilus_serialization::capnp::{ToCapnp, FromCapnp};

// Serialize a Price
let price = Price::from("123.45");
let bytes = nautilus_serialization::capnp::conversions::serialize_price(&price).unwrap();

// Deserialize back
let decoded = nautilus_serialization::capnp::conversions::deserialize_price(&bytes).unwrap();
assert_eq!(price, decoded);
```

See the `conversions` module for trait-based serialization patterns:

```rust
use nautilus_model::identifiers::InstrumentId;
use nautilus_serialization::capnp::{ToCapnp, FromCapnp, identifiers_capnp};

let instrument_id = InstrumentId::from("AAPL.NASDAQ");

// Using traits
let mut message = capnp::message::Builder::new_default();
let builder = message.init_root::<identifiers_capnp::instrument_id::Builder>();
instrument_id.to_capnp(builder);

// Serialize to bytes
let mut bytes = Vec::new();
capnp::serialize::write_message(&mut bytes, &message).unwrap();

// Deserialize
let reader = capnp::serialize::read_message(
    &mut &bytes[..],
    capnp::message::ReaderOptions::new()
).unwrap();
let root = reader.get_root::<identifiers_capnp::instrument_id::Reader>().unwrap();
let decoded = InstrumentId::from_capnp(root).unwrap();
```

### Contributing schemas

When adding or modifying schemas:

1. Edit schema files in the appropriate subdirectory under `schemas/capnp/`.
2. Use lowerCamelCase for field names to match Cap'n Proto conventions.
3. Generate a unique schema ID using: `capnp id`.
4. Implement `ToCapnp` and `FromCapnp` traits in `src/capnp/conversions.rs`.
5. Add integration tests in `tests/` to verify roundtrip serialization.

The build script (`build.rs`) automatically discovers and compiles all `.capnp` files during build.

## Serialization format comparison

This crate supports three serialization formats for market data types. Choose the format based on your use case:

| Format       | Serialize | Deserialize | Size      | Use case                                    |
|--------------|-----------|-------------|-----------|---------------------------------------------|
| Cap'n Proto  | ~267ns    | ~530ns      | 264 bytes | High-frequency data streams, IPC, caching.  |
| JSON         | ~332ns    | ~779ns      | 174 bytes | Human-readable output, debugging, APIs.     |
| MsgPack      | ~375ns    | ~634ns      | 134 bytes | Compact storage, network transmission.      |
| Arrow        | TBD       | TBD         | Columnar  | Batch processing, Parquet, IPC, analytics.  |

Performance numbers shown for `QuoteTick` serialization (measured on AMD Ryzen 9 7950X). Cap'n Proto provides the
fastest serialization and deserialization, while MsgPack offers the smallest size. Arrow is optimized for batch
processing rather than individual messages.

**Note:** Cap'n Proto performance can be further optimized through zero-copy techniques and direct buffer manipulation
for specialized use cases.

### Usage examples

#### JSON serialization

```rust
use nautilus_core::serialization::Serializable;
use nautilus_model::data::QuoteTick;

let quote = QuoteTick { /* ... */ };

// Serialize to JSON
let json_bytes = quote.to_json_bytes()?;

// Deserialize from JSON
let decoded = QuoteTick::from_json_bytes(&json_bytes)?;
```

#### MsgPack serialization

```rust
use nautilus_core::serialization::{ToMsgPack, FromMsgPack};
use nautilus_model::data::QuoteTick;

let quote = QuoteTick { /* ... */ };

// Serialize to MsgPack
let msgpack_bytes = quote.to_msgpack_bytes()?;

// Deserialize from MsgPack
let decoded = QuoteTick::from_msgpack_bytes(&msgpack_bytes)?;
```

#### Cap'n Proto serialization

```rust
use nautilus_model::data::QuoteTick;
use nautilus_serialization::capnp::{ToCapnp, FromCapnp, market_capnp};

let quote = QuoteTick { /* ... */ };

// Serialize to Cap'n Proto
let mut message = capnp::message::Builder::new_default();
let builder = message.init_root::<market_capnp::quote_tick::Builder>();
quote.to_capnp(builder);

let mut bytes = Vec::new();
capnp::serialize::write_message(&mut bytes, &message)?;

// Deserialize from Cap'n Proto
let reader = capnp::serialize::read_message(
    &mut &bytes[..],
    capnp::message::ReaderOptions::new()
)?;
let root = reader.get_root::<market_capnp::quote_tick::Reader>()?;
let decoded = QuoteTick::from_capnp(root)?;
```

## Benchmarking

Run benchmarks to compare serialization performance across formats:

```bash
# Compare all formats for QuoteTick
cargo bench -p nautilus-serialization --features capnp --bench serialization_comparison -- QuoteTick

# Compare all formats for TradeTick
cargo bench -p nautilus-serialization --features capnp --bench serialization_comparison -- TradeTick

# Compare all formats for Bar
cargo bench -p nautilus-serialization --features capnp --bench serialization_comparison -- Bar

# Run all Cap'n Proto benchmarks (including OrderBookDeltas with varying sizes)
cargo bench -p nautilus-serialization --features capnp --bench capnp_serialization

# Run all comparison benchmarks
cargo bench -p nautilus-serialization --features capnp --bench serialization_comparison
```

Benchmark results include serialization and deserialization times for each format.

## Documentation

See [the docs](https://docs.rs/nautilus-serialization) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="1382">
<source>crates/system/README.md</source>
<document_content>
# nautilus-system

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-system)](https://docs.rs/nautilus-system/latest/nautilus-system/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-system.svg)](https://crates.io/crates/nautilus-system)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)

System-level components and orchestration for [NautilusTrader](http://nautilustrader.io).

The `nautilus-system` crate provides the core system architecture for orchestrating trading systems,
including the kernel that manages all engines, configuration management,
and system-level factories for creating components:

- `NautilusKernel` - Core system orchestrator managing engines and components.
- `NautilusKernelConfig` - Configuration for kernel initialization.
- System builders and factories for component creation.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation,
depending on the intended use case, i.e. whether to provide Python bindings
for the [nautilus_trader](https://pypi.org/project/nautilus_trader) Python package,
or as part of a Rust only build.

- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).
- `extension-module`: Builds the crate as a Python extension module.

## Documentation

See [the docs](https://docs.rs/nautilus-system) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="1391">
<source>crates/testkit/README.md</source>
<document_content>
# nautilus-testkit

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-testkit)](https://docs.rs/nautilus-testkit/latest/nautilus-testkit/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-testkit.svg)](https://crates.io/crates/nautilus-testkit)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/NautilusTrader)

Test utilities and data management for [NautilusTrader](http://nautilustrader.io).

The `nautilus-testkit` crate provides comprehensive testing utilities including test data management,
file handling, and common testing patterns. This crate supports robust testing workflows
across the entire NautilusTrader ecosystem with automated data downloads and validation:

- **Test data management**: Automated downloading and caching of test datasets.
- **File utilities**: File integrity verification with SHA-256 checksums.
- **Path resolution**: Platform-agnostic test data path management.
- **Precision handling**: Support for both 64-bit and 128-bit precision test data.
- **Common patterns**: Reusable test utilities and helper functions.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation,
depending on the intended use case, i.e. whether to provide Python bindings
for the [nautilus_trader](https://pypi.org/project/nautilus_trader) Python package,
or as part of a Rust only build.

- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).
- `high-precision`: Enables [high-precision mode](https://nautilustrader.io/docs/nightly/getting_started/installation#precision-mode) to use 128-bit value types.
- `extension-module`: Builds the crate as a Python extension module.

## Documentation

See [the docs](https://docs.rs/nautilus-testkit) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="1399">
<source>crates/trading/README.md</source>
<document_content>
# nautilus-trading

[![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml)
[![Documentation](https://img.shields.io/docsrs/nautilus-trading)](https://docs.rs/nautilus-trading/latest/nautilus-trading/)
[![crates.io version](https://img.shields.io/crates/v/nautilus-trading.svg)](https://crates.io/crates/nautilus-trading)
![license](https://img.shields.io/github/license/nautechsystems/nautilus_trader?color=blue)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.gg/NautilusTrader)

Trading strategy machinery and orchestration for [NautilusTrader](http://nautilustrader.io).

The `nautilus-trading` crate provides core trading capabilities including:

- **Forex sessions**: Market session time calculations and timezone handling.

## Platform

[NautilusTrader](http://nautilustrader.io) is an open-source, high-performance, production-grade
algorithmic trading platform, providing quantitative traders with the ability to backtest
portfolios of automated trading strategies on historical data with an event-driven engine,
and also deploy those same strategies live, with no code changes.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting mission-critical, trading system backtesting and live deployment workloads.

## Feature flags

This crate provides feature flags to control source code inclusion during compilation,
depending on the intended use case, i.e. whether to provide Python bindings
for the [nautilus_trader](https://pypi.org/project/nautilus_trader) Python package,
or as part of a Rust only build.

- `python`: Enables Python bindings from [PyO3](https://pyo3.rs).
- `extension-module`: Builds the crate as a Python extension module.

## Documentation

See [the docs](https://docs.rs/nautilus-trading) for more detailed usage.

## License

The source code for NautilusTrader is available on GitHub under the [GNU Lesser General Public License v3.0](https://www.gnu.org/licenses/lgpl-3.0.en.html).
Contributions to the project are welcome and require the completion of a standard [Contributor License Agreement (CLA)](https://github.com/nautechsystems/nautilus_trader/blob/develop/CLA.md).

---

NautilusTrader™ is developed and maintained by Nautech Systems, a technology
company specializing in the development of high-performance trading systems.
For more information, visit <https://nautilustrader.io>.

<img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-logo-white.png" alt="logo" width="400" height="auto"/>

© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.

</document_content>
</document>
<document index="1405">
<source>docs/api_reference/accounting.md</source>
<document_content>
# Accounting

```{eval-rst}
.. automodule:: nautilus_trader.accounting
```

```{eval-rst}
.. automodule:: nautilus_trader.accounting.accounts.cash
    :show-inheritance:
    :inherited-members:
    :members:
    :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.accounting.accounts.margin
    :show-inheritance:
    :inherited-members:
    :members:
    :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.accounting.calculators
    :show-inheritance:
    :inherited-members:
    :members:
    :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.accounting.factory
    :show-inheritance:
    :inherited-members:
    :members:
    :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.accounting.manager
    :show-inheritance:
    :inherited-members:
    :members:
    :member-order: bysource
```

</document_content>
</document>
<document index="1406">
<source>docs/api_reference/adapters/betfair.md</source>
<document_content>
# Betfair

```{eval-rst}
.. automodule:: nautilus_trader.adapters.betfair
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Client

```{eval-rst}
.. automodule:: nautilus_trader.adapters.betfair.client
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Common

```{eval-rst}
.. automodule:: nautilus_trader.adapters.betfair.common
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Config

```{eval-rst}
.. automodule:: nautilus_trader.adapters.betfair.config
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Data

```{eval-rst}
.. automodule:: nautilus_trader.adapters.betfair.data
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Data Types

```{eval-rst}
.. automodule:: nautilus_trader.adapters.betfair.data_types
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Execution

```{eval-rst}
.. automodule:: nautilus_trader.adapters.betfair.execution
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Factories

```{eval-rst}
.. automodule:: nautilus_trader.adapters.betfair.factories
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## OrderBook

```{eval-rst}
.. automodule:: nautilus_trader.adapters.betfair.orderbook
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Providers

```{eval-rst}
.. automodule:: nautilus_trader.adapters.betfair.providers
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Sockets

```{eval-rst}
.. automodule:: nautilus_trader.adapters.betfair.sockets
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1407">
<source>docs/api_reference/adapters/binance.md</source>
<document_content>
# Binance

```{eval-rst}
.. automodule:: nautilus_trader.adapters.binance
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Config

```{eval-rst}
.. automodule:: nautilus_trader.adapters.binance.config
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Factories

```{eval-rst}
.. automodule:: nautilus_trader.adapters.binance.factories
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Enums

```{eval-rst}
.. automodule:: nautilus_trader.adapters.binance.common.enums
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Types

```{eval-rst}
.. automodule:: nautilus_trader.adapters.binance.common.types
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Futures

### Data

```{eval-rst}
.. automodule:: nautilus_trader.adapters.binance.futures.data
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

### Enums

```{eval-rst}
.. automodule:: nautilus_trader.adapters.binance.futures.enums
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

### Execution

```{eval-rst}
.. automodule:: nautilus_trader.adapters.binance.futures.execution
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

### Providers

```{eval-rst}
.. automodule:: nautilus_trader.adapters.binance.futures.providers
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

### Types

```{eval-rst}
.. automodule:: nautilus_trader.adapters.binance.futures.types
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Spot

### Data

```{eval-rst}
.. automodule:: nautilus_trader.adapters.binance.spot.data
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

### Enums

```{eval-rst}
.. automodule:: nautilus_trader.adapters.binance.spot.enums
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

### Execution

```{eval-rst}
.. automodule:: nautilus_trader.adapters.binance.spot.execution
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

### Providers

```{eval-rst}
.. automodule:: nautilus_trader.adapters.binance.spot.providers
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1408">
<source>docs/api_reference/adapters/bybit.md</source>
<document_content>
# Bybit

```{eval-rst}
.. automodule:: nautilus_trader.adapters.bybit
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Config

```{eval-rst}
.. automodule:: nautilus_trader.adapters.bybit.config
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Factories

```{eval-rst}
.. automodule:: nautilus_trader.adapters.bybit.factories
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Enums

```{eval-rst}
.. automodule:: nautilus_trader.adapters.bybit.common.enums
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Providers

```{eval-rst}
.. automodule:: nautilus_trader.adapters.bybit.providers
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Data

```{eval-rst}
.. automodule:: nautilus_trader.adapters.bybit.data
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Execution

```{eval-rst}
.. automodule:: nautilus_trader.adapters.bybit.execution
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1409">
<source>docs/api_reference/adapters/coinbase_intx.md</source>
<document_content>
# Coinbase International

```{eval-rst}
.. automodule:: nautilus_trader.adapters.coinbase_intx
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Config

```{eval-rst}
.. automodule:: nautilus_trader.adapters.coinbase_intx.config
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Constants

```{eval-rst}
.. automodule:: nautilus_trader.adapters.coinbase_intx.constants
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Factories

```{eval-rst}
.. automodule:: nautilus_trader.adapters.coinbase_intx.factories
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Providers

```{eval-rst}
.. automodule:: nautilus_trader.adapters.coinbase_intx.providers
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Data

```{eval-rst}
.. automodule:: nautilus_trader.adapters.coinbase_intx.data
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Execution

```{eval-rst}
.. automodule:: nautilus_trader.adapters.coinbase_intx.execution
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1410">
<source>docs/api_reference/adapters/databento.md</source>
<document_content>
# Databento

```{eval-rst}
.. automodule:: nautilus_trader.adapters.databento
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Config

```{eval-rst}
.. automodule:: nautilus_trader.adapters.databento.config
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Factories

```{eval-rst}
.. automodule:: nautilus_trader.adapters.databento.factories
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Enums

```{eval-rst}
.. automodule:: nautilus_trader.adapters.databento.enums
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Types

```{eval-rst}
.. automodule:: nautilus_trader.adapters.databento.types
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Loaders

```{eval-rst}
.. automodule:: nautilus_trader.adapters.databento.loaders
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Providers

```{eval-rst}
.. automodule:: nautilus_trader.adapters.databento.providers
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Data

```{eval-rst}
.. automodule:: nautilus_trader.adapters.databento.data
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1411">
<source>docs/api_reference/adapters/dydx.md</source>
<document_content>
# dYdX

```{eval-rst}
.. automodule:: nautilus_trader.adapters.dydx
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Config

```{eval-rst}
.. automodule:: nautilus_trader.adapters.dydx.config
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Factories

```{eval-rst}
.. automodule:: nautilus_trader.adapters.dydx.factories
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Enums

```{eval-rst}
.. automodule:: nautilus_trader.adapters.dydx.common.enums
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Providers

```{eval-rst}
.. automodule:: nautilus_trader.adapters.dydx.providers
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Data

```{eval-rst}
.. automodule:: nautilus_trader.adapters.dydx.data
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Execution

```{eval-rst}
.. automodule:: nautilus_trader.adapters.dydx.execution
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1412">
<source>docs/api_reference/adapters/index.md</source>
<document_content>
# Adapters

```{eval-rst}
.. automodule:: nautilus_trader.adapters
```

```{eval-rst}
.. toctree::
   :maxdepth: 2
   :glob:
   :titlesonly:
   :hidden:

   betfair.md
   binance.md
   bybit.md
   coinbase_intx.md
   databento.md
   dydx.md
   interactive_brokers.md
   okx.md
   polymarket.md
   tardis.md
```

</document_content>
</document>
<document index="1413">
<source>docs/api_reference/adapters/interactive_brokers.md</source>
<document_content>
# Interactive Brokers

```{eval-rst}
.. automodule:: nautilus_trader.adapters.interactive_brokers
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Client

```{eval-rst}
.. automodule:: nautilus_trader.adapters.interactive_brokers.client.client
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Common

```{eval-rst}
.. automodule:: nautilus_trader.adapters.interactive_brokers.common
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Config

```{eval-rst}
.. automodule:: nautilus_trader.adapters.interactive_brokers.config
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Data

```{eval-rst}
.. automodule:: nautilus_trader.adapters.interactive_brokers.data
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Execution

```{eval-rst}
.. automodule:: nautilus_trader.adapters.interactive_brokers.execution
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Factories

```{eval-rst}
.. automodule:: nautilus_trader.adapters.interactive_brokers.factories
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Gateway

```{eval-rst}
.. automodule:: nautilus_trader.adapters.interactive_brokers.gateway
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Historical

```{eval-rst}
.. automodule:: nautilus_trader.adapters.interactive_brokers.historical.client
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Parsing

```{eval-rst}
.. automodule:: nautilus_trader.adapters.interactive_brokers.parsing.execution
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.adapters.interactive_brokers.parsing.instruments
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Providers

```{eval-rst}
.. automodule:: nautilus_trader.adapters.interactive_brokers.providers
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1414">
<source>docs/api_reference/adapters/okx.md</source>
<document_content>
# OKX

```{eval-rst}
.. automodule:: nautilus_trader.adapters.okx
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Config

```{eval-rst}
.. automodule:: nautilus_trader.adapters.okx.config
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Factories

```{eval-rst}
.. automodule:: nautilus_trader.adapters.okx.factories
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Providers

```{eval-rst}
.. automodule:: nautilus_trader.adapters.okx.providers
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Data

```{eval-rst}
.. automodule:: nautilus_trader.adapters.okx.data
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Execution

```{eval-rst}
.. automodule:: nautilus_trader.adapters.okx.execution
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1415">
<source>docs/api_reference/adapters/polymarket.md</source>
<document_content>
# Polymarket

```{eval-rst}
.. automodule:: nautilus_trader.adapters.polymarket
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Config

```{eval-rst}
.. automodule:: nautilus_trader.adapters.polymarket.config
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Factories

```{eval-rst}
.. automodule:: nautilus_trader.adapters.polymarket.factories
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Enums

```{eval-rst}
.. automodule:: nautilus_trader.adapters.polymarket.common.enums
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Providers

```{eval-rst}
.. automodule:: nautilus_trader.adapters.polymarket.providers
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Data

```{eval-rst}
.. automodule:: nautilus_trader.adapters.polymarket.data
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Execution

```{eval-rst}
.. automodule:: nautilus_trader.adapters.polymarket.execution
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1416">
<source>docs/api_reference/adapters/tardis.md</source>
<document_content>
# Tardis

```{eval-rst}
.. automodule:: nautilus_trader.adapters.tardis
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Loaders

```{eval-rst}
.. automodule:: nautilus_trader.adapters.tardis.loaders
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Config

```{eval-rst}
.. automodule:: nautilus_trader.adapters.tardis.config
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Providers

```{eval-rst}
.. automodule:: nautilus_trader.adapters.tardis.providers
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Factories

```{eval-rst}
.. automodule:: nautilus_trader.adapters.tardis.factories
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Data

```{eval-rst}
.. automodule:: nautilus_trader.adapters.tardis.data
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1417">
<source>docs/api_reference/analysis.md</source>
<document_content>
# Analysis

```{eval-rst}
.. automodule:: nautilus_trader.analysis
```

```{eval-rst}
.. automodule:: nautilus_trader.analysis.analyzer
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.analysis.reporter
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.analysis.statistic
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1418">
<source>docs/api_reference/backtest.md</source>
<document_content>
# Backtest

```{eval-rst}
.. automodule:: nautilus_trader.backtest
```

```{eval-rst}
.. automodule:: nautilus_trader.backtest.auction
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.backtest.data_client
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.backtest.engine
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.backtest.execution_client
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.backtest.models
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.backtest.modules
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.backtest.node
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.backtest.results
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1419">
<source>docs/api_reference/cache.md</source>
<document_content>
# Cache

```{eval-rst}
.. automodule:: nautilus_trader.cache
```

```{eval-rst}
.. automodule:: nautilus_trader.cache.cache
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.cache.database
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.cache.base
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1420">
<source>docs/api_reference/common.md</source>
<document_content>
# Common

```{eval-rst}
.. automodule:: nautilus_trader.common
```

```{eval-rst}
.. automodule:: nautilus_trader.common.actor
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.common.factories
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Component

```{eval-rst}
.. automodule:: nautilus_trader.common.component
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Executor

```{eval-rst}
.. automodule:: nautilus_trader.common.executor
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Generators

```{eval-rst}
.. automodule:: nautilus_trader.common.generators
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.common.providers
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1422">
<source>docs/api_reference/config.md</source>
<document_content>
# Config

## Backtest

```{eval-rst}
.. automodule:: nautilus_trader.backtest.config
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Cache

```{eval-rst}
.. automodule:: nautilus_trader.cache.config
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Common

```{eval-rst}
.. automodule:: nautilus_trader.common.config
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Data

```{eval-rst}
.. automodule:: nautilus_trader.data.config
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Execution

```{eval-rst}
.. automodule:: nautilus_trader.execution.config
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Live

```{eval-rst}
.. automodule:: nautilus_trader.live.config
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Persistence

```{eval-rst}
.. automodule:: nautilus_trader.persistence.config
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Risk

```{eval-rst}
.. automodule:: nautilus_trader.risk.config
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## System

```{eval-rst}
.. automodule:: nautilus_trader.system.config
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Trading

```{eval-rst}
.. automodule:: nautilus_trader.trading.config
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1423">
<source>docs/api_reference/core.md</source>
<document_content>
# Core

```{eval-rst}
.. automodule:: nautilus_trader.core
```

## Datetime

```{eval-rst}
.. automodule:: nautilus_trader.core.datetime
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Finite-State Machine (FSM)

```{eval-rst}
.. automodule:: nautilus_trader.core.fsm
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Message

```{eval-rst}
.. automodule:: nautilus_trader.core.message
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Stats

```{eval-rst}
.. automodule:: nautilus_trader.core.stats
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## UUID

```{eval-rst}
.. automodule:: nautilus_trader.core.uuid
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1424">
<source>docs/api_reference/data.md</source>
<document_content>
# Data

```{eval-rst}
.. automodule:: nautilus_trader.data
```

## Aggregation

```{eval-rst}
.. automodule:: nautilus_trader.data.aggregation
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Client

```{eval-rst}
.. automodule:: nautilus_trader.data.client
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Engine

```{eval-rst}
.. automodule:: nautilus_trader.data.engine
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Messages

```{eval-rst}
.. automodule:: nautilus_trader.data.messages
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1425">
<source>docs/api_reference/execution.md</source>
<document_content>
# Execution

```{eval-rst}
.. automodule:: nautilus_trader.execution
```

## Components

```{eval-rst}
.. automodule:: nautilus_trader.execution.algorithm
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.execution.client
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.execution.emulator
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.execution.engine
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.execution.manager
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.execution.matching_core
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Messages

```{eval-rst}
.. automodule:: nautilus_trader.execution.messages
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

## Reports

```{eval-rst}
.. automodule:: nautilus_trader.execution.reports
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1426">
<source>docs/api_reference/index.md</source>
<document_content>
# Python API

Welcome to the Python API reference for NautilusTrader!

The API reference provides detailed technical documentation for the NautilusTrader framework,
including its modules, classes, methods, and functions. The reference is automatically generated
from the latest NautilusTrader source code using [Sphinx](https://www.sphinx-doc.org/en/master/).

Please note that there are separate references for different versions of NautilusTrader:

- **Latest**: This API reference is built from the head of the `develop` branch and represents the latest stable release.
- **Nightly**: This API reference is built from the head of the `nightly` branch and represents bleeding edge and experimental changes/features currently in development.

You can select the desired API reference from the **Versions** top left drop down menu.

Use the right navigation sidebar to explore the available modules and their contents.
You can click on any item to view its detailed documentation, including parameter descriptions, and return value explanations.

## Why Python?

Python was originally created decades ago as a simple scripting language with a clean straight
forward syntax. It has since evolved into a fully fledged general purpose object-oriented
programming language. Based on the TIOBE index, Python is currently the most popular programming language in the world.
Not only that, Python has become the *de facto lingua franca* of data science, machine learning, and artificial intelligence.

</document_content>
</document>
<document index="1427">
<source>docs/api_reference/indicators.md</source>
<document_content>
# Indicators

```{eval-rst}
.. automodule:: nautilus_trader.indicators
```

```{eval-rst}
.. automodule:: nautilus_trader.indicators.averages
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.indicators.fuzzy_candlesticks
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.indicators.momentum
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.indicators.spread_analyzer
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.indicators.trend
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.indicators.volatility
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.indicators.volume
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1428">
<source>docs/api_reference/live.md</source>
<document_content>
# Live

```{eval-rst}
.. automodule:: nautilus_trader.live
```

```{eval-rst}
.. automodule:: nautilus_trader.live.data_client
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.live.data_engine
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.live.execution_client
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.live.execution_engine
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.live.risk_engine
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.live.node
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.live.node_builder
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1429">
<source>docs/api_reference/model/book.md</source>
<document_content>
# Order Book

```{eval-rst}
.. automodule:: nautilus_trader.model.book
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1430">
<source>docs/api_reference/model/data.md</source>
<document_content>
# Data

```{eval-rst}
.. automodule:: nautilus_trader.model.data
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1431">
<source>docs/api_reference/model/events.md</source>
<document_content>
# Events

```{eval-rst}
.. automodule:: nautilus_trader.model.events
```

```{eval-rst}
.. automodule:: nautilus_trader.model.events.account
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.model.events.order
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.model.events.position
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1432">
<source>docs/api_reference/model/identifiers.md</source>
<document_content>
# Identifiers

```{eval-rst}
.. automodule:: nautilus_trader.model.identifiers
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1433">
<source>docs/api_reference/model/index.md</source>
<document_content>
# Model

```{eval-rst}
.. automodule:: nautilus_trader.model
```

```{eval-rst}
.. toctree::
   :maxdepth: 2
   :glob:
   :titlesonly:
   :hidden:

   book.md
   data.md
   events.md
   identifiers.md
   instruments.md
   objects.md
   orders.md
   position.md
   tick_scheme.md
```

</document_content>
</document>
<document index="1434">
<source>docs/api_reference/model/instruments.md</source>
<document_content>
# Instruments

```{eval-rst}
.. automodule:: nautilus_trader.model.instruments
```

```{eval-rst}
.. automodule:: nautilus_trader.model.instruments.betting
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.model.instruments.crypto_perpetual
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.model.instruments.crypto_future
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.model.instruments.currency_pair
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.model.instruments.equity
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.model.instruments.futures_contract
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.model.instruments.option_contract
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.model.instruments.synthetic
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.model.instruments.base
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1435">
<source>docs/api_reference/model/objects.md</source>
<document_content>
# Objects

```{eval-rst}
.. automodule:: nautilus_trader.model.objects
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1436">
<source>docs/api_reference/model/orders.md</source>
<document_content>
# Orders

```{eval-rst}
.. automodule:: nautilus_trader.model.orders
```

```{eval-rst}
.. automodule:: nautilus_trader.model.orders.market
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.model.orders.limit
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.model.orders.stop_market
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.model.orders.stop_limit
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.model.orders.market_to_limit
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.model.orders.market_if_touched
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.model.orders.limit_if_touched
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.model.orders.trailing_stop_market
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.model.orders.trailing_stop_limit
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.model.orders.list
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.model.orders.base
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1437">
<source>docs/api_reference/model/position.md</source>
<document_content>
# Position

```{eval-rst}
.. automodule:: nautilus_trader.model.position
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1438">
<source>docs/api_reference/model/tick_scheme.md</source>
<document_content>
# Tick Scheme

```{eval-rst}
.. automodule:: nautilus_trader.model.tick_scheme
```

```{eval-rst}
.. automodule:: nautilus_trader.model.tick_scheme.implementations.fixed
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.model.tick_scheme.implementations.tiered
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.model.tick_scheme.base
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1439">
<source>docs/api_reference/persistence.md</source>
<document_content>
# Persistence

```{eval-rst}
.. automodule:: nautilus_trader.persistence
```

```{eval-rst}
.. automodule:: nautilus_trader.persistence.catalog.base
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.persistence.catalog.parquet
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.persistence.wranglers
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.persistence.writer
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1440">
<source>docs/api_reference/portfolio.md</source>
<document_content>
# Portfolio

```{eval-rst}
.. automodule:: nautilus_trader.portfolio
```

```{eval-rst}
.. automodule:: nautilus_trader.portfolio.portfolio
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.portfolio.base
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1441">
<source>docs/api_reference/risk.md</source>
<document_content>
# Risk

```{eval-rst}
.. automodule:: nautilus_trader.risk
```

```{eval-rst}
.. automodule:: nautilus_trader.risk.engine
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.risk.sizing
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1442">
<source>docs/api_reference/serialization.md</source>
<document_content>
# Serialization

```{eval-rst}
.. automodule:: nautilus_trader.serialization
```

```{eval-rst}
.. automodule:: nautilus_trader.serialization.serializer
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.serialization.base
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1443">
<source>docs/api_reference/system.md</source>
<document_content>
# System

```{eval-rst}
.. automodule:: nautilus_trader.system
```

```{eval-rst}
.. automodule:: nautilus_trader.system.kernel
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1444">
<source>docs/api_reference/trading.md</source>
<document_content>
# Trading

```{eval-rst}
.. automodule:: nautilus_trader.trading
```

```{eval-rst}
.. automodule:: nautilus_trader.trading.controller
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.trading.filters
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.trading.strategy
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

```{eval-rst}
.. automodule:: nautilus_trader.trading.trader
   :show-inheritance:
   :inherited-members:
   :members:
   :member-order: bysource
```

</document_content>
</document>
<document index="1445">
<source>docs/concepts/actors.md</source>
<document_content>
# Actors

:::info
We are currently working on this concept guide.
:::

The `Actor` serves as the foundational component for interacting with the trading system.
It provides core functionality for receiving market data, handling events, and managing state within
the trading environment. The `Strategy` class inherits from Actor and extends its capabilities with
order management methods.

**Key capabilities**:

- Event subscription and handling.
- Market data reception.
- State management.
- System interaction primitives.

## Basic example

Just like strategies, actors support configuration through a very similar pattern.

```python
from nautilus_trader.config import ActorConfig
from nautilus_trader.model import InstrumentId
from nautilus_trader.model import Bar, BarType
from nautilus_trader.common.actor import Actor


class MyActorConfig(ActorConfig):
    instrument_id: InstrumentId   # example value: "ETHUSDT-PERP.BINANCE"
    bar_type: BarType             # example value: "ETHUSDT-PERP.BINANCE-15-MINUTE[LAST]-INTERNAL"
    lookback_period: int = 10


class MyActor(Actor):
    def __init__(self, config: MyActorConfig) -> None:
        super().__init__(config)

        # Custom state variables
        self.count_of_processed_bars: int = 0

    def on_start(self) -> None:
        # Subscribe to all incoming bars
        self.subscribe_bars(self.config.bar_type)   # You can access configuration directly via `self.config`

    def on_bar(self, bar: Bar):
        self.count_of_processed_bars += 1
```

## Data handling and callbacks

When working with data in Nautilus, it's important to understand the relationship between data
*requests/subscriptions* and their corresponding callback handlers. The system uses different handlers
depending on whether the data is historical or real-time.

### Historical vs real-time data

The system distinguishes between two types of data flow:

1. **Historical data** (from *requests*):
   - Obtained through methods like `request_bars()`, `request_quote_ticks()`, etc.
   - Processed through the `on_historical_data()` handler.
   - Used for initial data loading and historical analysis.

2. **Real-time data** (from *subscriptions*):
   - Obtained through methods like `subscribe_bars()`, `subscribe_quote_ticks()`, etc.
   - Processed through specific handlers like `on_bar()`, `on_quote_tick()`, etc.
   - Used for live data processing.

### Callback handlers

Here's how different data operations map to their handlers:

| Operation                       | Category         | Handler                  | Purpose |
|:--------------------------------|:-----------------|:-------------------------|:--------|
| `subscribe_data()`              | Real‑time        | `on_data()`              | Live data updates. |
| `subscribe_instrument()`        | Real‑time        | `on_instrument()`        | Live instrument definition updates. |
| `subscribe_instruments()`       | Real‑time        | `on_instrument()`        | Live instrument definition updates (for venue). |
| `subscribe_order_book_deltas()` | Real‑time        | `on_order_book_deltas()` | Live order book updates. |
| `subscribe_quote_ticks()`       | Real‑time        | `on_quote_tick()`        | Live quote updates. |
| `subscribe_trade_ticks()`       | Real‑time        | `on_trade_tick()`        | Live trade updates. |
| `subscribe_mark_prices()`       | Real‑time        | `on_mark_price()`        | Live mark price updates. |
| `subscribe_index_prices()`      | Real‑time        | `on_index_price()`       | Live index price updates. |
| `subscribe_funding_rates()`     | Real‑time        | `on_funding_rate()`      | Live funding rate updates. |
| `subscribe_bars()`              | Real‑time        | `on_bar()`               | Live bar updates. |
| `subscribe_instrument_status()` | Real‑time        | `on_instrument_status()` | Live instrument status updates. |
| `subscribe_instrument_close()`  | Real‑time        | `on_instrument_close()`  | Live instrument close updates. |
| `subscribe_order_fills()`       | Real‑time        | `on_order_filled()`      | Live order fill events for an instrument. |
| `request_data()`                | Historical       | `on_historical_data()`   | Historical data processing. |
| `request_instrument()`          | Historical       | `on_instrument()`        | Instrument definition updates. |
| `request_instruments()`         | Historical       | `on_instrument()`        | Instrument definition updates. |
| `request_quote_ticks()`         | Historical       | `on_historical_data()`   | Historical quotes processing. |
| `request_trade_ticks()`         | Historical       | `on_historical_data()`   | Historical trades processing. |
| `request_bars()`                | Historical       | `on_historical_data()`   | Historical bars processing. |
| `request_aggregated_bars()`     | Historical       | `on_historical_data()`   | Historical aggregated bars (on-the-fly). |

### Example

Here's an example demonstrating both historical and real-time data handling:

```python
from nautilus_trader.common.actor import Actor
from nautilus_trader.config import ActorConfig
from nautilus_trader.core.data import Data
from nautilus_trader.model import Bar, BarType
from nautilus_trader.model import ClientId, InstrumentId


class MyActorConfig(ActorConfig):
    instrument_id: InstrumentId  # example value: "AAPL.XNAS"
    bar_type: BarType            # example value: "AAPL.XNAS-1-MINUTE-LAST-EXTERNAL"


class MyActor(Actor):
    def __init__(self, config: MyActorConfig) -> None:
        super().__init__(config)
        self.bar_type = config.bar_type

    def on_start(self) -> None:
        # Request historical data - will be processed by on_historical_data() handler
        self.request_bars(
            bar_type=self.bar_type,
            # Many optional parameters
            start=None,                # datetime, optional
            end=None,                  # datetime, optional
            callback=None,             # called with the request ID when completed
            update_catalog_mode=None,  # UpdateCatalogMode | None, default None
            params=None,               # dict[str, Any], optional
        )

        # Subscribe to real-time data - will be processed by on_bar() handler
        self.subscribe_bars(
            bar_type=self.bar_type,
            # Many optional parameters
            client_id=None,  # ClientId, optional
            params=None,     # dict[str, Any], optional
        )

    def on_historical_data(self, data: Data) -> None:
        # Handle historical data (from requests)
        if isinstance(data, Bar):
            self.log.info(f"Received historical bar: {data}")

    def on_bar(self, bar: Bar) -> None:
        # Handle real-time bar updates (from subscriptions)
        self.log.info(f"Received real-time bar: {bar}")
```

This separation between historical and real-time data handlers allows for different processing logic
based on the data context. For example, you might want to:

- Use historical data to initialize indicators or establish baseline metrics.
- Process real-time data differently for live trading decisions.
- Apply different validation or logging for historical vs real-time data.

:::tip
When debugging data flow issues, check that you're looking at the correct handler for your data source.
If you're not seeing data in `on_bar()` but see log messages about receiving bars, check `on_historical_data()`
as the data might be coming from a request rather than a subscription.
:::

## Order fill subscriptions

Actors can subscribe to order fill events for specific instruments using `subscribe_order_fills()`. This is useful
for monitoring trading activity, implementing custom fill analysis, or tracking execution quality.

When subscribed, all order fills for the specified instrument are forwarded to the `on_order_filled()` handler,
regardless of which strategy or component generated the original order.

### Example

```python
from nautilus_trader.common.actor import Actor
from nautilus_trader.config import ActorConfig
from nautilus_trader.model import InstrumentId
from nautilus_trader.model.events import OrderFilled


class MyActorConfig(ActorConfig):
    instrument_id: InstrumentId  # example value: "ETHUSDT-PERP.BINANCE"


class FillMonitorActor(Actor):
    def __init__(self, config: MyActorConfig) -> None:
        super().__init__(config)
        self.fill_count = 0
        self.total_volume = 0.0

    def on_start(self) -> None:
        # Subscribe to all fills for the instrument
        self.subscribe_order_fills(self.config.instrument_id)

    def on_order_filled(self, event: OrderFilled) -> None:
        # Handle order fill events
        self.fill_count += 1
        self.total_volume += float(event.last_qty)

        self.log.info(
            f"Fill received: {event.order_side} {event.last_qty} @ {event.last_px}, "
            f"Total fills: {self.fill_count}, Volume: {self.total_volume}"
        )

    def on_stop(self) -> None:
        # Unsubscribe from fills
        self.unsubscribe_order_fills(self.config.instrument_id)
```

:::note
Order fill subscriptions are message bus-only subscriptions and do not involve the data engine.
The `on_order_filled()` handler will only receive events while the actor is in a running state.
:::

</document_content>
</document>
<document index="1446">
<source>docs/concepts/adapters.md</source>
<document_content>
# Adapters

The NautilusTrader design integrates data providers and/or trading venues
through adapter implementations. These can be found in the top-level `adapters` subpackage.

An integration adapter is *typically* comprised of the following main components:

- `HttpClient`
- `WebSocketClient`
- `InstrumentProvider`
- `DataClient`
- `ExecutionClient`

## Instrument providers

Instrument providers do as their name suggests - instantiating Nautilus
`Instrument` objects by parsing the raw API of the publisher or venue.

The use cases for the instruments available from an `InstrumentProvider` are either:

- Used standalone to discover the instruments available for an integration, using these for research or backtesting purposes
- Used in a `sandbox` or `live` [environment context](architecture.md#environment-contexts) for consumption by actors/strategies

### Research and backtesting

Here is an example of discovering the current instruments for the Binance Futures testnet:

```python
import asyncio
import os

from nautilus_trader.adapters.binance.common.enums import BinanceAccountType
from nautilus_trader.adapters.binance import get_cached_binance_http_client
from nautilus_trader.adapters.binance.futures.providers import BinanceFuturesInstrumentProvider
from nautilus_trader.common.component import LiveClock


clock = LiveClock()
account_type = BinanceAccountType.USDT_FUTURES

client = get_cached_binance_http_client(
    loop=asyncio.get_event_loop(),
    clock=clock,
    account_type=account_type,
    key=os.getenv("BINANCE_FUTURES_TESTNET_API_KEY"),
    secret=os.getenv("BINANCE_FUTURES_TESTNET_API_SECRET"),
    is_testnet=True,
)
await client.connect()

provider = BinanceFuturesInstrumentProvider(
    client=client,
    account_type=BinanceAccountType.USDT_FUTURES,
)

await provider.load_all_async()
```

### Live trading

Each integration is implementation specific, and there are generally two options for the behavior of an `InstrumentProvider` within a `TradingNode` for live trading,
as configured:

- All instruments are automatically loaded on start:

```python
from nautilus_trader.config import InstrumentProviderConfig

InstrumentProviderConfig(load_all=True)
```

- Only those instruments explicitly specified in the configuration are loaded on start:

```python
InstrumentProviderConfig(load_ids=["BTCUSDT-PERP.BINANCE", "ETHUSDT-PERP.BINANCE"])
```

## Data clients

### Requests

An `Actor` or `Strategy` can request custom data from a `DataClient` by sending a `DataRequest`. If the client that receives the
`DataRequest` implements a handler for the request, data will be returned to the `Actor` or `Strategy`.

#### Example

An example of this is a `DataRequest` for an `Instrument`, which the `Actor` class implements (copied below). Any `Actor` or
`Strategy` can call a `request_instrument` method with an `InstrumentId` to request the instrument from a `DataClient`.

In this particular case, the `Actor` implements a separate method `request_instrument`. A similar type of
`DataRequest` could be instantiated and called from anywhere and/or anytime in the actor/strategy code.

A simplified version of `request_instrument` for an actor/strategy is:

```python
# nautilus_trader/common/actor.pyx

cpdef void request_instrument(self, InstrumentId instrument_id, ClientId client_id=None):
    """
    Request `Instrument` data for the given instrument ID.

    Parameters
    ----------
    instrument_id : InstrumentId
        The instrument ID for the request.
    client_id : ClientId, optional
        The specific client ID for the command.
        If ``None`` then will be inferred from the venue in the instrument ID.
    """
    Condition.not_none(instrument_id, "instrument_id")

    cdef RequestInstrument request = RequestInstrument(
        instrument_id=instrument_id,
        start=None,
        end=None,
        client_id=client_id,
        venue=instrument_id.venue,
        callback=self._handle_instrument_response,
        request_id=UUID4(),
        ts_init=self._clock.timestamp_ns(),
        params=None,
    )

    self._send_data_req(request)
```

A simplified version of the request handler implemented in a `LiveMarketDataClient` that will retrieve the data
and send it back to actors/strategies is for example:

```python
# nautilus_trader/live/data_client.py

def request_instrument(self, request: RequestInstrument) -> None:
    self.create_task(self._request_instrument(request))

# nautilus_trader/adapters/binance/data.py

async def _request_instrument(self, request: RequestInstrument) -> None:
    instrument: Instrument | None = self._instrument_provider.find(request.instrument_id)

    if instrument is None:
        self._log.error(f"Cannot find instrument for {request.instrument_id}")
        return

    self._handle_instrument(instrument, request.id, request.params)
```

The `DataEngine` which is an important component in Nautilus links a request with a `DataClient`.
For example a simplified version of handling an instrument request is:

```python
# nautilus_trader/data/engine.pyx

self._msgbus.register(endpoint="DataEngine.request", handler=self.request)

cpdef void request(self, RequestData request):
    self._handle_request(request)

cpdef void _handle_request(self, RequestData request):
    cdef DataClient client = self._clients.get(request.client_id)

    if client is None:
        client = self._routing_map.get(request.venue, self._default_client)

    if isinstance(request, RequestInstrument):
        self._handle_request_instrument(client, request)

cpdef void _handle_request_instrument(self, DataClient client, RequestInstrument request):
    client.request_instrument(request)
```

</document_content>
</document>
<document index="1447">
<source>docs/concepts/architecture.md</source>
<document_content>
# Architecture

Welcome to the architectural overview of NautilusTrader.

This guide dives deep into the foundational principles, structures, and designs that underpin
the platform. Whether you're a developer, system architect, or just curious about the inner workings
of NautilusTrader, this section covers:

- The design philosophy that drives decisions and shapes the system's evolution.
- The overarching system architecture providing a bird's-eye view of the entire system framework.
- How the framework is organized to facilitate modularity and maintainability.
- The code structure that ensures readability and scalability.
- A breakdown of component organization and interaction to understand how different parts communicate and collaborate.
- And finally, the implementation techniques that are crucial for performance, reliability, and robustness.

:::note
Throughout the documentation, the term *"Nautilus system boundary"* refers to operations within
the runtime of a single Nautilus node (also known as a "trader instance").
:::

## Design philosophy

The major architectural techniques and design patterns employed by NautilusTrader are:

- [Domain driven design (DDD)](https://en.wikipedia.org/wiki/Domain-driven_design)
- [Event-driven architecture](https://en.wikipedia.org/wiki/Event-driven_programming)
- [Messaging patterns](https://en.wikipedia.org/wiki/Messaging_pattern) (Pub/Sub, Req/Rep, point-to-point)
- [Ports and adapters](https://en.wikipedia.org/wiki/Hexagonal_architecture_(software))
- [Crash-only design](#crash-only-design)

These techniques have been utilized to assist in achieving certain architectural quality attributes.

### Quality attributes

Architectural decisions are often a trade-off between competing priorities. The
below is a list of some of the most important quality attributes which are considered
when making design and architectural decisions, roughly in order of 'weighting'.

- Reliability
- Performance
- Modularity
- Testability
- Maintainability
- Deployability

### Assurance-driven engineering

NautilusTrader is incrementally adopting a high-assurance mindset: critical code
paths should carry executable invariants that verify behaviour matches the
business requirements. Practically this means we:

- Identify the components whose failure has the highest blast radius (core
  domain types, risk and execution flows) and write down their invariants in
  plain language.
- Codify those invariants as executable checks (unit tests, property tests,
  fuzzers, static assertions) that run in CI, keeping the feedback loop light.
- Prefer zero-cost safety techniques built into Rust (ownership, `Result`
  surfaces, `panic = abort`) and add targeted formal tools only where they pay
  for themselves.
- Track “assurance debt” alongside feature work so new integrations extend the
  safety net rather than bypass it.

This approach preserves the platform’s delivery cadence while giving mission
critical flows the additional scrutiny they need.

Further reading: [High Assurance Rust](https://highassurance.rs/).

### Crash-only design

NautilusTrader embraces [crash-only design](https://en.wikipedia.org/wiki/Crash-only_software),
a philosophy where *"the only way to stop the system is to crash it"*, and *"the only way to bring it
up is to recover from a crash"*. This approach simplifies state management and improves reliability
by eliminating the complexity of graceful shutdown code paths that are rarely tested.

Key principles:

- **Single code path** - Recovery from crash is the primary (and only) initialization path, ensuring it is well-tested.
- **No graceful shutdown** - The system does not attempt complex cleanup procedures that may fail or hang.
- **Externalized state** - Critical state is persisted externally (database, message bus) so crashes do not lose data.
- **Fast restart** - The system is designed to restart quickly after a crash, minimizing downtime.
- **Idempotent operations** - Operations are designed to be safely retried after restart.

This design complements the [fail-fast policy](#data-integrity-and-fail-fast-policy), where
unrecoverable errors (data corruption, invariant violations) result in immediate process termination
rather than attempting to continue in a compromised state.

**References:**

- [Crash-Only Software](https://www.usenix.org/conference/hotos-ix/crash-only-software) - Candea & Fox, HotOS 2003 (original research paper)
- [Microreboot—A Technique for Cheap Recovery](https://www.usenix.org/conference/osdi-04/microreboot—-technique-cheap-recovery) - Candea et al., OSDI 2004
- [The properties of crash-only software](https://brooker.co.za/blog/2012/01/22/crash-only.html) - Marc Brooker's blog
- [Crash-only software: More than meets the eye](https://lwn.net/Articles/191059/) - LWN.net article
- [Recovery-Oriented Computing (ROC) Project](http://roc.cs.berkeley.edu/) - UC Berkeley/Stanford research

### Data integrity and fail-fast policy

NautilusTrader prioritizes data integrity over availability for trading operations. The system employs
a strict fail-fast policy for arithmetic operations and data handling to prevent silent data corruption
that could lead to incorrect trading decisions.

#### Fail-fast principles

The system will fail fast (panic or return an error) when encountering:

- Arithmetic overflow or underflow in operations on timestamps, prices, or quantities that exceed valid ranges.
- Invalid data during deserialization including NaN, Infinity, or out-of-range values in market data or configuration.
- Type conversion failures such as negative values where only positive values are valid (timestamps, quantities).
- Malformed input parsing for prices, timestamps, or precision values.

Rationale:

In trading systems, corrupt data is worse than no data. A single incorrect price, timestamp, or quantity
can cascade through the system, resulting in:

- Incorrect position sizing or risk calculations.
- Orders placed at wrong prices.
- Backtests producing misleading results.
- Silent financial losses.

By crashing immediately on invalid data, NautilusTrader ensures:

1. **No silent corruption** - Invalid data never propagates through the system.
2. **Immediate feedback** - Issues are discovered during development and testing, not in production.
3. **Audit trail** - Crash logs clearly identify the source of invalid data.
4. **Deterministic behavior** - The same invalid input always produces the same failure.

#### When fail-fast applies

Panics are used for:

- Programmer errors (logic bugs, incorrect API usage).
- Data that violates fundamental invariants (negative timestamps, NaN prices).
- Arithmetic that would silently produce incorrect results.

Results or Options are used for:

- Expected runtime failures (network errors, file I/O).
- Business logic validation (order constraints, risk limits).
- User input validation.
- Library APIs exposed to downstream crates where callers need explicit error handling without relying on panics for control flow.

#### Example scenarios

```rust
// CORRECT: Panics on overflow - prevents data corruption
let total_ns = timestamp1 + timestamp2; // Panics if result > u64::MAX

// CORRECT: Rejects NaN during deserialization
let price = serde_json::from_str("NaN"); // Error: "must be finite"

// CORRECT: Explicit overflow handling when needed
let total_ns = timestamp1.checked_add(timestamp2)?; // Returns Option<UnixNanos>
```

This policy is implemented throughout the core types (`UnixNanos`, `Price`, `Quantity`, etc.)
and ensures that NautilusTrader maintains the highest standards of data correctness for production trading.

In production deployments, the system is typically configured with `panic = abort` in release builds,
ensuring that any panic results in a clean process termination that can be handled by process supervisors
or orchestration systems. This aligns with the [crash-only design](#crash-only-design) principle, where unrecoverable errors
lead to immediate restart rather than attempting to continue in a potentially corrupted state.

## System architecture

The NautilusTrader codebase is actually both a framework for composing trading
 systems, and a set of default system implementations which can operate in various
[environment contexts](#environment-contexts).

![Architecture](https://github.com/nautechsystems/nautilus_trader/blob/develop/assets/architecture-overview.png?raw=true "architecture")

### Core components

The platform is built around several key components that work together to provide a comprehensive trading system:

#### `NautilusKernel`

The central orchestration component responsible for:

- Initializing and managing all system components.
- Configuring the messaging infrastructure.
- Maintaining environment-specific behaviors.
- Coordinating shared resources and lifecycle management.
- Providing a unified entry point for system operations.

#### `MessageBus`

The backbone of inter-component communication, implementing:

- **Publish/Subscribe patterns**: For broadcasting events and data to multiple consumers.
- **Request/Response communication**: For operations requiring acknowledgment.
- **Command/Event messaging**: For triggering actions and notifying state changes.
- **Optional state persistence**: Using Redis for durability and restart capabilities.

#### `Cache`

High-performance in-memory storage system that:

- Stores instruments, accounts, orders, positions, and more.
- Provides performant fetching capabilities for trading components.
- Maintains consist state across the system.
- Supports both read and write operations with optimized access patterns.

#### `DataEngine`

Processes and routes market data throughout the system:

- Handles multiple data types (quotes, trades, bars, order books, custom data, and more).
- Routes data to appropriate consumers based on subscriptions.
- Manages data flow from external sources to internal components.

#### `ExecutionEngine`

Manages order lifecycle and execution:

- Routes trading commands to the appropriate adapter clients.
- Tracks order and position states.
- Coordinates with risk management systems.
- Handles execution reports and fills from venues.
- Handles reconciliation of external execution state.

#### `RiskEngine`

Provides comprehensive risk management:

- Pre-trade risk checks and validation.
- Position and exposure monitoring.
- Real-time risk calculations.
- Configurable risk rules and limits.

### Environment contexts

An environment context in NautilusTrader defines the type of data and trading venue you are working
with. Understanding these contexts is crucial for effective backtesting, development, and live trading.

Here are the available environments you can work with:

- `Backtest`: Historical data with simulated venues.
- `Sandbox`: Real-time data with simulated venues.
- `Live`: Real-time data with live venues (paper trading or real accounts).

### Common core

The platform has been designed to share as much common code between backtest, sandbox and live trading systems as possible.
This is formalized in the `system` subpackage, where you will find the `NautilusKernel` class,
providing a common core system 'kernel'.

The *ports and adapters* architectural style enables modular components to be integrated into the
core system, providing various hooks for user-defined or custom component implementations.

### Data and execution flow patterns

Understanding how data and execution flow through the system is crucial for effective use of the platform:

#### Data flow pattern

1. **External Data Ingestion**: Market data enters via venue-specific `DataClient` adapters where it is normalized.
2. **Data Processing**: The `DataEngine` handles data processing for internal components.
3. **Caching**: Processed data is stored in the high-performance `Cache` for fast access.
4. **Event Publishing**: Data events are published to the `MessageBus`.
5. **Consumer Delivery**: Subscribed components (Actors, Strategies) receive relevant data events.

#### Execution flow pattern

1. **Command Generation**: User strategies create trading commands.
2. **Command Publishing**: Commands are sent through the `MessageBus`.
3. **Risk Validation**: The `RiskEngine` validates trading commands against configured risk rules.
4. **Execution Routing**: The `ExecutionEngine` routes commands to appropriate venues.
5. **External Submission**: The `ExecutionClient` submits orders to external trading venues.
6. **Event Flow Back**: Order events (fills, cancellations) flow back through the system.
7. **State Updates**: Portfolio and position states are updated based on execution events.

#### Component state management

All components follow a finite state machine pattern with well-defined states:

- **PRE_INITIALIZED**: Component is created but not yet wired up to the system.
- **READY**: Component is configured and wired up, but not yet running.
- **RUNNING**: Component is actively processing messages and performing operations.
- **STOPPED**: Component has been gracefully stopped and is no longer processing.
- **DEGRADED**: Component is running but with reduced functionality due to errors.
- **FAULTED**: Component has encountered a critical error and cannot continue.
- **DISPOSED**: Component has been cleaned up and resources have been released.

### Messaging

To facilitate modularity and loose coupling, an extremely efficient `MessageBus` passes messages (data, commands and events) between components.

From a high level architectural view, it's important to understand that the platform has been designed to run efficiently
on a single thread, for both backtesting and live trading. Much research and testing
resulted in arriving at this design, as it was found the overhead of context switching between threads
didn't actually result in improved performance.

When considering the logic of how your algo trading will work within the system boundary, you can expect each component to consume messages
in a deterministic synchronous way (*similar* to the [actor model](https://en.wikipedia.org/wiki/Actor_model)).

:::note
Of interest is the LMAX exchange architecture, which achieves award winning performance running on
a single thread. You can read about their *disruptor* pattern based architecture in [this interesting article](https://martinfowler.com/articles/lmax.html) by Martin Fowler.
:::

## Framework organization

The codebase is organized with a layering of abstraction levels, and generally
grouped into logical subpackages of cohesive concepts. You can navigate to the documentation
for each of these subpackages from the left nav menu.

### Core / low-Level

- `core`: Constants, functions and low-level components used throughout the framework.
- `common`: Common parts for assembling the frameworks various components.
- `network`: Low-level base components for networking clients.
- `serialization`: Serialization base components and serializer implementations.
- `model`: Defines a rich trading domain model.

### Components

- `accounting`: Different account types and account management machinery.
- `adapters`: Integration adapters for the platform including brokers and exchanges.
- `analysis`: Components relating to trading performance statistics and analysis.
- `cache`: Provides common caching infrastructure.
- `data`: The data stack and data tooling for the platform.
- `execution`: The execution stack for the platform.
- `indicators`: A set of efficient indicators and analyzers.
- `persistence`: Data storage, cataloging and retrieval, mainly to support backtesting.
- `portfolio`: Portfolio management functionality.
- `risk`: Risk specific components and tooling.
- `trading`: Trading domain specific components and tooling.

### System implementations

- `backtest`: Backtesting componentry as well as a backtest engine and node implementations.
- `live`: Live engine and client implementations as well as a node for live trading.
- `system`: The core system kernel common between `backtest`, `sandbox`, `live` [environment contexts](#environment-contexts).

## Code structure

The foundation of the codebase is the `crates` directory, containing a collection of Rust crates including a C foreign function interface (FFI) generated by `cbindgen`.

The bulk of the production code resides in the `nautilus_trader` directory, which contains a collection of Python/Cython subpackages and modules.

Python bindings for the Rust core are provided by statically linking the Rust libraries to the C extension modules generated by Cython at compile time (effectively extending the CPython API).

### Dependency flow

```
┌─────────────────────────┐
│                         │
│                         │
│     nautilus_trader     │
│                         │
│     Python / Cython     │
│                         │
│                         │
└────────────┬────────────┘
 C API       │
             │
             │
             │
 C API       ▼
┌─────────────────────────┐
│                         │
│                         │
│      nautilus_core      │
│                         │
│          Rust           │
│                         │
│                         │
└─────────────────────────┘
```

:::note
Both Rust and Cython are build dependencies. The binary wheels produced from a build do not require
Rust or Cython to be installed at runtime.
:::

### Type safety

The design of the platform prioritizes software correctness and safety at the highest level.

The Rust codebase in `nautilus_core` is always type safe and memory safe as guaranteed by the `rustc` compiler,
and so is *correct by construction* (unless explicitly marked `unsafe`, see the Rust section of the [Developer Guide](../developer_guide/rust.md)).

Cython provides type safety at the C level at both compile time, and runtime:

:::info
If you pass an argument with an invalid type to a Cython implemented module with typed parameters,
then you will receive a `TypeError` at runtime.
:::

If a function or method's parameter is not explicitly typed to accept `None`, passing `None` as an
argument will result in a `ValueError` at runtime.

:::warning
The above exceptions are not explicitly documented to prevent excessive bloating of the docstrings.
:::

### Errors and exceptions

Every attempt has been made to accurately document the possible exceptions which
can be raised from NautilusTrader code, and the conditions which will trigger them.

:::warning
There may be other undocumented exceptions which can be raised by Python's standard
library, or from third party library dependencies.
:::

### Processes and threads

:::warning **One node per process**
Running multiple `TradingNode` or `BacktestNode` instances **concurrently** in the same process is not supported due to global singleton state:

- **Backtest force-stop flag** - The `_FORCE_STOP` global flag is shared across all engines in the process.
- **Logger mode and timestamps** - The logging subsystem uses global state; backtests flip between static and real-time modes.
- **Runtime singletons** - Global Tokio runtime, callback registries, and other `OnceLock` instances are process-wide.

**Sequential execution** of multiple nodes (one after another with proper disposal between runs) is fully supported and used in the test suite.

For production deployments, add multiple strategies to a **single TradingNode** within a process.
For parallel execution or workload isolation, run each node in its own separate process.
:::

</document_content>
</document>
<document index="1448">
<source>docs/concepts/cache.md</source>
<document_content>
# Cache

The `Cache` is a central in-memory database that automatically stores and manages all trading-related data.
Think of it as your trading system’s memory – storing everything from market data to order history to custom calculations.

The Cache serves multiple key purposes:

1. **Stores market data**:
   - Stores recent market history (e.g., order books, quotes, trades, bars).
   - Gives you access to both current and historical market data for your strategy.

2. **Tracks trading data**:
   - Maintains complete `Order` history and current execution state.
   - Tracks all `Position`s and `Account` information.
   - Stores `Instrument` definitions and `Currency` information.

3. **Stores custom data**:
   - You can store any user-defined objects or data in the `Cache` for later use.
   - Enables data sharing between different strategies.

## How caching works

**Built-in types**:

- The system automatically adds data to the `Cache` as it flows through.
- In live contexts, the engine applies updates asynchronously, so you might see a brief delay between an event and its appearance in the `Cache`.
- All data flows through the `Cache` before reaching your strategy’s callbacks – see the diagram below:

```
┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐     ┌───────────────────────┐
│                 │     │                 │     │                 │     │                       │
│                 │     │                 │     │                 │     │   Strategy callback:  │
│      Data       ├─────►   DataEngine    ├─────►     Cache       ├─────►                       │
│                 │     │                 │     │                 │     │   on_data(...)        │
│                 │     │                 │     │                 │     │                       │
└─────────────────┘     └─────────────────┘     └─────────────────┘     └───────────────────────┘
```

### Basic example

Within a strategy, you can access the `Cache` through `self.cache`. Here’s a typical example:

:::note
Anywhere you find `self`, it refers mostly to the `Strategy` itself.
:::

```python
def on_bar(self, bar: Bar) -> None:
    # Current bar is provided in the parameter 'bar'

    # Get historical bars from Cache
    last_bar = self.cache.bar(self.bar_type, index=0)        # Last bar (practically the same as the 'bar' parameter)
    previous_bar = self.cache.bar(self.bar_type, index=1)    # Previous bar
    third_last_bar = self.cache.bar(self.bar_type, index=2)  # Third last bar

    # Get current position information
    if self.last_position_opened_id is not None:
        position = self.cache.position(self.last_position_opened_id)
        if position.is_open:
            # Check position details
            current_pnl = position.unrealized_pnl

    # Get all open orders for our instrument
    open_orders = self.cache.orders_open(instrument_id=self.instrument_id)
```

## Configuration

Use the `CacheConfig` class to configure the `Cache` behavior and capacity.
You can provide this configuration either to a `BacktestEngine` or a `TradingNode`, depending on your [environment context](architecture.md#environment-contexts).

Here's a basic example of configuring the `Cache`:

```python
from nautilus_trader.config import CacheConfig, BacktestEngineConfig, TradingNodeConfig

# For backtesting
engine_config = BacktestEngineConfig(
    cache=CacheConfig(
        tick_capacity=10_000,  # Store last 10,000 ticks per instrument
        bar_capacity=5_000,    # Store last 5,000 bars per bar type
    ),
)

# For live trading
node_config = TradingNodeConfig(
    cache=CacheConfig(
        tick_capacity=10_000,
        bar_capacity=5_000,
    ),
)
```

:::tip
By default, the `Cache` keeps the last 10,000 bars for each bar type and 10,000 trade ticks per instrument.
These limits provide a good balance between memory usage and data availability. Increase them if your strategy needs more historical data.
:::

### Configuration options

The `CacheConfig` class supports these parameters:

```python
from nautilus_trader.config import CacheConfig

cache_config = CacheConfig(
    database: DatabaseConfig | None = None,  # Database configuration for persistence
    encoding: str = "msgpack",               # Data encoding format ('msgpack' or 'json')
    timestamps_as_iso8601: bool = False,     # Store timestamps as ISO8601 strings
    buffer_interval_ms: int | None = None,   # Buffer interval for batch operations
    use_trader_prefix: bool = True,          # Use trader prefix in keys
    use_instance_id: bool = False,           # Include instance ID in keys
    flush_on_start: bool = False,            # Clear database on startup
    drop_instruments_on_reset: bool = True,  # Clear instruments on reset
    tick_capacity: int = 10_000,             # Maximum ticks stored per instrument
    bar_capacity: int = 10_000,              # Maximum bars stored per each bar-type
)
```

:::note
Each bar type maintains its own separate capacity. For example, if you're using both 1-minute and 5-minute bars, each stores up to `bar_capacity` bars.
When `bar_capacity` is reached, the `Cache` automatically removes the oldest data.
:::

### Database configuration

For persistence between system restarts, you can configure a database backend.

When is it useful to use persistence?

- **Long-running systems**: If you want your data to survive system restarts, upgrading, or unexpected failures, having a database configuration helps to pick up exactly where you left off.
- **Historical insights**: When you need to preserve past trading data for detailed post-analysis or audits.
- **Multi-node or distributed setups**: If multiple services or nodes need to access the same state, a persistent store helps ensure shared and consistent data.

```python
from nautilus_trader.config import DatabaseConfig

config = CacheConfig(
    database=DatabaseConfig(
        type="redis",      # Database type
        host="localhost",  # Database host
        port=6379,         # Database port
        timeout=2,         # Connection timeout (seconds)
    ),
)
```

## Using the cache

### Accessing market data

The `Cache` provides a comprehensive interface for accessing order books, quotes, trades, and bars.
All market data in the cache uses reverse indexing, so the most recent entry sits at index 0.

#### Bar access

```python
# Get a list of all cached bars for a bar type
bars = self.cache.bars(bar_type)  # Returns list[Bar] or an empty list if no bars found

# Get the most recent bar
latest_bar = self.cache.bar(bar_type)  # Returns Bar or None if no such object exists

# Get a specific historical bar by index (0 = most recent)
second_last_bar = self.cache.bar(bar_type, index=1)  # Returns Bar or None if no such object exists

# Check if bars exist and get count
bar_count = self.cache.bar_count(bar_type)  # Returns number of bars in cache for the specified bar type
has_bars = self.cache.has_bars(bar_type)    # Returns bool indicating if any bars exist for the specified bar type
```

#### Quote ticks

```python
# Get quotes
quotes = self.cache.quote_ticks(instrument_id)                     # Returns list[QuoteTick] or an empty list if no quotes found
latest_quote = self.cache.quote_tick(instrument_id)                # Returns QuoteTick or None if no such object exists
second_last_quote = self.cache.quote_tick(instrument_id, index=1)  # Returns QuoteTick or None if no such object exists

# Check quote availability
quote_count = self.cache.quote_tick_count(instrument_id)  # Returns the number of quotes in cache for this instrument
has_quotes = self.cache.has_quote_ticks(instrument_id)    # Returns bool indicating if any quotes exist for this instrument
```

#### Trade ticks

```python
# Get trades
trades = self.cache.trade_ticks(instrument_id)         # Returns list[TradeTick] or an empty list if no trades found
latest_trade = self.cache.trade_tick(instrument_id)    # Returns TradeTick or None if no such object exists
second_last_trade = self.cache.trade_tick(instrument_id, index=1)  # Returns TradeTick or None if no such object exists

# Check trade availability
trade_count = self.cache.trade_tick_count(instrument_id)  # Returns the number of trades in cache for this instrument
has_trades = self.cache.has_trade_ticks(instrument_id)    # Returns bool indicating if any trades exist
```

#### Order book

```python
# Get current order book
book = self.cache.order_book(instrument_id)  # Returns OrderBook or None if no such object exists

# Check if order book exists
has_book = self.cache.has_order_book(instrument_id)  # Returns bool indicating if an order book exists

# Get count of order book updates
update_count = self.cache.book_update_count(instrument_id)  # Returns the number of updates received
```

#### Price access

```python
from nautilus_trader.core.rust.model import PriceType

# Get current price by type; Returns Price or None.
price = self.cache.price(
    instrument_id=instrument_id,
    price_type=PriceType.MID,  # Options: BID, ASK, MID, LAST
)
```

#### Bar types

```python
from nautilus_trader.core.rust.model import PriceType, AggregationSource

# Get all available bar types for an instrument; Returns list[BarType].
bar_types = self.cache.bar_types(
    instrument_id=instrument_id,
    price_type=PriceType.LAST,  # Options: BID, ASK, MID, LAST
    aggregation_source=AggregationSource.EXTERNAL,
)
```

#### Simple example

```python
class MarketDataStrategy(Strategy):
    def on_start(self):
        # Subscribe to 1-minute bars
        self.bar_type = BarType.from_str(f"{self.instrument_id}-1-MINUTE-LAST-EXTERNAL")  # example of instrument_id = "EUR/USD.FXCM"
        self.subscribe_bars(self.bar_type)

    def on_bar(self, bar: Bar) -> None:
        bars = self.cache.bars(self.bar_type)[:3]
        if len(bars) < 3:   # Wait until we have at least 3 bars
            return

        # Access last 3 bars for analysis
        current_bar = bars[0]    # Most recent bar
        prev_bar = bars[1]       # Second to last bar
        prev_prev_bar = bars[2]  # Third to last bar

        # Get latest quote and trade
        latest_quote = self.cache.quote_tick(self.instrument_id)
        latest_trade = self.cache.trade_tick(self.instrument_id)

        if latest_quote is not None:
            current_spread = latest_quote.ask_price - latest_quote.bid_price
            self.log.info(f"Current spread: {current_spread}")
```

### Trading objects

The `Cache` provides comprehensive access to all trading objects within the system, including:

- Orders
- Positions
- Accounts
- Instruments

#### Orders

You can access and query orders through multiple methods, with flexible filtering options by venue, strategy, instrument, and order side.

##### Basic order access

```python
# Get a specific order by its client order ID
order = self.cache.order(ClientOrderId("O-123"))

# Get all orders in the system
orders = self.cache.orders()

# Get orders filtered by specific criteria
orders_for_venue = self.cache.orders(venue=venue)                       # All orders for a specific venue
orders_for_strategy = self.cache.orders(strategy_id=strategy_id)        # All orders for a specific strategy
orders_for_instrument = self.cache.orders(instrument_id=instrument_id)  # All orders for an instrument
```

##### Order state queries

```python
# Get orders by their current state
open_orders = self.cache.orders_open()          # Orders currently active at the venue
closed_orders = self.cache.orders_closed()      # Orders that have completed their lifecycle
emulated_orders = self.cache.orders_emulated()  # Orders being simulated locally by the system
inflight_orders = self.cache.orders_inflight()  # Orders submitted (or modified) to venue, but not yet confirmed

# Check specific order states
exists = self.cache.order_exists(client_order_id)            # Checks if an order with the given ID exists in the cache
is_open = self.cache.is_order_open(client_order_id)          # Checks if an order is currently open
is_closed = self.cache.is_order_closed(client_order_id)      # Checks if an order is closed
is_emulated = self.cache.is_order_emulated(client_order_id)  # Checks if an order is being simulated locally
is_inflight = self.cache.is_order_inflight(client_order_id)  # Checks if an order is submitted or modified, but not yet confirmed
```

##### Order statistics

```python
# Get counts of orders in different states
open_count = self.cache.orders_open_count()          # Number of open orders
closed_count = self.cache.orders_closed_count()      # Number of closed orders
emulated_count = self.cache.orders_emulated_count()  # Number of emulated orders
inflight_count = self.cache.orders_inflight_count()  # Number of inflight orders
total_count = self.cache.orders_total_count()        # Total number of orders in the system

# Get filtered order counts
buy_orders_count = self.cache.orders_open_count(side=OrderSide.BUY)  # Number of currently open BUY orders
venue_orders_count = self.cache.orders_total_count(venue=venue)      # Total number of orders for a given venue
```

#### Positions

The `Cache` maintains a record of all positions and offers several ways to query them.

##### Position access

```python
# Get a specific position by its ID
position = self.cache.position(PositionId("P-123"))

# Get positions by their state
all_positions = self.cache.positions()            # All positions in the system
open_positions = self.cache.positions_open()      # All currently open positions
closed_positions = self.cache.positions_closed()  # All closed positions

# Get positions filtered by various criteria
venue_positions = self.cache.positions(venue=venue)                       # Positions for a specific venue
instrument_positions = self.cache.positions(instrument_id=instrument_id)  # Positions for a specific instrument
strategy_positions = self.cache.positions(strategy_id=strategy_id)        # Positions for a specific strategy
long_positions = self.cache.positions(side=PositionSide.LONG)             # All long positions
```

##### Position state queries

```python
# Check position states
exists = self.cache.position_exists(position_id)        # Checks if a position with the given ID exists
is_open = self.cache.is_position_open(position_id)      # Checks if a position is open
is_closed = self.cache.is_position_closed(position_id)  # Checks if a position is closed

# Get position and order relationships
orders = self.cache.orders_for_position(position_id)       # All orders related to a specific position
position = self.cache.position_for_order(client_order_id)  # Find the position associated with a specific order
```

##### Position statistics

```python
# Get position counts in different states
open_count = self.cache.positions_open_count()      # Number of currently open positions
closed_count = self.cache.positions_closed_count()  # Number of closed positions
total_count = self.cache.positions_total_count()    # Total number of positions in the system

# Get filtered position counts
long_positions_count = self.cache.positions_open_count(side=PositionSide.LONG)              # Number of open long positions
instrument_positions_count = self.cache.positions_total_count(instrument_id=instrument_id)  # Number of positions for a given instrument
```

#### Accounts

```python
# Access account information
account = self.cache.account(account_id)       # Retrieve account by ID
account = self.cache.account_for_venue(venue)  # Retrieve account for a specific venue
account_id = self.cache.account_id(venue)      # Retrieve account ID for a venue
accounts = self.cache.accounts()               # Retrieve all accounts in the cache
```

#### Purging cached state

The cache exposes explicit maintenance hooks that remove closed or stale objects while preserving safety checks:

- `purge_closed_orders(ts_now, buffer_secs=0, purge_from_database=False)` drops closed orders that have been inactive for at least `buffer_secs`. Linked contingency orders remain until every dependent child is closed.
- `purge_closed_positions(ts_now, buffer_secs=0, purge_from_database=False)` removes positions that have stayed closed beyond the buffer window and deletes associated indices.
- `purge_account_events(ts_now, lookback_secs=0, purge_from_database=False)` trims account event history outside the lookback window and can cascade deletes to the backing database.

Key safeguards:

- Open orders and positions are never purged; the cache logs a warning and leaves the item intact.
- Linked orders keep parents in the cache until all children have closed, preventing premature removal of contingency chains.
- Indices and reverse lookups are cleaned alongside the primary object to avoid dangling references.
- Database deletions occur only when `purge_from_database=True` and a cache database is configured, ensuring in-memory purges do not silently erase persisted data.

Use the trading clock (for example, `self.clock.timestamp_ns()`) when supplying `ts_now`. Set `purge_from_database=True` only when you intend to delete persisted records from Redis or PostgreSQL as well. In live trading these methods run automatically when the execution engine is configured with purge intervals; see [Memory management](live.md#memory-management) for the scheduler settings.

#### Instruments and currencies

##### Instruments

```python
# Get instrument information
instrument = self.cache.instrument(instrument_id) # Retrieve a specific instrument by its ID
all_instruments = self.cache.instruments()        # Retrieve all instruments in the cache

# Get filtered instruments
venue_instruments = self.cache.instruments(venue=venue)              # Instruments for a specific venue
instruments_by_underlying = self.cache.instruments(underlying="ES")  # Instruments by underlying

# Get instrument identifiers
instrument_ids = self.cache.instrument_ids()                   # Get all instrument IDs
venue_instrument_ids = self.cache.instrument_ids(venue=venue)  # Get instrument IDs for a specific venue
```

##### Currencies

```python
# Get currency information
currency = self.cache.load_currency("USD")  # Loads currency data for USD
```

---

### Custom data

The `Cache` can also store and retrieve custom data types in addition to built-in market data and trading objects.
Use it to share any user-defined data between system components, primarily actors and strategies.

#### Basic storage and retrieval

```python
# Call this code inside Strategy methods (`self` refers to Strategy)

# Store data
self.cache.add(key="my_key", value=b"some binary data")

# Retrieve data
stored_data = self.cache.get("my_key")  # Returns bytes or None
```

For more complex use cases, the `Cache` can store custom data objects that inherit from the `nautilus_trader.core.Data` base class.

:::warning
The `Cache` is not designed to be a full database replacement. For large datasets or complex querying needs, consider using a dedicated database system.
:::

## Best practices and common questions

### Cache vs. portfolio usage

The `Cache` and `Portfolio` components serve different but complementary purposes in NautilusTrader:

**Cache**:

- Maintains the historical knowledge and current state of the trading system.
- Updates immediately when local state changes (for example, initializing an order before submission).
- Updates asynchronously as external events occur (for example, when an order fills).
- Provides a complete history of trading activity and market data.
- Keeps every event the strategy receives in the cache.

**Portfolio**:

- Aggregates position, exposure, and account information.
- Provides current state without history.

**Example**:

```python
class MyStrategy(Strategy):
    def on_position_changed(self, event: PositionEvent) -> None:
        # Use Cache when you need historical perspective
        position_history = self.cache.position_snapshots(event.position_id)

        # Use Portfolio when you need current real-time state
        current_exposure = self.portfolio.net_exposure(event.instrument_id)
```

### Cache vs. strategy variables

Choosing between storing data in the `Cache` versus strategy variables depends on your specific needs:

**Cache storage**:

- Use for data that needs to be shared between strategies.
- Best for data that needs to persist between system restarts.
- Acts as a central database accessible to all components.
- Ideal for state that needs to survive strategy resets.

**Strategy variables**:

- Use for strategy-specific calculations.
- Better for temporary values and intermediate results.
- Provides faster access and better encapsulation.
- Best for data that only your strategy needs.

**Example**:

The following example shows how you might store data in the `Cache` so multiple strategies can access the same information.

```python
import pickle

class MyStrategy(Strategy):
    def on_start(self):
        # Prepare data you want to share with other strategies
        shared_data = {
            "last_reset": self.clock.timestamp_ns(),
            "trading_enabled": True,
            # Include any other fields that you want other strategies to read
        }

        # Store it in the cache with a descriptive key
        # This way, multiple strategies can call self.cache.get("shared_strategy_info")
        # to retrieve the same data
        self.cache.add("shared_strategy_info", pickle.dumps(shared_data))

```

Another strategy can retrieve the cached data as follows:

```python
import pickle

class AnotherStrategy(Strategy):
    def on_start(self):
        # Load the shared data from the same key
        data_bytes = self.cache.get("shared_strategy_info")
        if data_bytes is not None:
            shared_data = pickle.loads(data_bytes)
            self.log.info(f"Shared data retrieved: {shared_data}")
```

</document_content>
</document>
<document index="1449">
<source>docs/concepts/execution.md</source>
<document_content>
# Execution

NautilusTrader can handle trade execution and order management for multiple strategies and venues
simultaneously (per instance). Several interacting components are involved in execution, making it
crucial to understand the possible flows of execution messages (commands and events).

The main execution-related components include:

- `Strategy`
- `ExecAlgorithm` (execution algorithms)
- `OrderEmulator`
- `RiskEngine`
- `ExecutionEngine` or `LiveExecutionEngine`
- `ExecutionClient` or `LiveExecutionClient`

## Execution flow

The `Strategy` base class inherits from `Actor` and so contains all of the common data related
methods. It also provides methods for managing orders and trade execution:

- `submit_order(...)`
- `submit_order_list(...)`
- `modify_order(...)`
- `cancel_order(...)`
- `cancel_orders(...)`
- `cancel_all_orders(...)`
- `close_position(...)`
- `close_all_positions(...)`
- `query_account(...)`
- `query_order(...)`

These methods create the necessary execution commands under the hood and send them on the message
bus to the relevant components (point-to-point), as well as publishing any events (such as the
initialization of new orders i.e. `OrderInitialized` events).

The general execution flow looks like the following (each arrow indicates movement across the message bus):

`Strategy` -> `OrderEmulator` -> `ExecAlgorithm` -> `RiskEngine` -> `ExecutionEngine` -> `ExecutionClient`

The `OrderEmulator` and `ExecAlgorithm`(s) components are optional in the flow, depending on
individual order parameters (as explained below).

This diagram illustrates message flow (commands and events) across the Nautilus execution components.

```
                  ┌───────────────────┐
                  │                   │
                  │                   │
                  │                   │
          ┌───────►   OrderEmulator   ├────────────┐
          │       │                   │            │
          │       │                   │            │
          │       │                   │            │
┌─────────┴──┐    └─────▲──────┬──────┘            │
│            │          │      │           ┌───────▼────────┐   ┌─────────────────────┐   ┌─────────────────────┐
│            │          │      │           │                │   │                     │   │                     │
│            ├──────────┼──────┼───────────►                ├───►                     ├───►                     │
│  Strategy  │          │      │           │                │   │                     │   │                     │
│            │          │      │           │   RiskEngine   │   │   ExecutionEngine   │   │   ExecutionClient   │
│            ◄──────────┼──────┼───────────┤                ◄───┤                     ◄───┤                     │
│            │          │      │           │                │   │                     │   │                     │
│            │          │      │           │                │   │                     │   │                     │
└─────────┬──┘    ┌─────┴──────▼──────┐    └───────▲────────┘   └─────────────────────┘   └─────────────────────┘
          │       │                   │            │
          │       │                   │            │
          │       │                   │            │
          └───────►   ExecAlgorithm   ├────────────┘
                  │                   │
                  │                   │
                  │                   │
                  └───────────────────┘

```

## Order Management System (OMS)

An order management system (OMS) type refers to the method used for assigning orders to positions and tracking those positions for an instrument.
OMS types apply to both strategies and venues (simulated and real). Even if a venue doesn't explicitly
state the method in use, an OMS type is always in effect. The OMS type for a component can be specified
using the `OmsType` enum.

The `OmsType` enum has three variants:

- `UNSPECIFIED`: The OMS type defaults based on where it is applied (details below)
- `NETTING`: Positions are combined into a single position per instrument ID
- `HEDGING`: Multiple positions per instrument ID are supported (both long and short)

The table below describes different configuration combinations and their applicable scenarios.
When the strategy and venue OMS types differ, the `ExecutionEngine` handles this by overriding or assigning `position_id` values for received `OrderFilled` events.
A "virtual position" refers to a position ID that exists within the Nautilus system but not on the venue in
reality.

| Strategy OMS                 | Venue OMS              | Description                                                                                                                                                |
|:-----------------------------|:-----------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------|
| `NETTING`                    | `NETTING`              | The strategy uses the venues native OMS type, with a single position ID per instrument ID.                                                                 |
| `HEDGING`                    | `HEDGING`              | The strategy uses the venues native OMS type, with multiple position IDs per instrument ID (both `LONG` and `SHORT`).                                      |
| `NETTING`                    | `HEDGING`              | The strategy **overrides** the venues native OMS type. The venue tracks multiple positions per instrument ID, but Nautilus maintains a single position ID. |
| `HEDGING`                    | `NETTING`              | The strategy **overrides** the venues native OMS type. The venue tracks a single position per instrument ID, but Nautilus maintains multiple position IDs. |

:::note
Configuring OMS types separately for strategies and venues increases platform complexity but allows
for a wide range of trading styles and preferences (see below).
:::

OMS config examples:

- Most cryptocurrency exchanges use a `NETTING` OMS type, representing a single position per market. It may be desirable for a trader to track multiple "virtual" positions for a strategy.
- Some FX ECNs or brokers use a `HEDGING` OMS type, tracking multiple positions both `LONG` and `SHORT`. The trader may only care about the NET position per currency pair.

:::info
Nautilus does not yet support venue-side hedging modes such as Binance `BOTH` vs. `LONG/SHORT` where the venue nets per direction.
It is advised to keep Binance account configurations as `BOTH` so that a single position is netted.
:::

### OMS configuration

If a strategy OMS type is not explicitly set using the `oms_type` configuration option,
it will default to `UNSPECIFIED`. This means the `ExecutionEngine` will not override any venue `position_id`s,
and the OMS type will follow the venue's OMS type.

:::tip
When configuring a backtest, you can specify the `oms_type` for the venue. To enhance backtest
accuracy, it is recommended to match this with the actual OMS type used by the venue in practice.
:::

## Risk engine

The `RiskEngine` is a core component of every Nautilus system, including backtest, sandbox, and live environments.
Every order command and event passes through the `RiskEngine` unless specifically bypassed in the `RiskEngineConfig`.

The `RiskEngine` includes several built-in pre-trade risk checks, including:

- Price precisions correct for the instrument.
- Prices are positive (unless an option type instrument)
- Quantity precisions correct for the instrument.
- Below maximum notional for the instrument.
- Within maximum or minimum quantity for the instrument.
- Only reducing position when a `reduce_only` execution instruction is specified for the order.

If any risk check fails, the system generates an `OrderDenied` event, effectively closing the order and
preventing it from progressing further. This event includes a human-readable reason for the denial.

### Trading state

Additionally, the current trading state of a Nautilus system affects order flow.

The `TradingState` enum has three variants:

- `ACTIVE`: Operates normally.
- `HALTED`: Does not process further order commands until state changes.
- `REDUCING`: Only processes cancels or commands that reduce open positions.

:::info
See the `RiskEngineConfig` [API Reference](../api_reference/config#risk) for further details.
:::

## Execution algorithms

The platform supports customized execution algorithm components and provides some built-in
algorithms, such as the Time-Weighted Average Price (TWAP) algorithm.

### TWAP (Time-Weighted Average Price)

The TWAP execution algorithm aims to execute orders by evenly spreading them over a specified
time horizon. The algorithm receives a primary order representing the total size and direction
then splits this by spawning smaller child orders, which are then executed at regular intervals
throughout the time horizon.

This helps to reduce the impact of the full size of the primary order on the market, by
minimizing the concentration of trade size at any given time.

The algorithm will immediately submit the first order, with the final order submitted being the
primary order at the end of the horizon period.

Using the TWAP algorithm as an example (found in ``/examples/algorithms/twap.py``), this example
demonstrates how to initialize and register a TWAP execution algorithm directly with a
`BacktestEngine` (assuming an engine is already initialized):

```python
from nautilus_trader.examples.algorithms.twap import TWAPExecAlgorithm

# `engine` is an initialized BacktestEngine instance
exec_algorithm = TWAPExecAlgorithm()
engine.add_exec_algorithm(exec_algorithm)
```

For this particular algorithm, two parameters must be specified:

- `horizon_secs`
- `interval_secs`

The `horizon_secs` parameter determines the time period over which the algorithm will execute, while
the `interval_secs` parameter sets the time between individual order executions. These parameters
determine how a primary order is split into a series of spawned orders.

```python
from decimal import Decimal
from nautilus_trader.model.data import BarType
from nautilus_trader.test_kit.providers import TestInstrumentProvider
from nautilus_trader.examples.strategies.ema_cross_twap import EMACrossTWAP, EMACrossTWAPConfig

# Configure your strategy
config = EMACrossTWAPConfig(
    instrument_id=TestInstrumentProvider.ethusdt_binance().id,
    bar_type=BarType.from_str("ETHUSDT.BINANCE-250-TICK-LAST-INTERNAL"),
    trade_size=Decimal("0.05"),
    fast_ema_period=10,
    slow_ema_period=20,
    twap_horizon_secs=10.0,   # execution algorithm parameter (total horizon in seconds)
    twap_interval_secs=2.5,    # execution algorithm parameter (seconds between orders)
)

# Instantiate your strategy
strategy = EMACrossTWAP(config=config)
```

Alternatively, you can specify these parameters dynamically per order, determining them based on
actual market conditions. In this case, the strategy configuration parameters could be provided to
an execution model which determines the horizon and interval.

:::info
There is no limit to the number of execution algorithm parameters you can create. The parameters
just need to be a dictionary with string keys and primitive values (values that can be serialized
over the wire, such as ints, floats, and strings).
:::

### Writing execution algorithms

To implement a custom execution algorithm you must define a class which inherits from `ExecAlgorithm`.

An execution algorithm is a type of `Actor`, so it's capable of the following:

- Request and subscribe to data.
- Access the `Cache`.
- Set time alerts and/or timers using a `Clock`.

Additionally it can:

- Access the central `Portfolio`.
- Spawn secondary orders from a received primary (original) order.

Once an execution algorithm is registered, and the system is running, it will receive orders off the
messages bus which are addressed to its `ExecAlgorithmId` via the `exec_algorithm_id` order parameter.
The order may also carry the `exec_algorithm_params` being a `dict[str, Any]`.

:::warning
Because of the flexibility of the `exec_algorithm_params` dictionary. It's important to thoroughly
validate all of the key value pairs for correct operation of the algorithm (for starters that the
dictionary is not ``None`` and all necessary parameters actually exist).
:::

Received orders will arrive via the following `on_order(...)` method. These received orders are
know as "primary" (original) orders when being handled by an execution algorithm.

```python
from nautilus_trader.model.orders.base import Order

def on_order(self, order: Order) -> None:
    # Handle the order here
```

When the algorithm is ready to spawn a secondary order, it can use one of the following methods:

- `spawn_market(...)` (spawns a `MARKET` order)
- `spawn_market_to_limit(...)` (spawns a `MARKET_TO_LIMIT` order)
- `spawn_limit(...)` (spawns a `LIMIT` order)

:::note
Additional order types will be implemented in future versions, as the need arises.
:::

Each of these methods takes the primary (original) `Order` as the first argument. The primary order
quantity will be reduced by the `quantity` passed in (becoming the spawned orders quantity).

:::warning
There must be enough primary order quantity remaining (this is validated).
:::

Once the desired number of secondary orders have been spawned, and the execution routine is over,
the intention is that the algorithm will then finally send the primary (original) order.

### Spawned orders

All secondary orders spawned from an execution algorithm will carry a `exec_spawn_id` which is
simply the `ClientOrderId` of the primary (original) order, and whose `client_order_id`
derives from this original identifier with the following convention:

- `exec_spawn_id` (primary order `client_order_id` value)
- `spawn_sequence` (the sequence number for the spawned order)

```
{exec_spawn_id}-E{spawn_sequence}
```

e.g. `O-20230404-001-000-E1` (for the first spawned order)

:::note
The "primary" and "secondary" / "spawn" terminology was specifically chosen to avoid conflict
or confusion with the "parent" and "child" contingent orders terminology (an execution algorithm may also deal with contingent orders).
:::

### Managing execution algorithm orders

The `Cache` provides several methods to aid in managing (keeping track of) the activity of
an execution algorithm. Calling the below method will return all execution algorithm orders
for the given query filters.

```python
def orders_for_exec_algorithm(
    self,
    exec_algorithm_id: ExecAlgorithmId,
    venue: Venue | None = None,
    instrument_id: InstrumentId | None = None,
    strategy_id: StrategyId | None = None,
    side: OrderSide = OrderSide.NO_ORDER_SIDE,
) -> list[Order]:
```

As well as more specifically querying the orders for a certain execution series/spawn.
Calling the below method will return all orders for the given `exec_spawn_id` (if found).

```python
def orders_for_exec_spawn(self, exec_spawn_id: ClientOrderId) -> list[Order]:
```

:::note
This also includes the primary (original) order.
:::

## Own order books

Own order books are L3 order books that track only your own (user) orders organized by price level, maintained separately from the venue's public order books.

### Purpose

Own order books serve several purposes:

- Monitor the state of your orders within the venue's public book in real-time.
- Validate order placement by checking available liquidity at price levels before submission.
- Help prevent self-trading by identifying price levels where your own orders already exist.
- Support advanced order management strategies that depend on queue position.
- Enable reconciliation between internal state and venue state during live trading.

### Lifecycle

Own order books are maintained per instrument and automatically updated as orders transition through their lifecycle.
Orders are added when submitted or accepted, updated when modified, and removed when filled, canceled, rejected, or expired.

Only orders with prices can be represented in own order books. Market orders and other order types without explicit prices are excluded since they cannot be positioned at specific price levels.

### Safe cancellation queries

When querying own order books for orders to cancel, use a `status` filter that **excludes** `PENDING_CANCEL` to avoid processing orders already being cancelled.

:::warning
Including `PENDING_CANCEL` in status filters can cause:

- Duplicate cancel attempts on the same order.
- Inflated open order counts (orders in `PENDING_CANCEL` remain "open" until confirmed canceled).
- Order state explosion when multiple strategies attempt to cancel the same orders.

:::

The optional `accepted_buffer_ns` many methods expose is a time-based guard that only returns orders whose `ts_accepted` is at least that many nanoseconds in the past. Orders that have not yet been accepted by the venue still have `ts_accepted = 0`, so they are included once the buffer window elapses. To exclude those inflight orders you must pair the buffer with an explicit status filter (for example, restrict to `ACCEPTED` / `PARTIALLY_FILLED`).

### Auditing

During live trading, own order books can be periodically audited against the cache's order indexes to ensure consistency.
The audit mechanism verifies that closed orders are properly removed and that inflight orders (submitted but not yet accepted) remain tracked during venue latency windows.

The audit interval can be configured using the `own_books_audit_interval_secs` parameter in live trading configurations.

</document_content>
</document>
<document index="1450">
<source>docs/concepts/index.md</source>
<document_content>
# Concepts

Concept guides introduce and explain the foundational ideas, components, and best practices that underpin the NautilusTrader platform.
These guides are designed to provide both conceptual and practical insights, helping you navigate the system's architecture, strategies, data management, execution flow, and more.
Explore the following guides to deepen your understanding and make the most of NautilusTrader.

## [Overview](overview.md)

The **Overview** guide covers the main features and intended use cases for the platform.

## [Architecture](architecture.md)

The **Architecture** guide dives deep into the foundational principles, structures, and designs that underpin
the platform. It is ideal for developers, system architects, or anyone curious about the inner workings of NautilusTrader.

## [Actors](actors.md)

The `Actor` serves as the foundational component for interacting with the trading system.
The **Actors** guide covers capabilities and implementation specifics.

## [Strategies](strategies.md)

The `Strategy` is at the heart of the NautilusTrader user experience when writing and working with
trading strategies. The **Strategies** guide covers how to implement strategies for the platform.

## [Instruments](instruments.md)

The **Instruments** guide covers the different instrument definition specifications for tradable assets and contracts.

## [Data](data.md)

The NautilusTrader platform defines a range of built-in data types crafted specifically to represent
a trading domain. The **Data** guide covers working with both built-in and custom data.

## [Execution](execution.md)

NautilusTrader can handle trade execution and order management for multiple strategies and venues
simultaneously (per instance). The **Execution** guide covers components involved in execution, as
well as the flow of execution messages (commands and events).

## [Orders](orders.md)

The **Orders** guide provides more details about the available order types for the platform, along with
the execution instructions supported for each. Advanced order types and emulated orders are also covered.

## [Positions](positions.md)

The **Positions** guide explains how positions work in NautilusTrader, including their lifecycle,
aggregation from order fills, profit and loss calculations, and the important concept of position
snapshotting for netting OMS configurations.

## [Cache](cache.md)

The `Cache` is a central in-memory data store for managing all trading-related data.
The **Cache** guide covers capabilities and best practices of the cache.

## [Message Bus](message_bus.md)

The `MessageBus` is the core communication system enabling decoupled messaging patterns between components,
including point-to-point, publish/subscribe, and request/response.
The **Message Bus** guide covers capabilities and best practices of the `MessageBus`.

## [Portfolio](portfolio.md)

The `Portfolio` serves as the central hub for managing and tracking all positions across active strategies for the trading node or backtest.
It consolidates position data from multiple instruments, providing a unified view of your holdings, risk exposure, and overall performance.
Explore this section to understand how NautilusTrader aggregates and updates portfolio state to support effective trading and risk management.

## [Reports](reports.md)

The **Reports** guide covers the reporting capabilities in NautilusTrader, including execution reports,
portfolio analysis reports, PnL accounting considerations, and how reports are used for backtest
post-run analysis.

## [Logging](logging.md)

The platform provides logging for both backtesting and live trading using a high-performance logger implemented in Rust.

## [Backtesting](backtesting.md)

Backtesting with NautilusTrader is a methodical simulation process that replicates trading
activities using a specific system implementation.

## [Visualization](visualization.md)

The **Visualization** guide covers the interactive tearsheet system for analyzing backtest
results, including available charts, themes, customization options, and how to create
custom visualizations using the extensible chart registry.

## [Live Trading](live.md)

Live trading in NautilusTrader enables traders to deploy their backtested strategies in real-time
without any code changes. This seamless transition ensures consistency and reliability, though there
are key differences between backtesting and live trading.

## [Adapters](adapters.md)

The NautilusTrader design allows for integrating data providers and/or trading venues through adapter implementations.
The **Adapters** guide covers requirements and best practices for developing new integration adapters for the platform.

:::note
The [API Reference](../api_reference/index.md) documentation should be considered the source of truth
for the platform. If there are any discrepancies between concepts described here and the API Reference,
then the API Reference should be considered the correct information. We are working to ensure that
concepts stay up-to-date with the API Reference and will be introducing doc tests in the near future
to help with this.
:::

</document_content>
</document>
<document index="1451">
<source>docs/concepts/instruments.md</source>
<document_content>
# Instruments

The `Instrument` base class represents the core specification for any tradable asset/contract. There are
currently a number of subclasses representing a range of *asset classes* and *instrument classes* which are supported by the platform:

- `Equity` (listed shares or ETFs traded on cash markets)
- `FuturesContract` (deliverable futures contract with defined underlying, expiry, and multiplier)
- `FuturesSpread` (exchange-defined multi-leg futures strategy—e.g., calendar or inter-commodity—quoted as one instrument)
- `OptionContract` (exchange-traded option—put or call—on an underlying with strike and expiry)
- `OptionSpread` (exchange-defined multi-leg options strategy—e.g., vertical, calendar, straddle—quoted as one instrument)
- `BinaryOption` (fixed-payout option that settles to 0 or 1 based on a binary outcome)
- `Cfd` (over-the-counter Contract for Difference that tracks an underlying and is cash-settled)
- `Commodity` (spot commodity instrument—e.g., gold or oil—traded in cash markets)
- `CurrencyPair` (spot FX or crypto pair in BASE/QUOTE format traded in cash markets)
- `CryptoOption` (option on a crypto underlying with crypto quote/settlement; supports inverse or quanto styles)
- `CryptoPerpetual` (perpetual futures contract—aka perpetual swap—on crypto with no expiry; can be inverse or quanto-settled)
- `CryptoFuture` (dated, deliverable crypto futures contract with fixed expiry, underlying crypto, and settlement currency)
- `IndexInstrument` (spot index calculated from constituents; used as a reference price and not directly tradable)
- `BettingInstrument` (a sports/gaming market selection—e.g., team or runner—tradable on betting venues)

## Symbology

All instruments should have a unique `InstrumentId`, which is made up of both the native symbol, and venue ID, separated by a period.
For example, on the Binance Futures crypto exchange, the Ethereum Perpetual Futures Contract has the instrument ID `ETHUSDT-PERP.BINANCE`.

All native symbols *should* be unique for a venue (this is not always the case e.g. Binance share native symbols between spot and futures markets),
and the `{symbol.venue}` combination *must* be unique for a Nautilus system.

:::warning
The correct instrument must be matched to a market dataset such as ticks or order book data for logically sound operation.
An incorrectly specified instrument may truncate data or otherwise produce surprising results.
:::

## Backtesting

Generic test instruments can be instantiated through the `TestInstrumentProvider`:

```python
from nautilus_trader.test_kit.providers import TestInstrumentProvider

audusd = TestInstrumentProvider.default_fx_ccy("AUD/USD")
```

Exchange specific instruments can be discovered from live exchange data using an adapters `InstrumentProvider`:

```python
from nautilus_trader.adapters.binance.spot.providers import BinanceSpotInstrumentProvider
from nautilus_trader.model import InstrumentId

provider = BinanceSpotInstrumentProvider(client=binance_http_client)
await provider.load_all_async()

btcusdt = InstrumentId.from_str("BTCUSDT.BINANCE")
instrument = provider.find(btcusdt)
```

Or flexibly defined by the user through an `Instrument` constructor, or one of its more specific subclasses:

```python
from nautilus_trader.model.instruments import Instrument

instrument = Instrument(...)  # <-- provide all necessary parameters
```

See the full instrument [API Reference](../api_reference/model/instruments.md).

## Live trading

Live integration adapters have defined `InstrumentProvider` classes which work in an automated way to cache the
latest instrument definitions for the exchange. Refer to a particular `Instrument`
object by passing the matching `InstrumentId` to data and execution related methods and classes that require one.

## Finding instruments

Since the same actor/strategy classes can be used for both backtest and live trading, you can
get instruments in exactly the same way through the central cache:

```python
from nautilus_trader.model import InstrumentId

instrument_id = InstrumentId.from_str("ETHUSDT-PERP.BINANCE")
instrument = self.cache.instrument(instrument_id)
```

It's also possible to subscribe to any changes to a particular instrument:

```python
self.subscribe_instrument(instrument_id)
```

Or subscribe to all instrument changes for an entire venue:

```python
from nautilus_trader.model import Venue

binance = Venue("BINANCE")
self.subscribe_instruments(binance)
```

When an update to the instrument(s) is received by the `DataEngine`, the object(s) will
be passed to the actors/strategies `on_instrument()` method. A user can override this method with actions
to take upon receiving an instrument update:

```python
from nautilus_trader.model.instruments import Instrument

def on_instrument(self, instrument: Instrument) -> None:
    # Take some action on an instrument update
    pass
```

## Precisions and increments

The instrument objects are a convenient way to organize the specification of an
instrument through *read-only* properties. Correct price and quantity precisions, as well as
minimum price and size increments, multipliers and standard lot sizes, are available.

:::note
Most of these limits are checked by the Nautilus `RiskEngine`, otherwise invalid
values for prices and quantities *can* result in the exchange rejecting orders.
:::

## Limits

Certain value limits are optional for instruments and can be `None`, these are exchange
dependent and can include:

- `max_quantity` (maximum quantity for a single order).
- `min_quantity` (minimum quantity for a single order).
- `max_notional` (maximum value of a single order).
- `min_notional` (minimum value of a single order).
- `max_price` (maximum valid quote or order price).
- `min_price` (minimum valid quote or order price).

:::note
Most of these limits are checked by the Nautilus `RiskEngine`, otherwise exceeding
published limits *can* result in the exchange rejecting orders.
:::

## Prices and quantities

Instrument objects also offer a convenient way to create correct prices
and quantities based on given values.

```python
instrument = self.cache.instrument(instrument_id)

price = instrument.make_price(0.90500)
quantity = instrument.make_qty(150)
```

:::tip
The above is the recommended method for creating valid prices and quantities,
such as when passing them to the order factory to create an order.
:::

## Margins and fees

Margin calculations are handled by the `MarginAccount` class. This section explains how margins work and introduces key concepts you need to know.

### When margins apply?

Each exchange (e.g., CME or Binance) operates with a specific account type that determines whether margin calculations are applicable.
When setting up an exchange venue, you'll specify one of these account types:

- `AccountType.MARGIN`: Accounts that use margin calculations, which are explained below.
- `AccountType.CASH`: Simple accounts where margin calculations do not apply.
- `AccountType.BETTING`: Accounts designed for betting, which also do not involve margin calculations.

### Vocabulary

To understand trading on margin, let’s start with some key terms:

**Notional Value**: The total contract value in the quote currency. It represents the full market value of your position. For example, with EUR/USD futures on CME (symbol 6E).

- Each contract represents 125,000 EUR (EUR is base currency, USD is quote currency).
- If the current market price is 1.1000, the notional value equals 125,000 EUR × 1.1000 (price of EUR/USD) = 137,500 USD.

**Leverage** (`leverage`): The ratio that determines how much market exposure you can control relative to your account deposit. For example, with 10× leverage, you can control 10,000 USD worth of positions with just 1,000 USD in your account.

**Initial Margin** (`margin_init`): The margin rate required to open a position. It represents the minimum amount of funds that must be available in your account to open new positions. This is only a pre-check — no funds are actually locked.

**Maintenance Margin** (`margin_maint`): The margin rate required to keep a position open. This amount is locked in your account to maintain the position. It is always lower than the initial margin. You can view the total blocked funds (sum of maintenance margins for open positions) using the following in your strategy:

```python
self.portfolio.balances_locked(venue)
```

**Maker/Taker Fees**: The fees charged by exchanges based on your order's interaction with the market:

- Maker Fee (`maker_fee`): A fee (typically lower) charged when you "make" liquidity by placing an order that remains on the order book. For example, a limit buy order below the current price adds liquidity, and the *maker* fee applies when it fills.
- Taker Fee (`taker_fee`): A fee (typically higher) charged when you "take" liquidity by placing an order that executes immediately. For instance, a market buy order or a limit buy above the current price removes liquidity, and the *taker* fee applies.

:::tip
Not all exchanges or instruments implement maker/taker fees. If absent, set both `maker_fee` and `taker_fee` to 0 for the `Instrument` (e.g., `FuturesContract`, `Equity`, `CurrencyPair`, `Commodity`, `Cfd`, `BinaryOption`, `BettingInstrument`).
:::

### Margin calculation formula

The `MarginAccount` class calculates margins using the following formulas:

```python
# Initial margin calculation
margin_init = (notional_value / leverage * margin_init) + (notional_value / leverage * taker_fee)

# Maintenance margin calculation
margin_maint = (notional_value / leverage * margin_maint) + (notional_value / leverage * taker_fee)
```

**Key Points**:

- Both formulas follow the same structure but use their respective margin rates (`margin_init` and `margin_maint`).
- Each formula consists of two parts:
  - **Primary margin calculation**: Based on notional value, leverage, and margin rate.
  - **Fee Adjustment**: Accounts for the maker/taker fee.

### Implementation details

For those interested in exploring the technical implementation:

- [nautilus_trader/accounting/accounts/margin.pyx](https://github.com/nautechsystems/nautilus_trader/blob/develop/nautilus_trader/accounting/accounts/margin.pyx)
- Key methods: `calculate_margin_init(self, ...)` and `calculate_margin_maint(self, ...)`

## Commissions

Trading commissions represent the fees charged by exchanges or brokers for executing trades.
While maker/taker fees are common in cryptocurrency markets, traditional exchanges like CME often
employ other fee structures, such as per-contract commissions.
NautilusTrader supports multiple commission models to accommodate diverse fee structures across different markets.

### Built-in fee models

The framework provides two built-in fee model implementations:

1. `MakerTakerFeeModel`: Implements the maker/taker fee structure common in cryptocurrency exchanges, where fees are
    calculated as a percentage of the trade value.
2. `FixedFeeModel`: Applies a fixed commission per trade, regardless of the trade size.

### Creating custom fee models

While the built-in fee models cover common scenarios, you might encounter situations requiring specific commission structures.
NautilusTrader's flexible architecture allows you to implement custom fee models by inheriting from the base `FeeModel` class.

For example, if you're trading futures on exchanges that charge per-contract commissions (like CME), you can implement
a custom fee model. When creating custom fee models, we inherit from the `FeeModel` base class, which is implemented
in Cython for performance reasons. This Cython implementation is reflected in the parameter naming convention,
where type information is incorporated into parameter names using underscores (like `Order_order` or `Quantity_fill_qty`).

While these parameter names might look unusual to Python developers, they're a result of Cython's type system and help
maintain consistency with the framework's core components. Here's how you could create a per-contract commission model:

```python
class PerContractFeeModel(FeeModel):
    def __init__(self, commission: Money):
        super().__init__()
        self.commission = commission

    def get_commission(self, Order_order, Quantity_fill_qty, Price_fill_px, Instrument_instrument):
        total_commission = Money(self.commission * Quantity_fill_qty, self.commission.currency)
        return total_commission
```

This custom implementation calculates the total commission by multiplying a `fixed per-contract fee` by the `number
of contracts` traded. The `get_commission(...)` method receives information about the order, fill quantity, fill price
and instrument, allowing for flexible commission calculations based on these parameters.

Our new class `PerContractFeeModel` inherits class `FeeModel`, which is implemented in Cython,
so notice the Cython-style parameter names in the method signature:

- `Order_order`: The order object, with type prefix `Order_`.
- `Quantity_fill_qty`: The fill quantity, with type prefix `Quantity_`.
- `Price_fill_px`: The fill price, with type prefix `Price_`.
- `Instrument_instrument`: The instrument object, with type prefix `Instrument_`.

These parameter names follow NautilusTrader's Cython naming conventions, where the prefix indicates the expected type.
While this might seem verbose compared to typical Python naming conventions, it ensures type safety and consistency
with the framework's Cython codebase.

### Using fee models in practice

To use any fee model in your trading system, whether built-in or custom, you specify it when setting up the venue.
Here's an example using the custom per-contract fee model:

```python
from nautilus_trader.model.currencies import USD
from nautilus_trader.model.objects import Money, Currency

engine.add_venue(
    venue=venue,
    oms_type=OmsType.NETTING,
    account_type=AccountType.MARGIN,
    base_currency=USD,
    fee_model=PerContractFeeModel(Money(2.50, USD)),  # 2.50 USD per contract
    starting_balances=[Money(1_000_000, USD)],  # Starting with 1,000,000 USD balance
)
```

:::tip
When implementing custom fee models, ensure they accurately reflect the fee structure of your target exchange.
Even small discrepancies in commission calculations can significantly impact strategy performance metrics during backtesting.
:::

### Additional info

The raw instrument definition as provided by the exchange (typically from JSON serialized data) is also
included as a generic Python dictionary. This is to retain all information
which is not necessarily part of the unified Nautilus API, and is available to the user
at runtime by calling the `.info` property.

## Synthetic instruments

The platform supports creating customized synthetic instruments, which can generate synthetic quote
and trades. These are useful for:

- Enabling `Actor` and `Strategy` components to subscribe to quote or trade feeds.
- Triggering emulated orders.
- Constructing bars from synthetic quotes or trades.

Synthetic instruments cannot be traded directly, as they are constructs that only exist locally
within the platform. They serve as analytical tools, providing useful metrics based on their component
instruments.

In the future, we plan to support order management for synthetic instruments, enabling trading of
their component instruments based on the synthetic instrument's behavior.

:::info
The venue for a synthetic instrument is always designated as `'SYNTH'`.
:::

### Formula

A synthetic instrument is composed of a combination of two or more component instruments (which
can include instruments from multiple venues), as well as a "derivation formula".
Utilizing the dynamic expression engine powered by the [evalexpr](https://github.com/ISibboI/evalexpr)
Rust crate, the platform can evaluate the formula to calculate the latest synthetic price tick
from the incoming component instrument prices.

See the `evalexpr` documentation for a full description of available features, operators and precedence.

:::tip
Before defining a new synthetic instrument, ensure that all component instruments are already defined and exist in the cache.
:::

### Subscribing

The following example demonstrates the creation of a new synthetic instrument with an actor/strategy.
This synthetic instrument will represent a simple spread between Bitcoin and
Ethereum spot prices on Binance. For this example, it is assumed that spot instruments for
`BTCUSDT.BINANCE` and `ETHUSDT.BINANCE` are already present in the cache.

```python
from nautilus_trader.model.instruments import SyntheticInstrument

btcusdt_binance_id = InstrumentId.from_str("BTCUSDT.BINANCE")
ethusdt_binance_id = InstrumentId.from_str("ETHUSDT.BINANCE")

# Define the synthetic instrument
synthetic = SyntheticInstrument(
    symbol=Symbol("BTC-ETH:BINANCE"),
    price_precision=8,
    components=[
        btcusdt_binance_id,
        ethusdt_binance_id,
    ],
    formula=f"{btcusdt_binance_id} - {ethusdt_binance_id}",
    ts_event=self.clock.timestamp_ns(),
    ts_init=self.clock.timestamp_ns(),
)

# Recommended to store the synthetic instruments ID somewhere
self._synthetic_id = synthetic.id

# Add the synthetic instrument for use by other components
self.add_synthetic(synthetic)

# Subscribe to quotes for the synthetic instrument
self.subscribe_quote_ticks(self._synthetic_id)
```

:::note
The `instrument_id` for the synthetic instrument in the above example will be structured as `{symbol}.{SYNTH}`, resulting in `'BTC-ETH:BINANCE.SYNTH'`.
:::

### Updating formulas

It's also possible to update a synthetic instrument formulas at any time. The following example
shows how to achieve this with an actor/strategy.

```
# Recover the synthetic instrument from the cache (assuming `synthetic_id` was assigned)
synthetic = self.cache.synthetic(self._synthetic_id)

# Update the formula, here is a simple example of just taking the average
new_formula = "(BTCUSDT.BINANCE + ETHUSDT.BINANCE) / 2"
synthetic.change_formula(new_formula)

# Now update the synthetic instrument
self.update_synthetic(synthetic)
```

### Trigger instrument IDs

The platform allows for emulated orders to be triggered based on synthetic instrument prices. In
the following example, we build upon the previous one to submit a new emulated order.
This order will be retained in the emulator until a trigger from synthetic quotes releases it.
It will then be submitted to Binance as a MARKET order:

```python
order = self.strategy.order_factory.limit(
    instrument_id=ETHUSDT_BINANCE.id,
    order_side=OrderSide.BUY,
    quantity=Quantity.from_str("1.5"),
    price=Price.from_str("30000.00000000"),  # <-- Synthetic instrument price
    emulation_trigger=TriggerType.DEFAULT,
    trigger_instrument_id=self._synthetic_id,  # <-- Synthetic instrument identifier
)

self.strategy.submit_order(order)
```

### Error handling

Considerable effort has been made to validate inputs, including the derivation formula for
synthetic instruments. Despite this, caution is advised as invalid or erroneous inputs may lead to
undefined behavior.

:::info
See the `SyntheticInstrument` [API reference](../api_reference/model/instruments.md#class-syntheticinstrument-1)
for a detailed understanding of input requirements and potential exceptions.
:::

</document_content>
</document>
<document index="1452">
<source>docs/concepts/logging.md</source>
<document_content>
# Logging

The platform provides logging for both backtesting and live trading using a high-performance logging subsystem implemented in Rust
with a standardized facade from the `log` crate.

The core logger operates in a separate thread and uses a multi-producer single-consumer (MPSC) channel to receive log messages.
This design ensures that the main thread remains performant, avoiding potential bottlenecks caused by log string formatting or file I/O operations.

Logging output is configurable and supports:

- **stdout/stderr writer** for console output
- **file writer** for persistent storage of logs

:::info
Infrastructure such as [Vector](https://github.com/vectordotdev/vector) can be integrated to collect and aggregate events within your system.
:::

## Configuration

Logging can be configured by importing the `LoggingConfig` object.
By default, log events with an 'INFO' `LogLevel` and higher are written to stdout/stderr.

Log level (`LogLevel`) values include (and generally match Rust's `tracing` level filters).

Python loggers expose the following levels:

- `OFF`
- `TRACE` (can be set as a filter level, but not directly generated from Python)
- `DEBUG`
- `INFO`
- `WARNING`
- `ERROR`

:::warning
The Python `Logger` does not provide a `trace()` method; `TRACE` level logs are only emitted by the underlying Rust components and cannot be generated directly from Python code. However, you can set `TRACE` as a logging level filter to see trace logs from Rust components.

See the `LoggingConfig` [API Reference](../api_reference/config.md#class-loggingconfig) for further details.
:::

Logging can be configured in the following ways:

- Minimum `LogLevel` for stdout/stderr.
- Minimum `LogLevel` for log files.
- Maximum size before rotating a log file.
- Maximum number of backup log files to maintain when rotating.
- Automatic log file naming with date or timestamp components, or custom log file name.
- Directory for writing log files.
- Plain text or JSON log file formatting.
- Filtering of individual components by log level.
- ANSI colors in log lines.
- Bypass logging entirely.
- Print Rust config to stdout at initialization.
- Optionally initialize logging via the PyO3 bridge (`use_pyo3`) to capture log events emitted by Rust components.
- Truncate existing log file on startup if it already exists (`clear_log_file`)

### Standard output logging

Log messages are written to the console via stdout/stderr writers. The minimum log level can be configured using the `log_level` parameter.

### File logging

Log files are written to the current working directory by default. The naming convention and rotation behavior are configurable and follow specific patterns based on your settings.

You can specify a custom log directory using `log_directory` and/or a custom file basename using `log_file_name`. Log files are always suffixed with `.log` (plain text) or `.json` (JSON).

For detailed information about log file naming conventions and rotation behavior, see the [Log file rotation](#log-file-rotation) and [Log file naming convention](#log-file-naming-convention) sections below.

#### Log file rotation

Rotation behavior depends on both the presence of a size limit and whether a custom file name is provided:

- **Size-based rotation**:
  - Enabled by specifying the `log_file_max_size` parameter (e.g., `100_000_000` for 100 MB).
  - When writing a log entry would make the current file exceed this size, the file is closed and a new one is created.
- **Date-based rotation (default naming only)**:
  - Applies when no `log_file_max_size` is specified and no custom `log_file_name` is provided.
  - At each UTC date change (midnight), the current log file is closed and a new one is started, creating one file per UTC day.
- **No rotation**:
  - When a custom `log_file_name` is provided without a `log_file_max_size`, logs continue to append to the same file.
- **Backup file management**:
  - Controlled by the `log_file_max_backup_count` parameter (default: 5), limiting the total number of rotated files kept.
  - When this limit is exceeded, the oldest backup files are automatically removed.

#### Log file naming convention

The default naming convention ensures log files are uniquely identifiable and timestamped.
The format depends on whether file rotation is enabled:

**With file rotation enabled**:

- **Format**: `{trader_id}_{%Y-%m-%d_%H%M%S:%3f}_{instance_id}.{log|json}`
- **Example**: `TESTER-001_2025-04-09_210721:521_d7dc12c8-7008-4042-8ac4-017c3db0fc38.log`
- **Components**:
  - `{trader_id}`: The trader identifier (e.g., `TESTER-001`).
  - `{%Y-%m-%d_%H%M%S:%3f}`: Full ISO 8601-compliant datetime with millisecond resolution.
  - `{instance_id}`: A unique instance identifier.
  - `{log|json}`: File suffix based on format setting.

**Without size-based rotation (default naming)**:

- **Format**: `{trader_id}_{%Y-%m-%d}_{instance_id}.{log|json}`
- **Example**: `TESTER-001_2025-04-09_d7dc12c8-7008-4042-8ac4-017c3db0fc38.log`
- **Components**:
  - `{trader_id}`: The trader identifier.
  - `{%Y-%m-%d}`: Date only (YYYY-MM-DD).
  - `{instance_id}`: A unique instance identifier.
  - `{log|json}`: File suffix based on format setting.
- **Note**: With default naming and no size limit, logs rotate daily at UTC midnight.

**Custom naming**:

If `log_file_name` is set (e.g., `my_custom_log`):

- With rotation disabled: The file will be named exactly as provided (e.g., `my_custom_log.log`).
- With rotation enabled: The file will include the custom name and timestamp (e.g., `my_custom_log_2025-04-09_210721:521.log`).

### Component log filtering

The `log_component_levels` parameter can be used to set log levels for each component individually.
The input value should be a dictionary of component ID strings to log level strings: `dict[str, str]`.

Below is an example of a trading node logging configuration that includes some of the options mentioned above:

```python
from nautilus_trader.config import LoggingConfig
from nautilus_trader.config import TradingNodeConfig

config_node = TradingNodeConfig(
    trader_id="TESTER-001",
    logging=LoggingConfig(
        log_level="INFO",
        log_level_file="DEBUG",
        log_file_format="json",
        log_component_levels={ "Portfolio": "INFO" },
    ),
    ... # Omitted
)
```

For backtesting, the `BacktestEngineConfig` class can be used instead of `TradingNodeConfig`, as the same options are available.

### Components-only logging

When focusing on a subset of noisy systems, enable `log_components_only` to log messages only from components explicitly listed in `log_component_levels`. All other components are suppressed regardless of the global `log_level` or file level.

Example (Python configuration):

```python
logging = LoggingConfig(
    log_level="INFO",
    log_component_levels={
        "RiskEngine": "DEBUG",
        "Portfolio": "INFO",
    },
    log_components_only=True,
)
```

If configuring via the environment using the Rust spec string, include `log_components_only` alongside component filters, for example:

```bash
export NAUTILUS_LOG="stdout=Info;log_components_only;RiskEngine=Debug;Portfolio=Info"
```

:::warning
If `log_components_only=True` (or `log_components_only` is present in the spec string) and `log_component_levels` is empty, no log messages will be emitted to stdout/stderr or files. Add at least one component filter or disable components-only logging.
:::

### Log Colors

ANSI color codes are utilized to enhance the readability of logs when viewed in a terminal.
These color codes can make it easier to distinguish different parts of log messages.
In environments that do not support ANSI color rendering (such as some cloud environments or text editors),
these color codes may not be appropriate as they can appear as raw text.

To accommodate for such scenarios, the `LoggingConfig.log_colors` option can be set to `false`.
Disabling `log_colors` will prevent the addition of ANSI color codes to the log messages, ensuring
compatibility across different environments where color rendering is not supported.

## Using a logger directly

It's possible to use `Logger` objects directly, and these can be initialized anywhere (very similar to the Python built-in `logging` API).

If you ***aren't*** using an object which already initializes a `NautilusKernel` (and logging) such as `BacktestEngine` or `TradingNode`,
then you can activate logging in the following way:

```python
from nautilus_trader.common.component import init_logging
from nautilus_trader.common.component import Logger

log_guard = init_logging()
logger = Logger("MyLogger")
```

:::info
See the `init_logging` [API Reference](../api_reference/common.md) for further details.
:::

:::warning
Only one logging subsystem can be initialized per process with an `init_logging` call. Multiple `LogGuard` instances (up to 255) can exist concurrently, and the logging thread will remain active until all guards are dropped.
:::

## LogGuard: managing log lifecycle

The `LogGuard` ensures that the logging subsystem remains active and operational throughout the lifecycle of a process.
It prevents premature shutdown of the logging subsystem when running multiple engines in the same process.

### Reference Counting Implementation

The logging system uses reference counting to track active `LogGuard` instances:

- **Counter increments**: When a new `LogGuard` is created, an atomic counter is incremented.
- **Counter decrements**: When a `LogGuard` is dropped, the counter is decremented.
- **Logging thread termination**: When the counter reaches zero (last `LogGuard` dropped), the logging thread is properly joined to ensure all pending log messages are written before the process terminates.
- **Maximum guards**: The system supports up to 255 concurrent `LogGuard` instances. Attempting to create more will cause a panic.

This mechanism ensures that:

1. Log messages are never lost due to premature thread termination.
2. The logging thread remains active as long as any `LogGuard` exists.
3. All buffered logs are properly flushed to their destinations when the program ends.

### Why use LogGuard?

Without a `LogGuard`, any attempt to run sequential engines in the same process may result in errors such as:

```
Error sending log event: [INFO] ...
```

This occurs because the logging subsystem's underlying channel and Rust `Logger` are closed when the first engine is disposed.
As a result, subsequent engines lose access to the logging subsystem, leading to these errors.

By leveraging a `LogGuard`, you can ensure robust logging behavior across multiple backtests or engine runs in the same process.
The `LogGuard` retains the resources of the logging subsystem and ensures that logs continue to function correctly,
even as engines are disposed and initialized.

:::note
Using `LogGuard` is critical to maintain consistent logging behavior throughout a process with multiple engines.
:::

## Running multiple engines

The following example demonstrates how to use a `LogGuard` when running multiple engines sequentially in the same process:

```python
log_guard = None  # Initialize LogGuard reference

for i in range(number_of_backtests):
    engine = setup_engine(...)

    # Assign reference to LogGuard
    if log_guard is None:
        log_guard = engine.get_log_guard()

    # Add actors and execute the engine
    actors = setup_actors(...)
    engine.add_actors(actors)
    engine.run()
    engine.dispose()  # Dispose safely
```

### Steps

- **Initialize LogGuard once**: The `LogGuard` is obtained from the first engine (`engine.get_log_guard()`) and is retained throughout the process. This ensures that the logging subsystem remains active.
- **Dispose engines safely**: Each engine is safely disposed of after its backtest completes, without affecting the logging subsystem.
- **Reuse LogGuard**: The same `LogGuard` instance is reused for subsequent engines, preventing the logging subsystem from shutting down prematurely.

### Considerations

- **Multiple LogGuards per process**: The system supports up to 255 concurrent `LogGuard` instances per process. Each guard increments a reference counter when created and decrements it when dropped.
- **Thread safety**: The logging subsystem, including `LogGuard`, is thread-safe, ensuring consistent behavior even in multi-threaded environments.
- **Automatic cleanup**: When the last `LogGuard` is dropped (reference count reaches zero), the logging thread is properly joined to ensure all pending logs are written before the process terminates.

## Platform-specific considerations

### Windows shutdown behavior

On Windows, non-deterministic garbage collection during interpreter shutdown can occasionally
prevent the logging thread from joining properly. When the last `LogGuard` is dropped, the
logging subsystem signals the background thread to close and joins it to ensure all pending
messages are written. If Python's garbage collector delays dropping the guard until after
interpreter shutdown has begun, this join may not complete, resulting in truncated logs.

This issue is tracked in GitHub [issue #3027](https://github.com/nautechsystems/nautilus_trader/issues/3027).
A more deterministic shutdown mechanism is under consideration.

</document_content>
</document>
<document index="1453">
<source>docs/concepts/message_bus.md</source>
<document_content>
# Message Bus

The `MessageBus` is a fundamental part of the platform, enabling communication between system components
through message passing. This design creates a loosely coupled architecture where components can interact
without direct dependencies.

The *messaging patterns* include:

- Point-to-Point
- Publish/Subscribe
- Request/Response

Messages exchanged via the `MessageBus` fall into three categories:

- Data
- Events
- Commands

## Data and signal publishing

While the `MessageBus` is a lower-level component that users typically interact with indirectly,
`Actor` and `Strategy` classes provide convenient methods built on top of it:

```python
def publish_data(self, data_type: DataType, data: Data) -> None:
def publish_signal(self, name: str, value, ts_event: int | None = None) -> None:
```

These methods allow you to publish custom data and signals efficiently without needing to work directly with the `MessageBus` interface.

## Direct access

For advanced users or specialized use cases, direct access to the message bus is available within `Actor` and `Strategy`
classes through the `self.msgbus` reference, which provides the full message bus interface.

To publish a custom message directly, you can specify a topic as a `str` and any Python `object` as the message payload, for example:

```python

self.msgbus.publish("MyTopic", "MyMessage")
```

## Messaging styles

NautilusTrader is an **event-driven** framework where components communicate by sending and receiving messages.
Understanding the different messaging styles is crucial for building effective trading systems.

This guide explains the three primary messaging patterns available in NautilusTrader:

| **Messaging Style**                          | **Purpose**                                 | **Best For**                                          |
|:---------------------------------------------|:--------------------------------------------|:------------------------------------------------------|
| **MessageBus - Publish/Subscribe to topics** | Low-level, direct access to the message bus | Custom events, system-level communication             |
| **Actor-Based - Publish/Subscribe Data**     | Structured trading data exchange            | Trading metrics, indicators, data needing persistence |
| **Actor-Based - Publish/Subscribe Signal**   | Lightweight notifications                   | Simple alerts, flags, status updates                  |

Each approach serves different purposes and offers unique advantages. This guide will help you decide which messaging
pattern to use in your NautilusTrader applications.

### MessageBus publish/subscribe to topics

#### Concept

The `MessageBus` is the central hub for all messages in NautilusTrader. It enables a **publish/subscribe** pattern
where components can publish events to **named topics**, and other components can subscribe to receive those messages.
This decouples components, allowing them to interact indirectly via the message bus.

#### Key benefits and use cases

The message bus approach is ideal when you need:

- **Cross-component communication** within the system.
- **Flexibility** to define any topic and send any type of payload (any Python object).
- **Decoupling** between publishers and subscribers who don't need to know about each other.
- **Global Reach** where messages can be received by multiple subscribers.
- Working with events that don't fit within the predefined `Actor` model.
- Advanced scenarios requiring full control over messaging.

#### Considerations

- You must track topic names manually (typos could result in missed messages).
- You must define handlers manually.

#### Quick overview code

```python
from nautilus_trader.core.message import Event

# Define a custom event
class Each10thBarEvent(Event):
    TOPIC = "each_10th_bar"  # Topic name
    def __init__(self, bar):
        self.bar = bar

# Subscribe in a component (in Strategy)
self.msgbus.subscribe(Each10thBarEvent.TOPIC, self.on_each_10th_bar)

# Publish an event (in Strategy)
event = Each10thBarEvent(bar)
self.msgbus.publish(Each10thBarEvent.TOPIC, event)

# Handler (in Strategy)
def on_each_10th_bar(self, event: Each10thBarEvent):
    self.log.info(f"Received 10th bar: {event.bar}")
```

#### Full example

[MessageBus Example](https://github.com/nautechsystems/nautilus_trader/tree/develop/examples/backtest/example_09_messaging_with_msgbus)

### Actor-based publish/subscribe data

#### Concept

This approach provides a way to exchange trading specific data between `Actor`s in the system.
(note: each `Strategy` inherits from `Actor`). It inherits from `Data`, which ensures proper timestamping
and ordering of events - crucial for correct backtest processing.

#### Key Benefits and Use Cases

The Data publish/subscribe approach excels when you need:

- **Exchange of structured trading data** like market data, indicators, custom metrics, or option greeks.
- **Proper event ordering** via built-in timestamps (`ts_event`, `ts_init`) crucial for backtest accuracy.
- **Data persistence and serialization** through the `@customdataclass` decorator, integrating seamlessly with NautilusTrader's data catalog system.
- **Standardized trading data exchange** between system components.

#### Considerations

- Requires defining a class that inherits from `Data` or uses `@customdataclass`.

#### Inheriting from `Data` vs. using `@customdataclass`

**Inheriting from `Data` class:**

- Defines abstract properties `ts_event` and `ts_init` that must be implemented by the subclass. These ensure proper data ordering in backtests based on timestamps.

**The `@customdataclass` decorator:**

- Adds `ts_event` and `ts_init` attributes if they are not already present.
- Provides serialization functions: `to_dict()`, `from_dict()`, `to_bytes()`, `to_arrow()`, etc.
- Enables data persistence and external communication.

#### Quick overview code

```python
from nautilus_trader.core.data import Data
from nautilus_trader.model.custom import customdataclass

@customdataclass
class GreeksData(Data):
    delta: float
    gamma: float

# Publish data (in Actor / Strategy)
data = GreeksData(delta=0.75, gamma=0.1, ts_event=1_630_000_000_000_000_000, ts_init=1_630_000_000_000_000_000)
self.publish_data(GreeksData, data)

# Subscribe to receiving data  (in Actor / Strategy)
self.subscribe_data(GreeksData)

# Handler (this is static callback function with fixed name)
def on_data(self, data: Data):
    if isinstance(data, GreeksData):
        self.log.info(f"Delta: {data.delta}, Gamma: {data.gamma}")
```

#### Full example

[Actor-Based Data Example](https://github.com/nautechsystems/nautilus_trader/tree/develop/examples/backtest/example_10_messaging_with_actor_data)

### Actor-based publish/subscribe signal

#### Concept

**Signals** are a lightweight way to publish and subscribe to simple notifications within the actor framework.
This is the simplest messaging approach, requiring no custom class definitions.

#### Key Benefits and Use Cases

The Signal messaging approach shines when you need:

- **Simple, lightweight notifications/alerts** like "RiskThresholdExceeded" or "TrendUp".
- **Quick, on-the-fly messaging** without defining custom classes.
- **Broadcasting alerts or flags** as primitive data (`int`, `float`, or `str`).
- **Easy API integration** with straightforward methods (`publish_signal`, `subscribe_signal`).
- **Multiple subscriber communication** where all subscribers receive signals when published.
- **Minimal setup overhead** with no class definitions required.

#### Considerations

- Each signal can contain only **single value** of type: `int`, `float`, and `str`. That means no support for complex data structures or other Python types.
- In the `on_signal` handler, you can only differentiate between signals using `signal.value`, as the signal name is not accessible in the handler.

#### Quick overview code

```python
# Define signal constants for better organization (optional but recommended)
import types
from nautilus_trader.core.datetime import unix_nanos_to_dt
from nautilus_trader.common.enums import LogColor

signals = types.SimpleNamespace()
signals.NEW_HIGHEST_PRICE = "NewHighestPriceReached"
signals.NEW_LOWEST_PRICE = "NewLowestPriceReached"

# Subscribe to signals (in Actor/Strategy)
self.subscribe_signal(signals.NEW_HIGHEST_PRICE)
self.subscribe_signal(signals.NEW_LOWEST_PRICE)

# Publish a signal (in Actor/Strategy)
self.publish_signal(
    name=signals.NEW_HIGHEST_PRICE,
    value=signals.NEW_HIGHEST_PRICE,  # value can be the same as name for simplicity
    ts_event=bar.ts_event,  # timestamp from triggering event
)

# Handler (this is static callback function with fixed name)
def on_signal(self, signal):
    # IMPORTANT: We match against signal.value, not signal.name
    match signal.value:
        case signals.NEW_HIGHEST_PRICE:
            self.log.info(
                f"New highest price was reached. | "
                f"Signal value: {signal.value} | "
                f"Signal time: {unix_nanos_to_dt(signal.ts_event)}",
                color=LogColor.GREEN
            )
        case signals.NEW_LOWEST_PRICE:
            self.log.info(
                f"New lowest price was reached. | "
                f"Signal value: {signal.value} | "
                f"Signal time: {unix_nanos_to_dt(signal.ts_event)}",
                color=LogColor.RED
            )
```

#### Full example

[Actor-Based Signal Example](https://github.com/nautechsystems/nautilus_trader/tree/develop/examples/backtest/example_11_messaging_with_actor_signals)

### Summary and decision guide

Here's a quick reference to help you decide which messaging style to use:

#### Decision guide: Which style to choose?

| **Use Case**                                | **Recommended Approach**                                                        | **Setup required** |
|:--------------------------------------------|:--------------------------------------------------------------------------------|:-------------------|
| Custom events or system-level communication | `MessageBus` + Pub/Sub to topic                                                 | Topic + Handler management |
| Structured trading data                     | `Actor` + Pub/Sub Data + optional `@customdataclass` if serialization is needed | New class definition inheriting from `Data` (handler `on_data` is predefined) |
| Simple alerts/notifications                 | `Actor` + Pub/Sub Signal                                                        | Just signal name |

## External publishing

The `MessageBus` can be *backed* with any database or message broker technology which has an
integration written for it, this then enables external publishing of messages.

:::info
Redis is currently supported for all serializable messages which are published externally.
The minimum supported Redis version is 6.2 (required for [streams](https://redis.io/docs/latest/develop/data-types/streams/) functionality).
:::

Under the hood, when a backing database (or any other compatible technology) is configured,
all outgoing messages are first serialized, then transmitted via a Multiple-Producer Single-Consumer (MPSC) channel to a separate thread (implemented in Rust).
In this separate thread, the message is written to its final destination, which is presently Redis streams.

This design is primarily driven by performance considerations. By offloading the I/O operations to a separate thread,
we ensure that the main thread remains unblocked and can continue its tasks without being hindered by the potentially
time-consuming operations involved in interacting with a database or client.

### Serialization

Nautilus supports serialization for:

- All Nautilus built-in types (serialized as dictionaries `dict[str, Any]` containing serializable primitives).
- Python primitive types (`str`, `int`, `float`, `bool`, `bytes`).

You can add serialization support for custom types by registering them through the `serialization` subpackage.

```python
def register_serializable_type(
    cls,
    to_dict: Callable[[Any], dict[str, Any]],
    from_dict: Callable[[dict[str, Any]], Any],
):
    ...
```

- `cls`: The type to register.
- `to_dict`: The delegate to instantiate a dict of primitive types from the object.
- `from_dict`: The delegate to instantiate the object from a dict of primitive types.

## Configuration

The message bus external backing technology can be configured by importing the `MessageBusConfig` object and passing this to
your `TradingNodeConfig`. Each of these config options will be described below.

```python
...  # Other config omitted
message_bus=MessageBusConfig(
    database=DatabaseConfig(),
    encoding="json",
    timestamps_as_iso8601=True,
    buffer_interval_ms=100,
    autotrim_mins=30,
    use_trader_prefix=True,
    use_trader_id=True,
    use_instance_id=False,
    streams_prefix="streams",
    types_filter=[QuoteTick, TradeTick],
)
...
```

### Database config

A `DatabaseConfig` must be provided, for a default Redis setup on the local
loopback you can pass a `DatabaseConfig()`, which will use defaults to match.

### Encoding

Two encodings are currently supported by the built-in `Serializer` used by the `MessageBus`:

- JSON (`json`)
- MessagePack (`msgpack`)

Use the `encoding` config option to control the message writing encoding.

:::tip
The `msgpack` encoding is used by default as it offers the most optimal serialization and memory performance.
We recommend using `json` encoding for human readability when performance is not a primary concern.
:::

### Timestamp formatting

By default timestamps are formatted as UNIX epoch nanosecond integers. Alternatively you can
configure ISO 8601 string formatting by setting the `timestamps_as_iso8601` to `True`.

### Message stream keys

Message stream keys are essential for identifying individual trader nodes and organizing messages within streams.
They can be tailored to meet your specific requirements and use cases. In the context of message bus streams, a trader key is typically structured as follows:

```
trader:{trader_id}:{instance_id}:{streams_prefix}
```

The following options are available for configuring message stream keys:

#### Trader prefix

If the key should begin with the `trader` string.

#### Trader ID

If the key should include the trader ID for the node.

#### Instance ID

Each trader node is assigned a unique 'instance ID,' which is a UUIDv4. This instance ID helps distinguish individual traders when messages
are distributed across multiple streams. You can include the instance ID in the trader key by setting the `use_instance_id` configuration option to `True`.
This is particularly useful when you need to track and identify traders across various streams in a multi-node trading system.

#### Streams prefix

The `streams_prefix` string enables you to group all streams for a single trader instance or organize
messages for multiple instances. Configure this by passing a string to the `streams_prefix` configuration
option, ensuring other prefixes are set to false.

#### Stream per topic

Indicates whether the producer will write a separate stream for each topic. This is particularly
useful for Redis backings, which do not support wildcard topics when listening to streams.
If set to False, all messages will be written to the same stream.

:::info
Redis does not support wildcard stream topics. For better compatibility with Redis, it is recommended to set this option to False.
:::

### Types filtering

When messages are published on the message bus, they are serialized and written to a stream if a backing
for the message bus is configured and enabled. To prevent flooding the stream with data like high-frequency
quotes, you may filter out certain types of messages from external publication.

To enable this filtering mechanism, pass a list of `type` objects to the `types_filter` parameter in the message bus configuration,
specifying which types of messages should be excluded from external publication.

```python
from nautilus_trader.config import MessageBusConfig
from nautilus_trader.data import TradeTick
from nautilus_trader.data import QuoteTick

# Create a MessageBusConfig instance with types filtering
message_bus = MessageBusConfig(
    types_filter=[QuoteTick, TradeTick]
)

```

### Stream auto-trimming

The `autotrim_mins` configuration parameter allows you to specify the lookback window in minutes for automatic stream trimming in your message streams.
Automatic stream trimming helps manage the size of your message streams by removing older messages, ensuring that the streams remain manageable in terms of storage and performance.

:::info
The current Redis implementation will maintain the `autotrim_mins` as a maximum width (plus roughly a minute, as streams are trimmed no more than once per minute).
Rather than a maximum lookback window based on the current wall clock time.
:::

## External streams

The message bus within a `TradingNode` (node) is referred to as the "internal message bus".
A producer node is one which publishes messages onto an external stream (see [external publishing](#external-publishing)).
The consumer node listens to external streams to receive and publish deserialized message payloads on its internal message bus.

```
                  ┌───────────────────────────┐
                  │                           │
                  │                           │
                  │                           │
                  │      Producer Node        │
                  │                           │
                  │                           │
                  │                           │
                  │                           │
                  │                           │
                  │                           │
                  └─────────────┬─────────────┘
                                │
                                │
┌───────────────────────────────▼──────────────────────────────┐
│                                                              │
│                            Stream                            │
│                                                              │
└─────────────┬────────────────────────────────────┬───────────┘
              │                                    │
              │                                    │
┌─────────────▼───────────┐          ┌─────────────▼───────────┐
│                         │          │                         │
│                         │          │                         │
│     Consumer Node 1     │          │     Consumer Node 2     │
│                         │          │                         │
│                         │          │                         │
│                         │          │                         │
│                         │          │                         │
│                         │          │                         │
│                         │          │                         │
│                         │          │                         │
└─────────────────────────┘          └─────────────────────────┘
```

:::tip
Set the `LiveDataEngineConfig.external_clients` with the list of `client_id`s intended to represent the external streaming clients.
The `DataEngine` will filter out subscription commands for these clients, ensuring that the external streaming provides the necessary data for any subscriptions to these clients.
:::

### Example configuration

The following example details a streaming setup where a producer node publishes Binance data externally,
and a downstream consumer node publishes these data messages onto its internal message bus.

#### Producer node

We configure the `MessageBus` of the producer node to publish to a `"binance"` stream.
The settings `use_trader_id`, `use_trader_prefix`, and `use_instance_id` are all set to `False`
to ensure a simple and predictable stream key that the consumer nodes can register for.

```python
message_bus=MessageBusConfig(
    database=DatabaseConfig(timeout=2),
    use_trader_id=False,
    use_trader_prefix=False,
    use_instance_id=False,
    streams_prefix="binance",  # <---
    stream_per_topic=False,
    autotrim_mins=30,
),
```

#### Consumer node

We configure the `MessageBus` of the consumer node to receive messages from the same `"binance"` stream.
The node will listen to the external stream keys to publish these messages onto its internal message bus.
Additionally, we declare the client ID `"BINANCE_EXT"` as an external client. This ensures that the
`DataEngine` does not attempt to send data commands to this client ID, as we expect these messages to be
published onto the internal message bus from the external stream, to which the node has subscribed to the relevant topics.

```python
data_engine=LiveDataEngineConfig(
    external_clients=[ClientId("BINANCE_EXT")],
),
message_bus=MessageBusConfig(
    database=DatabaseConfig(timeout=2),
    external_streams=["binance"],  # <---
),
```

</document_content>
</document>
<document index="1454">
<source>docs/concepts/overview.md</source>
<document_content>
# Overview

## Introduction

NautilusTrader is an open-source, high-performance, production-grade algorithmic trading platform,
providing quantitative traders with the ability to backtest portfolios of automated trading strategies
on historical data with an event-driven engine, and also deploy those same strategies live, with no code changes.

The platform is *AI-first*, designed to develop and deploy algorithmic trading strategies within a highly performant
and robust Python-native environment. This helps to address the parity challenge of keeping the Python research/backtest
environment consistent with the production live trading environment.

NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting Python-native, mission-critical, trading system backtesting
and live deployment workloads.

The platform is also universal and asset-class-agnostic — with any REST API or WebSocket stream able to be integrated via modular
adapters. It supports high-frequency trading across a wide range of asset classes and instrument types
including FX, Equities, Futures, Options, Crypto, DeFi, and Betting — enabling seamless operations across multiple venues simultaneously.

## Features

- **Fast**: Core is written in Rust with asynchronous networking using [tokio](https://crates.io/crates/tokio).
- **Reliable**: Rust-powered type- and thread-safety, with optional Redis-backed state persistence.
- **Portable**: OS independent, runs on Linux, macOS, and Windows. Deploy using Docker.
- **Flexible**: Modular adapters mean any REST API or WebSocket stream can be integrated.
- **Advanced**: Time in force `IOC`, `FOK`, `GTC`, `GTD`, `DAY`, `AT_THE_OPEN`, `AT_THE_CLOSE`, advanced order types and conditional triggers. Execution instructions `post-only`, `reduce-only`, and icebergs. Contingency orders including `OCO`, `OUO`, `OTO`.
- **Customizable**: Add user-defined custom components, or assemble entire systems from scratch leveraging the [cache](cache.md) and [message bus](message_bus.md).
- **Backtesting**: Run with multiple venues, instruments and strategies simultaneously using historical quote tick, trade tick, bar, order book and custom data with nanosecond resolution.
- **Live**: Use identical strategy implementations between backtesting and live deployments.
- **Multi-venue**: Multiple venue capabilities facilitate market-making and statistical arbitrage strategies.
- **AI Training**: Backtest engine fast enough to be used to train AI trading agents (RL/ES).

![Nautilus](https://github.com/nautechsystems/nautilus_trader/blob/develop/assets/nautilus-art.png?raw=true "nautilus")
> *nautilus - from ancient Greek 'sailor' and naus 'ship'.*
>
> *The nautilus shell consists of modular chambers with a growth factor which approximates a logarithmic spiral.
> The idea is that this can be translated to the aesthetics of design and architecture.*

## Why NautilusTrader?

- **Highly performant event-driven Python**: Native binary core components.
- **Parity between backtesting and live trading**: Identical strategy code.
- **Reduced operational risk**: Enhanced risk management functionality, logical accuracy, and type safety.
- **Highly extendable**: Message bus, custom components and actors, custom data, custom adapters.

Traditionally, trading strategy research and backtesting might be conducted in Python
using vectorized methods, with the strategy then needing to be reimplemented in a more event-driven way
using C++, C#, Java or other statically typed language(s). The reasoning here is that vectorized backtesting code cannot
express the granular time and event dependent complexity of real-time trading, where compiled languages have
proven to be more suitable due to their inherently higher performance, and type safety.

One of the key advantages of NautilusTrader here, is that this reimplementation step is now circumvented - as the critical core components of the platform
have all been written entirely in [Rust](https://www.rust-lang.org/) or [Cython](https://cython.org/).
This means we're using the right tools for the job, where systems programming languages compile performant binaries,
with CPython C extension modules then able to offer a Python-native environment, suitable for professional quantitative traders and trading firms.

## Use cases

There are three main use cases for this software package:

- Backtest trading systems on historical data (`backtest`).
- Simulate trading systems with real-time data and virtual execution (`sandbox`).
- Deploy trading systems live on real or paper accounts (`live`).

The project's codebase provides a framework for implementing the software layer of systems which achieve the above. You will find
the default `backtest` and `live` system implementations in their respectively named subpackages. A `sandbox` environment can
be built using the sandbox adapter.

:::note

- All examples will utilize these default system implementations.
- We consider trading strategies to be subcomponents of end-to-end trading systems, these systems
include the application and infrastructure layers.

:::

## Distributed

The platform is designed to be easily integrated into a larger distributed system.
To facilitate this, nearly all configuration and domain objects can be serialized using JSON, MessagePack or Apache Arrow (Feather) for communication over the network.

## Common core

The common system core is utilized by all node [environment contexts](/concepts/architecture.md#environment-contexts) (`backtest`, `sandbox`, and `live`).
User-defined `Actor`, `Strategy` and `ExecAlgorithm` components are managed consistently across these environment contexts.

## Backtesting

Backtesting can be achieved by first making data available to a `BacktestEngine` either directly or via
a higher level `BacktestNode` and `ParquetDataCatalog`, and then running the data through the system with nanosecond resolution.

## Live trading

A `TradingNode` can ingest data and events from multiple data and execution clients.
Live deployments can use both demo/paper trading accounts, or real accounts.

For live trading, a `TradingNode` can ingest data and events from multiple data and execution clients.
The platform supports both demo/paper trading accounts and real accounts. High performance can be achieved by running
asynchronously on a single [event loop](https://docs.python.org/3/library/asyncio-eventloop.html),
with the potential to further boost performance by leveraging the [uvloop](https://github.com/MagicStack/uvloop) implementation (available for Linux and macOS).

## Domain model

The platform features a comprehensive trading domain model that includes various value types such as
`Price` and `Quantity`, as well as more complex entities such as `Order` and `Position` objects,
which are used to aggregate multiple events to determine state.

## Timestamps

All timestamps within the platform are recorded at nanosecond precision in UTC.

Timestamp strings follow ISO 8601 (RFC 3339) format with either 9 digits (nanoseconds) or 3 digits (milliseconds) of decimal precision,
(but mostly nanoseconds) always maintaining all digits including trailing zeros.
These can be seen in log messages, and debug/display outputs for objects.

A timestamp string consists of:

- Full date component always present: `YYYY-MM-DD`.
- `T` separator between date and time components.
- Always nanosecond precision (9 decimal places) or millisecond precision (3 decimal places) for certain cases such as GTD expiry times.
- Always UTC timezone designated by `Z` suffix.

Example: `2024-01-05T15:30:45.123456789Z`

For the complete specification, refer to [RFC 3339: Date and Time on the Internet](https://datatracker.ietf.org/doc/html/rfc3339).

## UUIDs

The platform uses Universally Unique Identifiers (UUID) version 4 (RFC 4122) for unique identifiers.
Our high-performance implementation leverages the `uuid` crate for correctness validation when parsing from strings,
ensuring input UUIDs comply with the specification.

A valid UUID v4 consists of:

- 32 hexadecimal digits displayed in 5 groups.
- Groups separated by hyphens: `8-4-4-4-12` format.
- Version 4 designation (indicated by the third group starting with "4").
- RFC 4122 variant designation (indicated by the fourth group starting with "8", "9", "a", or "b").

Example: `2d89666b-1a1e-4a75-b193-4eb3b454c757`

For the complete specification, refer to [RFC 4122: A Universally Unique IIdentifier (UUID) URN Namespace](https://datatracker.ietf.org/doc/html/rfc4122).

## Data types

The following market data types can be requested historically, and also subscribed to as live streams when available from a venue / data provider, and implemented in an integrations adapter.

- `OrderBookDelta` (L1/L2/L3)
- `OrderBookDeltas` (container type)
- `OrderBookDepth10` (fixed depth of 10 levels per side)
- `QuoteTick`
- `TradeTick`
- `Bar`
- `Instrument`
- `InstrumentStatus`
- `InstrumentClose`

The following `PriceType` options can be used for bar aggregations:

- `BID`
- `ASK`
- `MID`
- `LAST`

## Bar aggregations

The following `BarAggregation` methods are available:

- `MILLISECOND`
- `SECOND`
- `MINUTE`
- `HOUR`
- `DAY`
- `WEEK`
- `MONTH`
- `YEAR`
- `TICK`
- `VOLUME`
- `VALUE` (a.k.a Dollar bars)
- `RENKO` (price-based bricks)
- `TICK_IMBALANCE`
- `TICK_RUNS`
- `VOLUME_IMBALANCE`
- `VOLUME_RUNS`
- `VALUE_IMBALANCE`
- `VALUE_RUNS`

Currently implemented aggregations:

- `MILLISECOND`
- `SECOND`
- `MINUTE`
- `HOUR`
- `DAY`
- `WEEK`
- `MONTH`
- `YEAR`
- `TICK`
- `VOLUME`
- `VALUE`
- `RENKO`

Aggregations listed above that are not repeated in the implemented list are planned but not yet available.

The price types and bar aggregations can be combined with step sizes >= 1 in any way through a `BarSpecification`.
This enables maximum flexibility and now allows alternative bars to be aggregated for live trading.

## Account types

The following account types are available for both live and backtest environments:

- `Cash` single-currency (base currency)
- `Cash` multi-currency
- `Margin` single-currency (base currency)
- `Margin` multi-currency
- `Betting` single-currency

## Order types

The following order types are available (when possible on a venue):

- `MARKET`
- `LIMIT`
- `STOP_MARKET`
- `STOP_LIMIT`
- `MARKET_TO_LIMIT`
- `MARKET_IF_TOUCHED`
- `LIMIT_IF_TOUCHED`
- `TRAILING_STOP_MARKET`
- `TRAILING_STOP_LIMIT`

## Value types

The following value types are backed by either 128-bit or 64-bit raw integer values, depending on the
[precision mode](../getting_started/installation.md#precision-mode) used during compilation.

- `Price`
- `Quantity`
- `Money`

### High-precision mode (128-bit)

When the `high-precision` feature flag is **enabled** (default), values use the specification:

| Type         | Raw backing | Max precision | Min value           | Max value          |
|:-------------|:------------|:--------------|:--------------------|:-------------------|
| `Price`      | `i128`      | 16            | -17,014,118,346,046 | 17,014,118,346,046 |
| `Money`      | `i128`      | 16            | -17,014,118,346,046 | 17,014,118,346,046 |
| `Quantity`   | `u128`      | 16            | 0                   | 34,028,236,692,093 |

### Standard-precision mode (64-bit)

When the `high-precision` feature flag is **disabled**, values use the specification:

| Type         | Raw backing | Max precision | Min value           | Max value          |
|:-------------|:------------|:--------------|:--------------------|:-------------------|
| `Price`      | `i64`       | 9             | -9,223,372,036      | 9,223,372,036      |
| `Money`      | `i64`       | 9             | -9,223,372,036      | 9,223,372,036      |
| `Quantity`   | `u64`       | 9             | 0                   | 18,446,744,073     |

</document_content>
</document>
<document index="1455">
<source>docs/concepts/portfolio.md</source>
<document_content>
# Portfolio

:::info
We are currently working on this concept guide.
:::

The Portfolio serves as the central hub for managing and tracking all positions across active strategies for the trading node or backtest.
It consolidates position data from multiple instruments, providing a unified view of your holdings, risk exposure, and overall performance.
Explore this section to understand how NautilusTrader aggregates and updates portfolio state to support effective trading and risk management.

## Portfolio statistics

There are a variety of [built-in portfolio statistics](https://github.com/nautechsystems/nautilus_trader/tree/develop/crates/analysis/src/statistics)
which are used to analyse a trading portfolios performance for both backtests and live trading.

The statistics are generally categorized as follows.

- PnLs based statistics (per currency)
- Returns based statistics
- Positions based statistics
- Orders based statistics

It's also possible to call a traders `PortfolioAnalyzer` and calculate statistics at any arbitrary
time, including *during* a backtest, or live trading session.

## Custom statistics

Custom portfolio statistics can be defined by inheriting from the `PortfolioStatistic`
base class, and implementing any of the `calculate_` methods.

For example, the following is the implementation for the built-in `WinRate` statistic:

```python
import pandas as pd
from typing import Any
from nautilus_trader.analysis.statistic import PortfolioStatistic


class WinRate(PortfolioStatistic):
    """
    Calculates the win rate from a realized PnLs series.
    """

    def calculate_from_realized_pnls(self, realized_pnls: pd.Series) -> Any | None:
        # Preconditions
        if realized_pnls is None or realized_pnls.empty:
            return 0.0

        # Calculate statistic
        winners = [x for x in realized_pnls if x > 0.0]
        losers = [x for x in realized_pnls if x <= 0.0]

        return len(winners) / float(max(1, (len(winners) + len(losers))))
```

These statistics can then be registered with a traders `PortfolioAnalyzer`.

```python
stat = WinRate()

# Register with the portfolio analyzer
engine.portfolio.analyzer.register_statistic(stat)

:::info
See the `PortfolioAnalyzer` [API Reference](../api_reference/analysis.md#class-portfolioanalyzer) for details on available methods.
:::
```

:::tip
Ensure your statistic is robust to degenerate inputs such as ``None``, empty series, or insufficient data.

The expectation is that you would then return ``None``, NaN or a reasonable default.
:::

## Backtest analysis

Following a backtest run, a performance analysis will be carried out by passing realized PnLs, returns, positions and orders data to each registered
statistic in turn, calculating their values (with a default configuration). Any output is then displayed in the tear sheet
under the `Portfolio Performance` heading, grouped as.

- Realized PnL statistics (per currency)
- Returns statistics (for the entire portfolio)
- General statistics derived from position and order data (for the entire portfolio)

</document_content>
</document>
<document index="1456">
<source>docs/concepts/positions.md</source>
<document_content>
# Positions

This guide explains how positions work in NautilusTrader, including their lifecycle, aggregation
from order fills, profit and loss calculations, and the important concept of position snapshotting
for netting OMS configurations.

## Overview

A position represents an open exposure to a particular instrument in the market. Positions are
fundamental to tracking trading performance and risk, as they aggregate all fills for a particular
instrument and continuously calculate metrics like unrealized PnL, average entry price, and total
exposure.

The system automatically creates positions when orders fill and tracks them
from open to close. The platform supports both netting
and hedging position management styles through its OMS (Order Management System) configuration.

## Position lifecycle

### Creation

The system opens a position on the first fill:

- **NETTING OMS**: Opens on first fill for an instrument (one position per instrument).
- **HEDGING OMS**: Opens on first fill for a new `position_id` (multiple positions per instrument).

A position tracks:

- Opening order and fill details.
- Entry side (`LONG` or `SHORT`).
- Initial quantity and average price.
- Timestamps for initialization and opening.

:::tip
You can access positions through the Cache using `self.cache.position(position_id)` or
`self.cache.positions(instrument_id=instrument_id)` from within your actors/strategies.
:::

### Updates

As additional fills occur, the position:

- Aggregates quantities from buy and sell fills.
- Recalculates average entry and exit prices.
- Updates peak quantity (maximum exposure reached).
- Tracks all associated order IDs and trade IDs.
- Accumulates commissions by currency.

### Closure

A position closes when the net quantity becomes zero (`FLAT`). At closure:

- The closing order ID is recorded.
- Duration is calculated from open to close.
- Final realized PnL is computed.
- In `NETTING` OMS, the engine preserves closed position state through snapshots to maintain historical PnL (see [Position snapshotting](#position-snapshotting)).

## Order fill aggregation

Positions aggregate order fills to maintain an accurate view of market exposure. The aggregation
process handles both sides of trading activity:

### Buy fills

When a BUY order fills:

- Increases long exposure or reduces short exposure.
- Updates average entry price for opening trades.
- Updates average exit price for closing trades.
- Calculates realized PnL for any closed portion.

### Sell fills

When a SELL order fills:

- Increases short exposure or reduces long exposure.
- Updates average entry price for opening trades.
- Updates average exit price for closing trades.
- Calculates realized PnL for any closed portion.

### Net position calculation

The position maintains a `signed_qty` field representing the net exposure:

- Positive values indicate `LONG` positions.
- Negative values indicate `SHORT` positions.
- Zero indicates a `FLAT` (closed) position.

```python
# Example: Position aggregation
# Initial BUY 100 units at $50
signed_qty = +100  # LONG position

# Subsequent SELL 150 units at $55
signed_qty = -50   # Now SHORT position

# Final BUY 50 units at $52
signed_qty = 0     # Position FLAT (closed)
```

## Position adjustments

Position adjustments track quantity or PnL changes that occur outside of normal order fills,
ensuring the position quantity accurately reflects the true net asset position. The system
generates `PositionAdjusted` events for these scenarios.

### Base currency commissions

When trading spot currency pairs (e.g., BTC/USDT) or FX spot, commissions paid in the base
currency directly affect the net quantity received or delivered:

- **Opening fills**: Commission is deducted from the traded quantity. A buy of 1.0 BTC with
  -0.001 BTC commission results in a net long position of 0.999 BTC.
- **Closing fills**: Commission is applied to `signed_qty` because it affects actual inventory.
  Selling a 0.999 BTC LONG position with -0.000999 BTC commission leaves you SHORT 0.000999 BTC,
  not FLAT, because you gave up 0.999999 BTC total.
- **Flips**: Commission affects the final position size on both sides of the flip.

:::note
Base currency commissions only apply to spot currency pairs and FX spot instruments where the
commission currency matches `instrument.base_currency`. For other instruments, commissions are
tracked separately and do not affect position quantity.
:::

### Funding payments

Funding adjustments track periodic payments for perpetual futures without affecting position
quantity. These are logged with `quantity_change = None` and can include PnL impacts.

### Adjustment tracking

All adjustments are preserved in the position event history:

- `position.adjustments` returns the list of all `PositionAdjusted` events.
- Each adjustment includes type (`COMMISSION` or `FUNDING`), quantity change, and timestamps.
- The adjustment history is cleared when positions close and reopen. When events are purged,
  commission adjustments tied to the removed fills are regenerated while non-commission adjustments
  (for example funding) are preserved.

## OMS types and position management

NautilusTrader supports two primary OMS types that fundamentally affect how positions are tracked
and managed. An `OmsType.UNSPECIFIED` option also exists, which defaults to the component's
context. For comprehensive details, see the [Execution guide](execution.md#order-management-system-oms).

### `NETTING`

In `NETTING` mode, all fills for an instrument are aggregated into a single position:

- One position per instrument ID.
- All fills contribute to the same position.
- Position flips from `LONG` to `SHORT` (or vice versa) as net quantity changes.
- Historical snapshots preserve closed position states.

### `HEDGING`

In `HEDGING` mode, multiple positions can exist for the same instrument:

- Multiple simultaneous `LONG` and `SHORT` positions.
- Each position has a unique position ID.
- Positions are tracked independently.
- No automatic netting across positions.

:::warning
When using `HEDGING` mode, be aware of increased margin requirements as each position
consumes margin independently. Some venues may not support true hedging mode and will
net positions automatically.
:::

### Strategy vs venue OMS

The platform allows different OMS configurations for strategies and venues:

| Strategy OMS | Venue OMS | Behavior                                                    |
|--------------|-----------|-------------------------------------------------------------|
| `NETTING`    | `NETTING` | Single position per instrument at both strategy and venue.  |
| `HEDGING`    | `HEDGING` | Multiple positions supported at both levels.                |
| `NETTING`    | `HEDGING` | Venue tracks multiple, Nautilus maintains single position.  |
| `HEDGING`    | `NETTING` | Venue tracks single, Nautilus maintains virtual positions.  |

:::tip
For most trading scenarios, keeping strategy and venue OMS types aligned simplifies
position management. Override configurations are primarily useful for prop trading
desks or when interfacing with legacy systems. See the [Live guide](live.md)
for venue-specific OMS configuration.
:::

## Position snapshotting

Position snapshotting is an important feature for `NETTING` OMS configurations that preserves
the state of closed positions for accurate PnL tracking and reporting.

### Why snapshotting matters

In a `NETTING` system, when a position closes (becomes `FLAT`) and then reopens with a new trade,
the position object is reset to track the new exposure. Without snapshotting, the historical
realized PnL from the previous position cycle would be lost.

### How it works

When a `NETTING` position closes and then receives a new fill for the same instrument, the execution
engine snapshots the closed position state before resetting it, preserving:

- Final quantities and prices.
- Realized PnL.
- All fill events.
- Commission totals.

This snapshot is stored in the cache indexed by position ID. The position then resets for the new
cycle while previous snapshots remain accessible. The Portfolio aggregates PnL across all snapshots
for accurate totals.

:::note
This historical snapshot mechanism differs from optional position state snapshots (`snapshot_positions`),
which periodically record open-position state for telemetry. See the [Live guide](live.md) for
`snapshot_positions` and `snapshot_positions_interval_secs` settings.
:::

### Example scenario

```python
# NETTING OMS Example
# Cycle 1: Open LONG position
BUY 100 units at $50   # Position opens
SELL 100 units at $55  # Position closes, PnL = $500
# Snapshot taken preserving $500 realized PnL

# Cycle 2: Open SHORT position
SELL 50 units at $54   # Position reopens (SHORT)
BUY 50 units at $52    # Position closes, PnL = $100
# Snapshot taken preserving $100 realized PnL

# Total realized PnL = $500 + $100 = $600 (from snapshots)
```

Without snapshotting, only the most recent cycle's PnL would be available, leading to
incorrect reporting and analysis.

## PnL calculations

NautilusTrader provides comprehensive PnL calculations that account for instrument
specifications and market conventions.

### Realized PnL

Calculated when positions are partially or fully closed:

```python
# For standard instruments
realized_pnl = (exit_price - entry_price) * closed_quantity * multiplier

# For inverse instruments (side-aware)
# LONG: realized_pnl = closed_quantity * multiplier * (1/entry_price - 1/exit_price)
# SHORT: realized_pnl = closed_quantity * multiplier * (1/exit_price - 1/entry_price)
```

The engine automatically applies the correct formula based on position side.

### Unrealized PnL

Calculated using current market prices for open positions. The `price` parameter accepts any
reference price (bid, ask, mid, last, or mark):

```python
position.unrealized_pnl(last_price)  # Using last traded price
position.unrealized_pnl(bid_price)   # Conservative for LONG positions
position.unrealized_pnl(ask_price)   # Conservative for SHORT positions
```

### Total PnL

Combines realized and unrealized components:

```python
total_pnl = position.total_pnl(current_price)
# Returns realized_pnl + unrealized_pnl
```

### Currency considerations

- PnL is calculated in the instrument's settlement currency.
- For Forex, this is typically the quote currency.
- For inverse contracts, PnL may be in the base currency.
- Portfolio aggregates realized PnL per instrument in settlement currency.
- Multi-currency totals require conversion outside the Position class.

## Commissions and costs

Positions track all trading costs:

- Commissions are accumulated by currency.
- Each fill's commission is added to the running total.
- Multiple commission currencies are supported.
- Realized PnL includes commissions only when denominated in the settlement currency.
- Other commissions are tracked separately and may require conversion.

```python
commissions = position.commissions()
# Returns list[Money] with aggregated commission totals per currency

notional = position.notional_value(current_price)
# Returns Money in quote currency (standard) or base currency (inverse)
```

**Limitations:**

- Panics if inverse instrument has no `base_currency` set.
- Does not handle quanto contracts (returns quote currency instead of settlement currency).
- For quanto instruments, use `instrument.calculate_notional_value()` instead.

## Position properties and state

### Identifiers

- `id`: Unique position identifier.
- `instrument_id`: The traded instrument.
- `account_id`: Account where position is held.
- `trader_id`: The trader who owns the position.
- `strategy_id`: The strategy managing the position.
- `opening_order_id`: Client order ID that opened the position.
- `closing_order_id`: Client order ID that closed the position.

### Position state

- `side`: Current position side (`LONG`, `SHORT`, or `FLAT`).
- `entry`: Direction of the currently open position (`Buy` for `LONG`, `Sell` for `SHORT`). Updates when position flips direction.
- `quantity`: Current absolute position size.
- `signed_qty`: Signed position size (positive for `LONG`, negative for `SHORT`).
- `peak_qty`: Maximum quantity reached during position lifetime.
- `is_open`: Whether position is currently open.
- `is_closed`: Whether position is closed (`FLAT`).
- `is_long`: Whether position side is `LONG`.
- `is_short`: Whether position side is `SHORT`.

### Pricing and valuation

- `avg_px_open`: Average entry price.
- `avg_px_close`: Average exit price when closing.
- `realized_pnl`: Realized profit/loss.
- `realized_return`: Realized return as decimal (e.g., 0.05 for 5%).
- `quote_currency`: Quote currency of the instrument.
- `base_currency`: Base currency if applicable.
- `settlement_currency`: Currency for PnL settlement.

### Instrument specifications

- `multiplier`: Contract multiplier.
- `price_precision`: Decimal precision for prices.
- `size_precision`: Decimal precision for quantities.
- `is_inverse`: Whether instrument is inverse.

### Timestamps

- `ts_init`: When position was initialized.
- `ts_opened`: When position was opened.
- `ts_last`: Last update timestamp.
- `ts_closed`: When position was closed.
- `duration_ns`: Duration from open to close in nanoseconds.

### Associated data

- `symbol`: The instrument's ticker symbol.
- `venue`: The trading venue.
- `client_order_ids`: All client order IDs associated with position.
- `venue_order_ids`: All venue order IDs associated with position.
- `trade_ids`: All trade/fill IDs from venue.
- `events`: All order fill events applied to position.
- `event_count`: Total number of fill events applied.
- `last_event`: Most recent fill event.
- `last_trade_id`: Most recent trade ID.

:::info
For complete type information and detailed property documentation, see the Position
[API Reference](../api_reference/model/position.md#class-position).
:::

## Events and tracking

Positions maintain a complete history of events:

- All order fill events are stored chronologically.
- Associated client order IDs are tracked.
- Trade IDs from the venue are preserved.
- Event count indicates total fills applied.

This historical data enables:

- Detailed position analysis.
- Trade reconciliation.
- Performance attribution.
- Audit trails.

:::tip
Use `position.events` to access the full history of fills for reconciliation.
The `position.trade_ids` property helps match against broker statements.
See the [Execution guide](execution.md) for reconciliation best practices.
:::

## Numerical precision

Position calculations use 64-bit floating-point (`f64`) arithmetic for PnL and average price computations.
While fixed-point types (`Price`, `Quantity`, `Money`) preserve exact precision at configured decimal places,
internal calculations convert to `f64` for performance and overflow safety.

### Design rationale

The platform uses `f64` for position calculations to balance performance and accuracy:

- Floating-point operations are significantly faster than arbitrary-precision arithmetic.
- Raw integer multiplication can overflow even with 128-bit integers.
- Each calculation starts from precise fixed-point values, avoiding cumulative error.
- IEEE-754 double precision provides ~15 decimal digits of accuracy.

### Validated precision characteristics

Testing confirms `f64` arithmetic maintains accuracy for typical trading scenarios:

- Standard amounts: No precision loss for amounts ≥ 0.01 in standard currencies.
- High-precision instruments: 9-decimal crypto prices preserved within 1e-6 tolerance.
- Sequential fills: 100 fills show no drift (commission accuracy to 1e-10).
- Extreme prices: Handles range from 0.00001 to 99,999.99999 without overflow.
- Round-trip trades: Opening and closing at same price produces exact PnL (commissions only).

For implementation details, see `test_position_pnl_precision_*` tests in `crates/model/src/position.rs`.

:::note
For regulatory compliance or audit trails requiring exact decimal arithmetic, consider using `Decimal`
types from external libraries. Very small amounts below `f64` epsilon (~1e-15) may round to zero,
though this does not affect realistic trading scenarios with standard currency precisions.
:::

## Integration with other components

Positions interact with several key components:

- **Portfolio**: Aggregates positions across instruments and strategies.
- **ExecutionEngine**: Creates and updates positions from fills.
- **Cache**: Stores position state and snapshots.
- **RiskEngine**: Monitors position limits and exposure.

:::note
Positions are not created for spread instruments. While contingent orders can still trigger for spreads,
they operate without position linkage. The engine handles spread instruments separately from regular positions.
:::

## Summary

Positions are central to tracking trading activity and performance in NautilusTrader. Understanding
how positions aggregate fills, calculate PnL, and handle different OMS configurations is essential
for building robust trading strategies. The position snapshotting mechanism ensures accurate
historical tracking in `NETTING` mode, while the comprehensive event history supports detailed
analysis and reconciliation.

</document_content>
</document>
<document index="1457">
<source>docs/concepts/reports.md</source>
<document_content>
# Reports

:::info
We are currently working on this concept guide.
:::

This guide explains the portfolio analysis and reporting capabilities provided by the `ReportProvider`
class, and how these reports are used for PnL accounting and backtest post-run analysis.

## Overview

The `ReportProvider` class in NautilusTrader generates structured analytical reports from
trading data, transforming raw orders, fills, positions, and account states into pandas DataFrames
for analysis and visualization. These reports are essential for understanding strategy performance,
analyzing execution quality, and ensuring accurate PnL accounting.

Reports can be generated using two approaches:

- **Trader helper methods** (recommended): Convenient methods like `trader.generate_orders_report()`.
- **ReportProvider directly**: For more control over data selection and filtering.

Reports provide consistent analytics across both backtesting and live trading environments,
enabling reliable performance evaluation and strategy comparison.

## Available reports

The `ReportProvider` class offers several static methods to generate reports from trading data.
Each report returns a pandas DataFrame with specific columns and indexing for easy analysis.

### Orders report

Generates a comprehensive view of all orders:

```python
# Using Trader helper method (recommended)
orders_report = trader.generate_orders_report()

# Or using ReportProvider directly
from nautilus_trader.analysis.reporter import ReportProvider
orders = cache.orders()
orders_report = ReportProvider.generate_orders_report(orders)
```

**Returns `pd.DataFrame` with:**

| Column             | Description                                   |
|--------------------|-----------------------------------------------|
| `client_order_id`  | Index - unique order identifier.              |
| `instrument_id`    | Trading instrument.                           |
| `strategy_id`      | Strategy that created the order.              |
| `side`             | BUY or SELL.                                  |
| `type`             | MARKET, LIMIT, etc.                           |
| `status`           | Current order status.                         |
| `quantity`         | Original order quantity (string).             |
| `filled_qty`       | Amount filled (string).                       |
| `price`            | Limit price (string if set).                  |
| `avg_px`           | Average fill price (float if set).            |
| `ts_init`          | Order initialization timestamp (nanoseconds). |
| `ts_last`          | Last update timestamp (nanoseconds).          |

### Order fills report

Provides a summary of filled orders (one row per order):

```python
# Using Trader helper method (recommended)
fills_report = trader.generate_order_fills_report()

# Or using ReportProvider directly
orders = cache.orders()
fills_report = ReportProvider.generate_order_fills_report(orders)
```

This report includes only orders with `filled_qty > 0` and contains the same columns as the
orders report, but filtered to executed orders only. Note that `ts_init` and `ts_last` are
converted to datetime objects in this report for easier analysis.

### Fills report

Details individual fill events (one row per fill):

```python
# Using Trader helper method (recommended)
fills_report = trader.generate_fills_report()

# Or using ReportProvider directly
orders = cache.orders()
fills_report = ReportProvider.generate_fills_report(orders)
```

**Returns `pd.DataFrame` with:**

| Column             | Description                          |
|--------------------|--------------------------------------|
| `client_order_id`  | Index - order identifier.            |
| `trade_id`         | Unique trade/fill identifier.        |
| `venue_order_id`   | Venue-assigned order ID.             |
| `last_px`          | Fill execution price (string).       |
| `last_qty`         | Fill execution quantity (string).    |
| `liquidity_side`   | MAKER or TAKER.                      |
| `commission`       | Commission amount and currency.      |
| `ts_event`         | Fill timestamp (datetime).           |
| `ts_init`          | Initialization timestamp (datetime). |

### Positions report

Comprehensive position analysis including snapshots:

```python
# Using Trader helper method (recommended)
# Automatically includes snapshots for NETTING OMS
positions_report = trader.generate_positions_report()

# Or using ReportProvider directly
positions = cache.positions()
snapshots = cache.position_snapshots()  # For NETTING OMS
positions_report = ReportProvider.generate_positions_report(
    positions=positions,
    snapshots=snapshots
)
```

**Returns `pd.DataFrame` with:**

| Column             | Description                            |
|--------------------|----------------------------------------|
| `position_id`      | Index - unique position identifier.    |
| `instrument_id`    | Trading instrument.                    |
| `strategy_id`      | Strategy that managed the position.    |
| `entry`            | Entry side (BUY or SELL).              |
| `side`             | Position side (LONG, SHORT, or FLAT).  |
| `quantity`         | Position size.                         |
| `peak_qty`         | Maximum size reached.                  |
| `avg_px_open`      | Average entry price.                   |
| `avg_px_close`     | Average exit price (if closed).        |
| `realized_pnl`     | Realized profit/loss.                  |
| `realized_return`  | Return percentage.                     |
| `ts_opened`        | Opening timestamp (datetime).          |
| `ts_closed`        | Closing timestamp (datetime or NA).    |
| `duration_ns`      | Position duration in nanoseconds.      |
| `is_snapshot`      | Whether this is a historical snapshot. |

### Account report

Tracks account balance and margin changes over time:

```python
# Using Trader helper method (recommended)
# Requires venue parameter
from nautilus_trader.model.identifiers import Venue
venue = Venue("BINANCE")
account_report = trader.generate_account_report(venue)

# Or using ReportProvider directly
account = cache.account(account_id)
account_report = ReportProvider.generate_account_report(account)
```

**Returns `pd.DataFrame` with:**

| Column             | Description                                |
|--------------------|--------------------------------------------|
| `ts_event`         | Index - timestamp of account state change. |
| `account_id`       | Account identifier.                        |
| `account_type`     | Type of account (e.g., SPOT, MARGIN).      |
| `base_currency`    | Base currency for the account.             |
| `total`            | Total balance amount.                      |
| `free`             | Available balance.                         |
| `locked`           | Balance locked in orders.                  |
| `currency`         | Currency of the balance.                   |
| `reported`         | Whether balance was reported by venue.     |
| `margins`          | Margin information (if applicable).        |
| `info`             | Additional venue-specific information.     |

## PnL accounting considerations

Accurate PnL accounting requires careful consideration of several factors:

### Position-based PnL

- **Realized PnL**: Calculated when positions are partially or fully closed.
- **Unrealized PnL**: Marked-to-market using current prices.
- **Commission impact**: Only included when in settlement currency.

:::warning
PnL calculations depend on the OMS type. In `NETTING` mode, position snapshots
preserve historical PnL when positions reopen. Always include snapshots in
reports for accurate total PnL calculation.
:::

### Multi-currency accounting

When dealing with multiple currencies:

- Each position tracks PnL in its settlement currency.
- Portfolio aggregation requires currency conversion.
- Commission currencies may differ from settlement currency.

```python
# Accessing PnL across positions
for position in positions:
    realized = position.realized_pnl  # In settlement currency
    unrealized = position.unrealized_pnl(last_price)

    # Handle multi-currency aggregation (illustrative)
    # Note: Currency conversion requires user-provided exchange rates
    if position.settlement_currency != base_currency:
        # Apply conversion rate from your data source
        # rate = get_exchange_rate(position.settlement_currency, base_currency)
        # realized_converted = realized.as_double() * rate
        pass
```

### Snapshot considerations

For `NETTING` OMS configurations:

```python
from nautilus_trader.model.objects import Money

# Include snapshots for complete PnL (per currency)
pnl_by_currency = {}

# Add PnL from current positions
for position in cache.positions(instrument_id=instrument_id):
    if position.realized_pnl:
        currency = position.realized_pnl.currency
        if currency not in pnl_by_currency:
            pnl_by_currency[currency] = 0.0
        pnl_by_currency[currency] += position.realized_pnl.as_double()

# Add PnL from historical snapshots
for snapshot in cache.position_snapshots(instrument_id=instrument_id):
    if snapshot.realized_pnl:
        currency = snapshot.realized_pnl.currency
        if currency not in pnl_by_currency:
            pnl_by_currency[currency] = 0.0
        pnl_by_currency[currency] += snapshot.realized_pnl.as_double()

# Create Money objects for each currency
total_pnls = [Money(amount, currency) for currency, amount in pnl_by_currency.items()]
```

## Backtest post-run analysis

After a backtest completes, comprehensive analysis is available through various reports
and the portfolio analyzer.

### Accessing backtest results

```python
# After backtest run
engine.run(start=start_time, end=end_time)

# Generate reports using Trader helper methods
orders_report = engine.trader.generate_orders_report()
positions_report = engine.trader.generate_positions_report()
fills_report = engine.trader.generate_fills_report()

# Or access data directly for custom analysis
orders = engine.cache.orders()
positions = engine.cache.positions()
snapshots = engine.cache.position_snapshots()
```

### Portfolio statistics

The portfolio analyzer provides comprehensive performance metrics:

```python
# Access portfolio analyzer
portfolio = engine.portfolio

# Get different categories of statistics
stats_pnls = portfolio.analyzer.get_performance_stats_pnls()
stats_returns = portfolio.analyzer.get_performance_stats_returns()
stats_general = portfolio.analyzer.get_performance_stats_general()
```

:::info
For detailed information about available statistics and creating custom metrics,
see the [Portfolio guide](portfolio.md#portfolio-statistics). The Portfolio guide covers:

- Built-in statistics categories (PnLs, returns, positions, orders based).
- Creating custom statistics with `PortfolioStatistic`.
- Registering and using custom metrics.

:::

### Visualization

NautilusTrader provides interactive tearsheets and plots via Plotly:

```python
from nautilus_trader.analysis.tearsheet import create_tearsheet

# After backtest run
engine.run()

# Generate interactive HTML tearsheet
create_tearsheet(engine, output_path="tearsheet.html")
```

This creates an interactive HTML report with:

- Equity curve
- Drawdown analysis
- Monthly returns heatmap
- Performance statistics table
- Returns distribution

For more control, generate individual plots:

```python
from nautilus_trader.analysis.tearsheet import create_equity_curve

returns = engine.portfolio.analyzer.returns()
fig = create_equity_curve(returns, title="My Strategy Equity")
fig.show()  # Display in browser
fig.write_image("equity.png")  # Export to PNG (requires kaleido)
```

Install visualization dependencies:

```bash
uv pip install "nautilus_trader[visualization]"
```

## Report generation patterns

### Live trading

During live trading, generate reports periodically:

```python
import pandas as pd

class ReportingActor(Actor):
    def on_start(self):
        # Schedule periodic reporting
        self.clock.set_timer(
            name="generate_reports",
            interval=pd.Timedelta(minutes=30),
            callback=self.generate_reports
        )

    def generate_reports(self, event):
        # Generate and log reports
        positions_report = self.trader.generate_positions_report()

        # Save or transmit report
        positions_report.to_csv(f"positions_{event.ts_event}.csv")
```

### Performance analysis

For backtest analysis:

```python
import pandas as pd

# Run the backtest
engine.run(start=start_time, end=end_time)

# Collect comprehensive results
positions_closed = engine.cache.positions_closed()
stats_pnls = engine.portfolio.analyzer.get_performance_stats_pnls()
stats_returns = engine.portfolio.analyzer.get_performance_stats_returns()
stats_general = engine.portfolio.analyzer.get_performance_stats_general()

# Create summary dictionary
results = {
    "total_positions": len(positions_closed),
    "pnl_total": stats_pnls.get("PnL (total)"),
    "sharpe_ratio": stats_returns.get("Sharpe Ratio (252 days)"),
    "profit_factor": stats_general.get("Profit Factor"),
    "win_rate": stats_general.get("Win Rate"),
}

# Display results
results_df = pd.DataFrame([results])
print(results_df.T)  # Transpose for vertical display
```

:::info
Reports are generated from in-memory data structures. For large-scale analysis
or long-running systems, consider persisting reports to a database for efficient
querying. See the [Cache guide](cache.md) for persistence options.
:::

## Integration with other components

The `ReportProvider` works with several system components:

- **Cache**: Source of all trading data (orders, positions, accounts) for reports.
- **Portfolio**: Uses reports for performance analysis and metrics calculation.
- **BacktestEngine**: Leverages reports for post-run analysis and visualization.
- **Position snapshots**: Critical for accurate PnL reporting in `NETTING` OMS mode.

## Summary

The `ReportProvider` class offers a comprehensive suite of analytical reports for evaluating
trading performance. These reports transform raw trading data into structured DataFrames,
enabling detailed analysis of orders, fills, positions, and account states. Understanding
how to generate and interpret these reports is essential for strategy development,
performance evaluation, and accurate PnL accounting, particularly when dealing with
position snapshots in `NETTING` OMS configurations.

## Related guides

- [Visualization](visualization.md) - Learn how to create interactive tearsheets and charts from backtest results.
- [Portfolio](portfolio.md) - Explore portfolio statistics and performance metrics.
- [Backtesting](backtesting.md) - Learn how to run backtests that generate reports.
- [Cache](cache.md) - Understand the cache system that stores data for reports.

</document_content>
</document>
<document index="1458">
<source>docs/concepts/strategies.md</source>
<document_content>
# Strategies

The heart of the NautilusTrader user experience is in writing and working with
trading strategies. Defining a strategy involves inheriting the `Strategy` class and
implementing the methods required by the strategy's logic.

**Key capabilities**:

- All `Actor` capabilities.
- Order management.

**Relationship with actors**:
The `Strategy` class inherits from `Actor`, which means strategies have access to all actor functionality
plus order management capabilities.

:::tip
We recommend reviewing the [Actors](actors.md) guide before diving into strategy development.
:::

Strategies can be added to Nautilus systems in any [environment contexts](/concepts/architecture.md#environment-contexts) and will start sending commands and receiving
events based on their logic as soon as the system starts.

Using the basic building blocks of data ingest, event handling, and order management (which we will discuss
below), it's possible to implement any type of strategy including directional, momentum, re-balancing,
pairs, market making etc.

:::info
See the `Strategy` [API Reference](../api_reference/trading.md) for a complete description
of all available methods.
:::

There are two main parts of a Nautilus trading strategy:

- The strategy implementation itself, defined by inheriting the `Strategy` class.
- The *optional* strategy configuration, defined by inheriting the `StrategyConfig` class.

:::tip
Once a strategy is defined, the same source code can be used for backtesting and live trading.
:::

The main capabilities of a strategy include:

- Historical data requests.
- Live data feed subscriptions.
- Setting time alerts or timers.
- Cache access.
- Portfolio access.
- Creating and managing orders and positions.

## Strategy implementation

Since a trading strategy is a class which inherits from `Strategy`, you must define
a constructor where you can handle initialization. Minimally the base/super class needs to be initialized:

```python
from nautilus_trader.trading.strategy import Strategy

class MyStrategy(Strategy):
    def __init__(self) -> None:
        super().__init__()  # <-- the superclass must be called to initialize the strategy
```

From here, you can implement handlers as necessary to perform actions based on state transitions
and events.

:::warning
Do not call components such as `clock` and `logger` in the `__init__` constructor (which is prior to registration).
This is because the systems clock and logging subsystem have not yet been initialized.
:::

### Handlers

Handlers are methods within the `Strategy` class which may perform actions based on different types of events or on state changes.
These methods are named with the prefix `on_*`. You can choose to implement any or all of these handler
methods depending on the specific goals and needs of your strategy.

The purpose of having multiple handlers for similar types of events is to provide flexibility in handling granularity.
This means that you can choose to respond to specific events with a dedicated handler, or use a more generic
handler to react to a range of related events (using typical switch statement logic).
The handlers are called in sequence from the most specific to the most general.

#### Stateful actions

These handlers are triggered by lifecycle state changes of the `Strategy`. It's recommended to:

- Use the `on_start` method to initialize your strategy (e.g., fetch instruments, subscribe to data).
- Use the `on_stop` method for cleanup tasks (e.g., cancel open orders, close open positions, unsubscribe from data).

```python
def on_start(self) -> None:
def on_stop(self) -> None:
def on_resume(self) -> None:
def on_reset(self) -> None:
def on_dispose(self) -> None:
def on_degrade(self) -> None:
def on_fault(self) -> None:
def on_save(self) -> dict[str, bytes]:  # Returns user-defined dictionary of state to be saved
def on_load(self, state: dict[str, bytes]) -> None:
```

#### Data handling

These handlers receive data updates, including built-in market data and custom user-defined data.
You can use these handlers to define actions upon receiving data object instances.

```python
from nautilus_trader.core import Data
from nautilus_trader.model import OrderBook
from nautilus_trader.model import Bar
from nautilus_trader.model import QuoteTick
from nautilus_trader.model import TradeTick
from nautilus_trader.model import OrderBookDeltas
from nautilus_trader.model import InstrumentClose
from nautilus_trader.model import InstrumentStatus
from nautilus_trader.model.instruments import Instrument

def on_order_book_deltas(self, deltas: OrderBookDeltas) -> None:
def on_order_book(self, order_book: OrderBook) -> None:
def on_quote_tick(self, tick: QuoteTick) -> None:
def on_trade_tick(self, tick: TradeTick) -> None:
def on_bar(self, bar: Bar) -> None:
def on_instrument(self, instrument: Instrument) -> None:
def on_instrument_status(self, data: InstrumentStatus) -> None:
def on_instrument_close(self, data: InstrumentClose) -> None:
def on_historical_data(self, data: Data) -> None:
def on_data(self, data: Data) -> None:  # Custom data passed to this handler
def on_signal(self, signal: Data) -> None:  # Custom signals passed to this handler
```

#### Order management

These handlers receive events related to orders.
`OrderEvent` type messages are passed to handlers in the following sequence:

1. Specific handler (e.g., `on_order_accepted`, `on_order_rejected`, etc.)
2. `on_order_event(...)`
3. `on_event(...)`

```python
from nautilus_trader.model.events import OrderAccepted
from nautilus_trader.model.events import OrderCanceled
from nautilus_trader.model.events import OrderCancelRejected
from nautilus_trader.model.events import OrderDenied
from nautilus_trader.model.events import OrderEmulated
from nautilus_trader.model.events import OrderEvent
from nautilus_trader.model.events import OrderExpired
from nautilus_trader.model.events import OrderFilled
from nautilus_trader.model.events import OrderInitialized
from nautilus_trader.model.events import OrderModifyRejected
from nautilus_trader.model.events import OrderPendingCancel
from nautilus_trader.model.events import OrderPendingUpdate
from nautilus_trader.model.events import OrderRejected
from nautilus_trader.model.events import OrderReleased
from nautilus_trader.model.events import OrderSubmitted
from nautilus_trader.model.events import OrderTriggered
from nautilus_trader.model.events import OrderUpdated

def on_order_initialized(self, event: OrderInitialized) -> None:
def on_order_denied(self, event: OrderDenied) -> None:
def on_order_emulated(self, event: OrderEmulated) -> None:
def on_order_released(self, event: OrderReleased) -> None:
def on_order_submitted(self, event: OrderSubmitted) -> None:
def on_order_rejected(self, event: OrderRejected) -> None:
def on_order_accepted(self, event: OrderAccepted) -> None:
def on_order_canceled(self, event: OrderCanceled) -> None:
def on_order_expired(self, event: OrderExpired) -> None:
def on_order_triggered(self, event: OrderTriggered) -> None:
def on_order_pending_update(self, event: OrderPendingUpdate) -> None:
def on_order_pending_cancel(self, event: OrderPendingCancel) -> None:
def on_order_modify_rejected(self, event: OrderModifyRejected) -> None:
def on_order_cancel_rejected(self, event: OrderCancelRejected) -> None:
def on_order_updated(self, event: OrderUpdated) -> None:
def on_order_filled(self, event: OrderFilled) -> None:
def on_order_event(self, event: OrderEvent) -> None:  # All order event messages are eventually passed to this handler
```

#### Position management

These handlers receive events related to positions.
`PositionEvent` type messages are passed to handlers in the following sequence:

1. Specific handler (e.g., `on_position_opened`, `on_position_changed`, etc.)
2. `on_position_event(...)`
3. `on_event(...)`

```python
from nautilus_trader.model.events import PositionChanged
from nautilus_trader.model.events import PositionClosed
from nautilus_trader.model.events import PositionEvent
from nautilus_trader.model.events import PositionOpened

def on_position_opened(self, event: PositionOpened) -> None:
def on_position_changed(self, event: PositionChanged) -> None:
def on_position_closed(self, event: PositionClosed) -> None:
def on_position_event(self, event: PositionEvent) -> None:  # All position event messages are eventually passed to this handler
```

#### Generic event handling

This handler will eventually receive all event messages which arrive at the strategy, including those for
which no other specific handler exists.

```python
from nautilus_trader.core.message import Event

def on_event(self, event: Event) -> None:
```

#### Handler example

The following example shows a typical `on_start` handler method implementation (taken from the example EMA cross strategy).
Here we can see the following:

- Indicators being registered to receive bar updates.
- Historical data being requested (to hydrate the indicators).
- Live data being subscribed to.

```python
def on_start(self) -> None:
    """
    Actions to be performed on strategy start.
    """
    self.instrument = self.cache.instrument(self.instrument_id)
    if self.instrument is None:
        self.log.error(f"Could not find instrument for {self.instrument_id}")
        self.stop()
        return

    # Register the indicators for updating
    self.register_indicator_for_bars(self.bar_type, self.fast_ema)
    self.register_indicator_for_bars(self.bar_type, self.slow_ema)

    # Get historical data
    self.request_bars(self.bar_type)

    # Subscribe to live data
    self.subscribe_bars(self.bar_type)
    self.subscribe_quote_ticks(self.instrument_id)
```

### Clock and timers

Strategies have access to a `Clock` which provides a number of methods for creating
different timestamps, as well as setting time alerts or timers to trigger `TimeEvent`s.

:::info
See the `Clock` [API reference](../api_reference/common.md) for a complete list of available methods.
:::

#### Current timestamps

While there are multiple ways to obtain current timestamps, here are two commonly used methods as examples:

To get the current UTC timestamp as a tz-aware `pd.Timestamp`:

```python
import pandas as pd


now: pd.Timestamp = self.clock.utc_now()
```

To get the current UTC timestamp as nanoseconds since the UNIX epoch:

```python
unix_nanos: int = self.clock.timestamp_ns()
```

#### Time alerts

Time alerts can be set which will result in a `TimeEvent` being dispatched to the `on_event` handler at the
specified alert time. In a live context, this might be slightly delayed by a few microseconds.

This example sets a time alert to trigger one minute from the current time:

```python
import pandas as pd

# Fire a TimeEvent one minute from now
self.clock.set_time_alert(
    name="MyTimeAlert1",
    alert_time=self.clock.utc_now() + pd.Timedelta(minutes=1),
)
```

#### Timers

Continuous timers can be set up which will generate a `TimeEvent` at regular intervals until the timer expires
or is canceled.

This example sets a timer to fire once per minute, starting immediately:

```python
import pandas as pd

# Fire a TimeEvent every minute
self.clock.set_timer(
    name="MyTimer1",
    interval=pd.Timedelta(minutes=1),
)
```

### Cache access

The trader instances central `Cache` can be accessed to fetch data and execution objects (orders, positions etc).
There are many methods available often with filtering functionality, here we go through some basic use cases.

#### Fetching data

The following example shows how data can be fetched from the cache (assuming some instrument ID attribute is assigned):

```python
last_quote = self.cache.quote_tick(self.instrument_id)
last_trade = self.cache.trade_tick(self.instrument_id)
last_bar = self.cache.bar(bar_type)
```

#### Fetching execution objects

The following example shows how individual order and position objects can be fetched from the cache:

```python
order = self.cache.order(client_order_id)
position = self.cache.position(position_id)

```

:::info
See the `Cache` [API Reference](../api_reference/cache.md) for a complete description
of all available methods.
:::

### Portfolio access

The traders central `Portfolio` can be accessed to fetch account and positional information.
The following shows a general outline of available methods.

#### Account and positional information

```python
import decimal

from nautilus_trader.accounting.accounts.base import Account
from nautilus_trader.model import Venue
from nautilus_trader.model import Currency
from nautilus_trader.model import Money
from nautilus_trader.model import InstrumentId

def account(self, venue: Venue) -> Account

def balances_locked(self, venue: Venue) -> dict[Currency, Money]
def margins_init(self, venue: Venue) -> dict[Currency, Money]
def margins_maint(self, venue: Venue) -> dict[Currency, Money]
def unrealized_pnls(self, venue: Venue) -> dict[Currency, Money]
def realized_pnls(self, venue: Venue) -> dict[Currency, Money]
def net_exposures(self, venue: Venue) -> dict[Currency, Money]

def unrealized_pnl(self, instrument_id: InstrumentId) -> Money
def realized_pnl(self, instrument_id: InstrumentId) -> Money
def net_exposure(self, instrument_id: InstrumentId) -> Money
def net_position(self, instrument_id: InstrumentId) -> decimal.Decimal

def is_net_long(self, instrument_id: InstrumentId) -> bool
def is_net_short(self, instrument_id: InstrumentId) -> bool
def is_flat(self, instrument_id: InstrumentId) -> bool
def is_completely_flat(self) -> bool
```

:::info
See the `Portfolio` [API Reference](../api_reference/portfolio.md) for a complete description
of all available methods.
:::

#### Reports and analysis

The `Portfolio` also makes a `PortfolioAnalyzer` available, which can be fed with a flexible amount of data
(to accommodate different lookback windows). The analyzer can provide tracking for and generating of performance
metrics and statistics.

:::info
See the `PortfolioAnalyzer` [API Reference](../api_reference/analysis.md) for a complete description
of all available methods.
:::

:::info
See the [Portfolio statistics](portfolio.md#portfolio-statistics) guide.
:::

### Trading commands

NautilusTrader offers a comprehensive suite of trading commands, enabling granular order management
tailored for algorithmic trading. These commands are essential for executing strategies, managing risk,
and ensuring seamless interaction with various trading venues. In the following sections, we will
delve into the specifics of each command and its use cases.

:::info
The [Execution](../concepts/execution.md) guide explains the flow through the system, and can be helpful to read in conjunction with the below.
:::

#### Submitting orders

An `OrderFactory` is provided on the base class for every `Strategy` as a convenience, reducing
the amount of boilerplate required to create different `Order` objects (although these objects
can still be initialized directly with the `Order.__init__(...)` constructor if the trader prefers).

The component a `SubmitOrder` or `SubmitOrderList` command will flow to for execution depends on the following:

- If an `emulation_trigger` is specified, the command will *firstly* be sent to the `OrderEmulator`.
- If an `exec_algorithm_id` is specified (with no `emulation_trigger`), the command will *firstly* be sent to the relevant `ExecAlgorithm`.
- Otherwise, the command will *firstly* be sent to the `RiskEngine`.

This example submits a `LIMIT` BUY order for emulation (see [Emulated Orders](orders.md#emulated-orders)):

```python
from nautilus_trader.model.enums import OrderSide
from nautilus_trader.model.enums import TriggerType
from nautilus_trader.model.orders import LimitOrder


def buy(self) -> None:
    """
    Users simple buy method (example).
    """
    order: LimitOrder = self.order_factory.limit(
        instrument_id=self.instrument_id,
        order_side=OrderSide.BUY,
        quantity=self.instrument.make_qty(self.trade_size),
        price=self.instrument.make_price(5000.00),
        emulation_trigger=TriggerType.LAST_PRICE,
    )

    self.submit_order(order)
```

:::info
You can specify both order emulation and an execution algorithm.
:::

This example submits a `MARKET` BUY order to a TWAP execution algorithm:

```python
from nautilus_trader.model.enums import OrderSide
from nautilus_trader.model.enums import TimeInForce
from nautilus_trader.model import ExecAlgorithmId


def buy(self) -> None:
    """
    Users simple buy method (example).
    """
    order: MarketOrder = self.order_factory.market(
        instrument_id=self.instrument_id,
        order_side=OrderSide.BUY,
        quantity=self.instrument.make_qty(self.trade_size),
        time_in_force=TimeInForce.FOK,
        exec_algorithm_id=ExecAlgorithmId("TWAP"),
        exec_algorithm_params={"horizon_secs": 20, "interval_secs": 2.5},
    )

    self.submit_order(order)
```

#### Canceling orders

Orders can be canceled individually, as a batch, or all orders for an instrument (with an optional side filter).

If the order is already *closed* or already pending cancel, then a warning will be logged.

If the order is currently *open* then the status will become `PENDING_CANCEL`.

The component a `CancelOrder`, `CancelAllOrders` or `BatchCancelOrders` command will flow to for execution depends on the following:

- If the order is currently emulated, the command will *firstly* be sent to the `OrderEmulator`.
- If an `exec_algorithm_id` is specified (with no `emulation_trigger`), and the order is still active within the local system, the command will *firstly* be sent to the relevant `ExecAlgorithm`.
- Otherwise, the order will *firstly* be sent to the `ExecutionEngine`.

:::info
Any managed GTD timer will also be canceled after the command has left the strategy.
:::

The following shows how to cancel an individual order:

```python

self.cancel_order(order)

```

The following shows how to cancel a batch of orders:

```python
from nautilus_trader.model import Order


my_order_list: list[Order] = [order1, order2, order3]
self.cancel_orders(my_order_list)

```

The following shows how to cancel all orders:

```python

self.cancel_all_orders()

```

#### Modifying orders

Orders can be modified individually when emulated, or *open* on a venue (if supported).

If the order is already *closed* or already pending cancel, then a warning will be logged.
If the order is currently *open* then the status will become `PENDING_UPDATE`.

:::warning
At least one value must differ from the original order for the command to be valid.
:::

The component a `ModifyOrder` command will flow to for execution depends on the following:

- If the order is currently emulated, the command will *firstly* be sent to the `OrderEmulator`.
- Otherwise, the order will *firstly* be sent to the `RiskEngine`.

:::info
Once an order is under the control of an execution algorithm, it cannot be directly modified by a strategy (only canceled).
:::

The following shows how to modify the size of `LIMIT` BUY order currently *open* on a venue:

```python
from nautilus_trader.model import Quantity


new_quantity: Quantity = Quantity.from_int(5)
self.modify_order(order, new_quantity)

```

:::info
The price and trigger price can also be modified (when emulated or supported by a venue).
:::

## Strategy configuration

The main purpose of a separate configuration class is to provide total flexibility
over where and how a trading strategy can be instantiated. This includes being able
to serialize strategies and their configurations over the wire, making distributed backtesting
and firing up remote live trading possible.

This configuration flexibility is actually opt-in, in that you can actually choose not to have
any strategy configuration beyond the parameters you choose to pass into your
strategies' constructor. If you would like to run distributed backtests or launch
live trading servers remotely, then you will need to define a configuration.

Here is an example configuration:

```python
from decimal import Decimal
from nautilus_trader.config import StrategyConfig
from nautilus_trader.model import Bar, BarType
from nautilus_trader.model import InstrumentId
from nautilus_trader.trading.strategy import Strategy


# Configuration definition
class MyStrategyConfig(StrategyConfig):
    instrument_id: InstrumentId   # example value: "ETHUSDT-PERP.BINANCE"
    bar_type: BarType             # example value: "ETHUSDT-PERP.BINANCE-15-MINUTE[LAST]-EXTERNAL"
    fast_ema_period: int = 10
    slow_ema_period: int = 20
    trade_size: Decimal
    order_id_tag: str


# Strategy definition
class MyStrategy(Strategy):
    def __init__(self, config: MyStrategyConfig) -> None:
        # Always initialize the parent Strategy class
        # After this, configuration is stored and available via `self.config`
        super().__init__(config)

        # Custom state variables
        self.time_started = None
        self.count_of_processed_bars: int = 0

    def on_start(self) -> None:
        self.time_started = self.clock.utc_now()    # Remember time, when strategy started
        self.subscribe_bars(self.config.bar_type)   # See how configuration data are exposed via `self.config`

    def on_bar(self, bar: Bar):
        self.count_of_processed_bars += 1           # Update count of processed bars


# Instantiate configuration with specific values. By setting:
#   - InstrumentId - we parameterize the instrument the strategy will trade.
#   - BarType - we parameterize bar-data, that strategy will trade.
config = MyStrategyConfig(
    instrument_id=InstrumentId.from_str("ETHUSDT-PERP.BINANCE"),
    bar_type=BarType.from_str("ETHUSDT-PERP.BINANCE-15-MINUTE[LAST]-EXTERNAL"),
    trade_size=Decimal(1),
    order_id_tag="001",
)

# Pass configuration to our trading strategy.
strategy = MyStrategy(config=config)
```

When implementing strategies, it's recommended to access configuration values directly through `self.config`.
This provides clear separation between:

- Configuration data (accessed via `self.config`):
  - Contains initial settings, that define how the strategy works.
  - Example: `self.config.trade_size`, `self.config.instrument_id`

- Strategy state variables (as direct attributes):
  - Track any custom state of the strategy.
  - Example: `self.time_started`, `self.count_of_processed_bars`

This separation makes code easier to understand and maintain.

:::note
Even though it often makes sense to define a strategy which will trade a single
instrument. The number of instruments a single strategy can work with is only limited by machine resources.
:::

### Managed GTD expiry

It's possible for the strategy to manage expiry for orders with a time in force of GTD (*Good 'till Date*).
This may be desirable if the exchange/broker does not support this time in force option, or for any
reason you prefer the strategy to manage this.

To use this option, pass `manage_gtd_expiry=True` to your `StrategyConfig`. When an order is submitted with
a time in force of GTD, the strategy will automatically start an internal time alert.
Once the internal GTD time alert is reached, the order will be canceled (if not already *closed*).

Some venues (such as Binance Futures) support the GTD time in force, so to avoid conflicts when using
`managed_gtd_expiry` you should set `use_gtd=False` for your execution client config.

### Multiple strategies

If you intend running multiple instances of the same strategy, with different
configurations (such as trading different instruments), then you will need to define
a unique `order_id_tag` for each of these strategies (as shown above).

:::note
The platform has built-in safety measures in the event that two strategies share a
duplicated strategy ID, then an exception will be raised that the strategy ID has already been registered.
:::

The reason for this is that the system must be able to identify which strategy
various commands and events belong to. A strategy ID is made up of the
strategy class name, and the strategies `order_id_tag` separated by a hyphen. For
example the above config would result in a strategy ID of `MyStrategy-001`.

:::note
See the `StrategyId` [API Reference](../api_reference/model/identifiers.md) for further details.
:::

</document_content>
</document>
<document index="1459">
<source>docs/concepts/visualization.md</source>
<document_content>
# Visualization

NautilusTrader provides interactive HTML tearsheets for analyzing backtest results through
an extensible visualization system built on Plotly. The system emphasizes configurability
and extensibility, allowing you to generate comprehensive performance reports with minimal
code while maintaining the flexibility to add custom charts and themes.

## Overview

The visualization system is built on three core pillars:

1. **Chart Registry** - Decoupled chart definitions that can be extended with custom visualizations.
2. **Theme System** - Consistent styling with built-in and custom themes.
3. **Configuration** - Declarative specification of what to render and how to display it.

All visualization outputs are self-contained HTML files that can be viewed in any modern
browser, shared with stakeholders, or archived for future reference.

:::note
The visualization system requires `plotly>=6.3.1`. Install it with:

```bash
uv pip install "nautilus_trader[visualization]"
```

or

```bash
uv pip install "plotly>=6.3.1"
```

:::

## Tearsheets

A tearsheet is a comprehensive performance report that combines multiple charts and
statistics into a single interactive visualization. Tearsheets are generated after
completing a backtest run and provide immediate visual feedback on strategy performance.

### Quick start

Generate a tearsheet with default settings:

```python
from nautilus_trader.backtest.engine import BacktestEngine

# After running your backtest
engine.run()

# Generate tearsheet
from nautilus_trader.analysis.tearsheet import create_tearsheet

create_tearsheet(
    engine=engine,
    output_path="backtest_results.html",
)
```

This produces an HTML file with all default charts, using the light theme and automatic
layout. Open `backtest_results.html` in your browser to view the interactive tearsheet.

### Customization

Control which charts appear and how they're styled:

```python
from nautilus_trader.analysis import TearsheetConfig

config = TearsheetConfig(
    charts=["run_info", "stats_table", "equity", "drawdown"],
    theme="nautilus_dark",
    height=2000,
)

create_tearsheet(
    engine=engine,
    output_path="custom_tearsheet.html",
    config=config,
)
```

### Currency filtering

For multi-currency backtests, filter statistics to a specific currency:

```python
from nautilus_trader.model.currencies import USD

create_tearsheet(
    engine=engine,
    output_path="usd_only.html",
    currency=USD,  # Show only USD statistics
)
```

When `currency` is `None` (default), all currencies are displayed in the tearsheet.

## Available charts

The tearsheet can include any combination of the following built-in charts:

| Chart Name         | Type         | Description                                              |
|--------------------|--------------|----------------------------------------------------------|
| `run_info`         | Table        | Run metadata and account balances.                       |
| `stats_table`      | Table        | Performance statistics (PnL, returns, general metrics).  |
| `equity`           | Line         | Cumulative returns over time with optional benchmark.    |
| `drawdown`         | Area         | Drawdown percentage from peak equity.                    |
| `monthly_returns`  | Heatmap      | Monthly return percentages organized by year.            |
| `distribution`     | Histogram    | Distribution of individual return values.                |
| `rolling_sharpe`   | Line         | 60-day rolling Sharpe ratio.                             |
| `yearly_returns`   | Bar          | Annual return percentages.                               |
| `bars_with_fills`  | Candlestick  | Price bars (OHLC) with order fills overlaid as bars.     |

All charts are registered in the chart registry and can be referenced by name in
`TearsheetConfig.charts`.

### Run information table

The `run_info` chart displays critical metadata about the backtest run:

- Run ID, start time, finish time
- Backtest period (start/end dates)
- Total iterations processed
- Event, order, and position counts
- Account starting and ending balances (per currency)

This table appears in the top-left position by default.

### Performance statistics table

The `stats_table` chart displays comprehensive performance metrics organized into sections:

- **PnL Statistics** (per currency): Total PnL, win rate, profit factor, etc.
- **Returns Statistics**: Sharpe ratio, Sortino ratio, max drawdown, etc.
- **General Statistics**: Total trades, average trade duration, etc.

This table appears in the top-right position by default.

### Equity curve

The `equity` chart plots cumulative returns over the backtest period. When `benchmark_returns`
is provided to `create_tearsheet()`, the benchmark is overlaid for comparison.

```python
import pandas as pd

# Load benchmark returns (e.g., from a market index)
benchmark_returns = pd.read_csv("sp500_returns.csv", index_col=0)["return"]

create_tearsheet(
    engine=engine,
    output_path="with_benchmark.html",
    benchmark_returns=benchmark_returns,
    benchmark_name="S&P 500",
)
```

## Themes

Themes control the visual styling of charts including colors, fonts, and backgrounds.
NautilusTrader provides four built-in themes:

| Theme Name      | Description                                    | Use Case                      |
|-----------------|------------------------------------------------|-------------------------------|
| `plotly_white`  | Clean light theme with dark gray headers.      | Default, professional reports.|
| `plotly_dark`   | Dark background with standard Plotly colors.   | Low-light environments.       |
| `nautilus`      | Light theme with NautilusTrader brand colors.  | Official light mode.          |
| `nautilus_dark` | Dark theme with teal/cyan signature colors.    | Official dark mode.           |

### Selecting a theme

Specify the theme in `TearsheetConfig`:

```python
config = TearsheetConfig(theme="nautilus_dark")
create_tearsheet(engine=engine, config=config)
```

### Custom themes

Register a custom theme for consistent branding across all visualizations:

```python
from nautilus_trader.analysis.themes import register_theme

register_theme(
    name="corporate",
    template="plotly_white",  # Base Plotly template
    colors={
        "primary": "#003366",      # Navy blue
        "positive": "#2e8b57",     # Sea green
        "negative": "#c41e3a",     # Cardinal red
        "neutral": "#808080",      # Gray
        "background": "#ffffff",   # White
        "grid": "#e5e5e5",         # Light gray
        # Optional table colors (defaults will be provided if omitted)
        "table_section": "#e5e5e5",
        "table_row_odd": "#f8f8f8",
        "table_row_even": "#ffffff",
        "table_text": "#000000",
    }
)

# Use the custom theme
config = TearsheetConfig(theme="corporate")
```

The theme system automatically provides sensible defaults for `table_*` colors based on
the `background` and `grid` colors, ensuring backward compatibility with themes registered
before table-specific colors were introduced.

## Configuration

The `TearsheetConfig` class provides declarative control over tearsheet generation:

```python
from nautilus_trader.analysis import TearsheetConfig, GridLayout

config = TearsheetConfig(
    charts=["equity", "drawdown", "stats_table"],
    theme="nautilus_dark",
    title="Q4 2024 Strategy Performance",
    height=1800,
    include_benchmark=True,
    benchmark_name="SPY",
    layout=GridLayout(
        rows=2,
        cols=2,
        heights=[0.60, 0.40],
        vertical_spacing=0.08,
        horizontal_spacing=0.12,
    ),
)
```

### Configuration parameters

| Parameter           | Type                          | Default                           | Description                                   |
|---------------------|-------------------------------|-----------------------------------|-----------------------------------------------|
| `charts`            | `list[str]`                   | All built-in charts               | List of chart names to include.               |
| `theme`             | `str`                         | `"plotly_white"`                  | Theme name for styling.                       |
| `layout`            | `GridLayout`                  | `None` (auto-calculated)          | Custom subplot grid layout.                   |
| `title`             | `str`                         | Auto-generated with strategy/time | Tearsheet title.                              |
| `include_benchmark` | `bool`                        | `True`                            | Show benchmark when provided.                 |
| `benchmark_name`    | `str`                         | `"Benchmark"`                     | Display name for benchmark.                   |
| `height`            | `int`                         | `1500`                            | Total height in pixels.                       |
| `show_logo`         | `bool`                        | `True`                            | Display NautilusTrader logo (not implemented).|
| `chart_args`        | `dict[str, dict[str, Any]]`   | `None`                            | Arguments for specific charts (e.g., `bar_type` for `bars_with_fills`).|

When `layout` is `None`, the grid dimensions and row heights are automatically calculated
based on the number of charts. For 8 charts (the default), a 4×2 grid is used with
heights `[0.50, 0.22, 0.16, 0.12]` to give more space to the top row tables.

## Custom charts

The registry pattern makes adding custom charts straightforward. Charts are functions that
render traces onto a Plotly figure object.

### Registering a custom chart

```python
from nautilus_trader.analysis.tearsheet import register_chart
import plotly.graph_objects as go

def my_custom_chart(returns, output_path=None, title="Custom Chart", theme="plotly_white"):
    """
    Create a custom visualization.

    This function signature matches the built-in chart functions for consistency.
    """
    from nautilus_trader.analysis.themes import get_theme

    theme_config = get_theme(theme)

    # Create your visualization
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=returns.index,
        y=returns.cumsum(),
        mode="lines",
        name="Custom Metric",
        line={"color": theme_config["colors"]["primary"]},
    ))

    fig.update_layout(
        title=title,
        template=theme_config["template"],
        xaxis_title="Date",
        yaxis_title="Value",
    )

    if output_path:
        fig.write_html(output_path)

    return fig

# Register the chart for use in tearsheets
register_chart("my_custom", my_custom_chart)

# Include it in tearsheet config
config = TearsheetConfig(
    charts=["stats_table", "equity", "my_custom"],
)
```

### Tearsheet integration

For full tearsheet integration with proper grid placement, use the lower-level registration:

```python
from nautilus_trader.analysis.tearsheet import _register_tearsheet_chart

def _render_my_metric(fig, row, col, returns, theme_config, **kwargs):
    """
    Render custom metric directly onto a subplot.

    Parameters
    ----------
    fig : go.Figure
        The figure to add traces to.
    row : int
        Subplot row position.
    col : int
        Subplot column position.
    returns : pd.Series
        Strategy returns from analyzer.
    theme_config : dict
        Theme configuration dictionary.
    **kwargs : dict
        Additional parameters (stats_pnls, stats_returns, benchmark_returns, etc.).
    """
    metric_values = returns.rolling(30).std() * 100  # Example metric

    fig.add_trace(
        go.Scatter(
            x=returns.index,
            y=metric_values,
            mode="lines",
            name="30-Day Volatility",
            line={"color": theme_config["colors"]["neutral"]},
        ),
        row=row,
        col=col,
    )

    fig.update_xaxes(title_text="Date", row=row, col=col)
    fig.update_yaxes(title_text="Volatility (%)", row=row, col=col)

# Register for tearsheet use
_register_tearsheet_chart(
    name="volatility",
    subplot_type="scatter",
    title="Rolling Volatility (30-day)",
    renderer=_render_my_metric,
)

# Now "volatility" can be used in TearsheetConfig.charts
```

The renderer function receives all necessary data (returns, statistics, theme configuration)
and renders directly onto the specified subplot position.

## Offline analysis

For situations where you have precomputed statistics but not a `BacktestEngine` instance,
use the lower-level API:

```python
from nautilus_trader.analysis.tearsheet import create_tearsheet_from_stats

# Load precomputed data
stats_pnls = {"USD": {...}}  # Per-currency PnL statistics
stats_returns = {...}         # Returns-based statistics
stats_general = {...}         # General statistics
returns = pd.Series(...)      # Returns series

create_tearsheet_from_stats(
    stats_pnls=stats_pnls,
    stats_returns=stats_returns,
    stats_general=stats_general,
    returns=returns,
    output_path="offline_analysis.html",
)
```

This approach is useful for:

- Analyzing results from multiple backtest runs stored separately.
- Comparing strategies using precomputed metrics.
- Integrating with external analysis pipelines.

## Best practices

### Chart selection

- Use default charts for exploratory analysis to see all available metrics.
- Customize charts when you know which metrics matter for your strategy.
- Remove irrelevant charts to reduce visual clutter and file size.

### Theme usage

- Use `plotly_white` for professional reports and presentations.
- Use `nautilus_dark` for official materials or low-light viewing.
- Create custom themes to match internal guidelines or personal preferences.

### Performance considerations

- Tearsheet HTML files contain all data inline and can be several megabytes for long backtests.
- Consider generating separate tearsheets for different analysis timeframes.
- For very large datasets, use the individual chart functions instead of full tearsheets.

### Custom statistics integration

Custom charts work best when paired with [custom statistics](reports.md) registered in the
`PortfolioAnalyzer`. This ensures your visualizations display metrics computed consistently
with the rest of the system:

```python
from nautilus_trader.analysis.statistic import PortfolioStatistic

class MyCustomStatistic(PortfolioStatistic):
    """Custom metric for specialized strategy analysis."""

    def calculate_from_returns(self, returns):
        # Your calculation logic
        return custom_metric_value

# Register with analyzer
analyzer.register_statistic(MyCustomStatistic())

# Now available in stats_returns for custom charts
```

## API levels

The visualization system provides two API levels:

### High-level API

Recommended for most use cases:

```python
create_tearsheet(engine=engine, config=config)
```

Automatically extracts data from the `BacktestEngine`, generates all configured charts,
and produces a complete HTML tearsheet.

### Low-level API

For advanced customization or offline analysis:

```python
create_tearsheet_from_stats(
    stats_pnls=stats_pnls,
    stats_returns=stats_returns,
    stats_general=stats_general,
    returns=returns,
    run_info=run_info,
    account_info=account_info,
    config=config,
)
```

Provides fine-grained control over data inputs and allows analysis of precomputed statistics.

### Standalone chart functions

Individual chart functions can be used independently to generate single-purpose HTML visualizations
or Plotly figures for custom analysis workflows.

#### Price bars with fills

The `create_bars_with_fills` function generates a candlestick chart with order fills overlaid,
useful for visually analyzing strategy execution within price action. It can be used standalone
or included in tearsheets:

```python
from nautilus_trader.analysis.tearsheet import create_bars_with_fills
from nautilus_trader.model.data import BarType

# Standalone usage
bar_type = BarType.from_str("ESM4.XCME-1-MINUTE-LAST-EXTERNAL")
fig = create_bars_with_fills(
    engine=engine,
    bar_type=bar_type,
    title="ES Futures - Entry/Exit Analysis",
)
fig.show()  # Display in Jupyter
fig.write_html("bars_with_fills.html")  # Or save to file

# Include in tearsheet
config = TearsheetConfig(
    charts=["stats_table", "equity", "bars_with_fills"],
    chart_args={
        "bars_with_fills": {"bar_type": "ESM4.XCME-1-MINUTE-LAST-EXTERNAL"},
    },
)
create_tearsheet(engine=engine, config=config)
```

The visualization shows candlesticks for OHLC price action with vertical bars representing order fills
(colored by buy/sell side). The `chart_args` parameter in `TearsheetConfig` allows passing custom
arguments to charts that require additional configuration beyond standard tearsheet data.

Other individual chart functions include `create_equity_curve`, `create_drawdown_chart`,
`create_monthly_returns_heatmap`, and more. See the API reference for the complete list.

## Related guides

- [Backtesting](backtesting.md) - Learn how to run backtests that generate tearsheets.
- [Reports](reports.md) - Understand the underlying statistics displayed in tearsheets.
- [Portfolio](portfolio.md) - Explore portfolio tracking and performance metrics.

</document_content>
</document>
<document index="1462">
<source>docs/developer_guide/benchmarking.md</source>
<document_content>
# Benchmarking

This guide explains how NautilusTrader measures Rust performance, when to
use each tool and the conventions you should follow when adding new benches.

---

## Tooling overview

NautilusTrader relies on **two complementary benchmarking frameworks**:

| Framework | What is it? | What it measures | When to prefer it |
|-----------|-------------|------------------|-------------------|
| [**Criterion**](https://docs.rs/criterion/latest/criterion/) | Statistical benchmark harness that produces detailed HTML reports and performs outlier detection. | Wall-clock run time with confidence intervals. | End-to-end scenarios, anything slower than ≈100 ns, visual comparisons. |
| [**iai**](https://docs.rs/iai/latest/iai/) | Deterministic micro-benchmark harness that counts retired CPU instructions via hardware counters. | Exact instruction counts (noise-free). | Ultra-fast functions, CI gating via instruction diff. |

Most hot code paths benefit from **both** kinds of measurements.

---

## Directory layout

Each crate keeps its performance tests in a local `benches/` folder:

```text
crates/<crate_name>/
└── benches/
    ├── foo_criterion.rs   # Criterion group(s)
    └── foo_iai.rs         # iai micro benches
```

`Cargo.toml` must list every benchmark explicitly so `cargo bench` discovers
them:

```toml
[[bench]]
name = "foo_criterion"             # file stem in benches/
path = "benches/foo_criterion.rs"
harness = false                    # disable the default libtest harness
```

---

## Writing Criterion benchmarks

1. Perform **all expensive set-up outside** the timing loop (`b.iter`).
2. Wrap inputs/outputs in `black_box` to prevent the optimizer from removing
   work.
3. Group related cases with `benchmark_group!` and set `throughput` or
   `sample_size` when the defaults aren’t ideal.

```rust
use std::hint::black_box;

use criterion::{Criterion, criterion_group, criterion_main};

fn bench_my_algo(c: &mut Criterion) {
    let data = prepare_data(); // heavy set-up done once

    c.bench_function("my_algo", |b| {
        b.iter(|| my_algo(black_box(&data)));
    });
}

criterion_group!(benches, bench_my_algo);
criterion_main!(benches);
```

---

## Writing iai benchmarks

`iai` requires functions that take **no parameters** and return a value (which
can be ignored). Keep them as small as possible so the measured instruction
count is meaningful.

```rust
use std::hint::black_box;

fn bench_add() -> i64 {
    let a = black_box(123);
    let b = black_box(456);
    a + b
}

iai::main!(bench_add);
```

---

## Running benches locally

- **Single crate**: `cargo bench -p nautilus-core`.
- **Single benchmark module**: `cargo bench -p nautilus-core --bench time`.
- **CI performance benches**: `make cargo-ci-benches` (runs the crates included
  in the CI performance workflow one at a time to avoid the mixed-panic-strategy
  linker issue).

Criterion writes HTML reports to `target/criterion/`; open `target/criterion/report/index.html` in your browser.

### Generating a flamegraph

`cargo-flamegraph` lets you see a sampled call-stack profile of a single
benchmark. On Linux it uses `perf`, and on macOS it uses `DTrace`.

1. Install `cargo-flamegraph` once per machine (it installs a `cargo flamegraph`
   subcommand automatically).

   ```bash
   cargo install flamegraph
   ```

2. Run a specific bench with the symbol-rich `bench` profile.

   ```bash
   # example: the matching benchmark in nautilus-common
   cargo flamegraph --bench matching -p nautilus-common --profile bench
   ```

3. Open the generated `flamegraph.svg` in your browser and zoom into hot paths.

#### Linux

On Linux, `perf` must be available. On Debian/Ubuntu, you can install it with:

```bash
sudo apt install linux-tools-common linux-tools-$(uname -r)
```

If you see an error mentioning `perf_event_paranoid` you need to relax the
kernel’s perf restrictions for the current session (root required):

```bash
sudo sh -c 'echo 1 > /proc/sys/kernel/perf_event_paranoid'
```

A value of `1` is typically enough; set it back to `2` (default) or make
the change permanent via `/etc/sysctl.conf` if desired.

#### macOS

On macOS, `DTrace` requires root permissions, so you must run `cargo flamegraph`
with `sudo`:

```bash
# Note the use of sudo
sudo cargo flamegraph --bench matching -p nautilus-common --profile bench
```

> **Warning**
> Running with `sudo` will create files in your `target/` directory that are
> owned by the `root` user. This can cause permission errors with subsequent
> `cargo` commands.
>
> To fix this, you may need to remove the root-owned files manually, or simply
> run `sudo cargo clean` to remove the entire `target/` directory.

Because `[profile.bench]` keeps full debug symbols the SVG will show readable
function names without bloating production binaries (which still use
`panic = "abort"` and are built via `[profile.release]`).

> **Note** Benchmark binaries are compiled with the custom `[profile.bench]`
> defined in the workspace `Cargo.toml`.  That profile inherits from
> `release-debugging`, preserving full optimisation *and* debug symbols so that
> tools like `cargo flamegraph` or `perf` produce human-readable stack traces.

---

## Templates

Ready-to-copy starter files live in `docs/dev_templates/`.

- **Criterion**: `criterion_template.rs`
- **iai**: `iai_template.rs`

Copy the template into `benches/`, adjust imports and names, and start measuring!

</document_content>
</document>
<document index="1463">
<source>docs/developer_guide/coding_standards.md</source>
<document_content>
# Coding Standards

## Code Style

The current codebase can be used as a guide for formatting conventions.
Additional guidelines are provided below.

### Universal formatting rules

The following applies to **all** source files (Rust, Python, Cython, shell, etc.):

- Use **spaces only**, never hard tab characters.
- Lines should generally stay below **100 characters**; wrap thoughtfully when necessary.
- Prefer American English spelling (`color`, `serialize`, `behavior`).

### Comment conventions

1. Generally leave **one blank line above** every comment block or docstring so it is visually separated from code.
2. Use *sentence case* – capitalize the first letter, keep the rest lowercase unless proper nouns or acronyms.
3. Do not use double spaces after periods.
4. **Single-line comments** *must not* end with a period *unless* the line ends with a URL or inline Markdown link – in those cases leave the punctuation exactly as the link requires.
5. **Multi-line comments** should separate sentences with commas (not period-per-line). The final line *should* end with a period.
6. Keep comments concise; favor clarity and only explain the non-obvious – *less is more*.
7. Avoid emoji symbols in text.

### Doc comment mood

**Rust** doc comments should be written in the **indicative mood** – e.g. *"Returns a cached client."*

This convention aligns with the prevailing style of the Rust ecosystem and makes generated
documentation feel natural to end-users.

### Terminology and phrasing

1. **Error messages**: Avoid using ", got" in error messages. Use more descriptive alternatives like ", was", ", received", or ", found" depending on context.
   - ❌ `"Expected string, got {type(value)}"`
   - ✅ `"Expected string, was {type(value)}"`

2. **Spelling**: Use "hardcoded" (single word) rather than "hard-coded" or "hard coded" – this is the more modern and accepted spelling.

### Formatting

1. For longer lines of code, and when passing more than a couple of arguments, you should take a new line which aligns at the next logical indent (rather than attempting a hanging 'vanity' alignment off an opening parenthesis). This practice conserves space to the right, ensures important code is more central in view, and is also robust to function/method name changes.

2. The closing parenthesis should be located on a new line, aligned at the logical indent.

3. Also ensure multiple hanging parameters or arguments end with a trailing comma:

```python
long_method_with_many_params(
    some_arg1,
    some_arg2,
    some_arg3,  # <-- trailing comma
)
```

## Commit messages

Here are some guidelines for the style of your commit messages:

1. Limit subject titles to 60 characters or fewer. Capitalize subject line and do not end with period.

2. Use 'imperative voice', i.e. the message should describe what the commit will do if applied.

3. Optional: Use the body to explain change. Separate from subject with a blank line. Keep under 100 character width. You can use bullet points with or without terminating periods.

4. Optional: Provide # references to relevant issues or tickets.

5. Optional: Provide any hyperlinks which are informative.

### Gitlint (optional)

Gitlint is available to help enforce commit message standards automatically. It checks that commit messages follow the guidelines above (character limits, formatting, etc.). This is **opt-in** and not enforced in CI.

**Benefits**: Encourages concise yet expressive commit messages, helps develop clear explanations of changes.

**Installation**: First install gitlint to run it locally:

```bash
uv pip install gitlint
```

To enable gitlint as an automatic commit-msg hook:

```bash
pre-commit install --hook-type commit-msg
```

**Manual usage**: Check your last commit message:

```bash
gitlint
```

Configuration is in `.gitlint` at the repository root:

- **60-character title limit**: Ensures clear rendering on GitHub and encourages brevity while remaining descriptive.
- **79-character body width**: Aligns with Python's PEP 8 conventions and the traditional limit for git tooling.

:::note
Gitlint may be enforced in CI in the future, so adopting these practices early helps ensure a smooth transition.
:::

</document_content>
</document>
<document index="1464">
<source>docs/developer_guide/docs.md</source>
<document_content>
# Docs Style

This guide outlines the style conventions and best practices for writing documentation for NautilusTrader.

## General principles

- We favor simplicity over complexity, less is more.
- We favor concise yet readable prose and documentation.
- We value standardization in conventions, style, patterns, etc.
- Documentation should be accessible to users of varying technical backgrounds.

## Language and tone

- Use active voice when possible ("Configure the adapter" vs "The adapter should be configured").
- Write in present tense for describing current functionality.
- Use future tense only for planned features.
- Avoid unnecessary jargon; define technical terms on first use.
- Be direct and concise; avoid filler words like "basically", "simply", "just".

## Markdown tables

### Column alignment and spacing

- Use symmetrical column widths based on the space dictated by the widest content in each column.
- Align column separators (`|`) vertically for better readability.
- Use consistent spacing around cell content.

### Notes and descriptions

- All notes and descriptions should have terminating periods.
- Keep notes concise but informative.
- Use sentence case (capitalize only the first letter and proper nouns).

### Example

```markdown
| Order Type             | Spot | Margin | USDT Futures | Coin Futures | Notes                   |
|------------------------|------|--------|--------------|--------------|-------------------------|
| `MARKET`               | ✓    | ✓      | ✓            | ✓            |                         |
| `STOP_MARKET`          | -    | ✓      | ✓            | ✓            | Not supported for Spot. |
| `MARKET_IF_TOUCHED`    | -    | -      | ✓            | ✓            | Futures only.           |
```

### Support indicators

- Use `✓` for supported features.
- Use `-` for unsupported features (not `✗` or other symbols).
- When adding notes for unsupported features, emphasize with italics: `*Not supported*`.
- Leave cells empty when no content is needed.

## Code references

- Use backticks for inline code, method names, class names, and configuration options.
- Use code blocks for multi-line examples.
- When referencing functions or code locations, include the pattern `file_path:line_number` to allow easy navigation.

## Headings

We follow modern documentation conventions that prioritize readability and accessibility:

- Use title case for the main page heading (# Level 1 only).
- Use sentence case for all subheadings (## Level 2 and below).
- Always capitalize proper nouns regardless of heading level (product names, technologies, companies, acronyms).
- Ensure proper heading hierarchy (don't skip levels).

This convention aligns with industry standards used by major technology companies including Google Developer Documentation, Microsoft Docs, and Anthropic's documentation.
It improves readability, reduces cognitive load, and is more accessible for international users and screen readers.

### Examples

```markdown
# NautilusTrader Developer Guide

## Getting started with Python
## Using the Binance adapter
## REST API implementation
## WebSocket data streaming
## Testing with pytest
```

## Lists

- Use hyphens (`-`) for unordered list bullets; avoid `*` or `+` to keep the Markdown style consistent across the project.
- Use numbered lists only when order matters.
- Maintain consistent indentation for nested lists.
- End list items with periods when they are complete sentences.

## Links and references

- Use descriptive link text (avoid "click here" or "this link").
- Reference external documentation when appropriate.
- Ensure all internal links are relative and accurate.

## Technical terminology

- Base capability matrices on the Nautilus domain model, not exchange-specific terminology.
- Mention exchange-specific terms in parentheses or notes when necessary for clarity.
- Use consistent terminology throughout the documentation.

## Examples and code samples

- Provide practical, working examples.
- Include necessary imports and context.
- Use realistic variable names and values.
- Add comments to explain non-obvious parts of examples.

## Warnings and notes

- Use appropriate admonition blocks for important information:
  - `:::note` for general information.
  - `:::warning` for important caveats.
  - `:::tip` for helpful suggestions.

## Line length and wrapping

- Wrap lines at no more than ~100-120 characters for better readability and diff reviews.
- Break long sentences at natural points (after commas, conjunctions, or phrases).
- Avoid orphaned words on new lines when possible.
- Code blocks and URLs can exceed the line limit when necessary.

## API documentation

- Document parameters and return types clearly.
- Include usage examples for complex APIs.
- Explain any side effects or important behavior.
- Keep parameter descriptions concise but complete.

</document_content>
</document>
<document index="1465">
<source>docs/developer_guide/environment_setup.md</source>
<document_content>
# Environment Setup

For development we recommend using the PyCharm *Professional* edition IDE, as it interprets Cython syntax. Alternatively, you could use Visual Studio Code with a Cython extension.

[uv](https://docs.astral.sh/uv) is the preferred tool for handling all Python virtual environments and dependencies.

[pre-commit](https://pre-commit.com/) is used to automatically run various checks, auto-formatters and linting tools at commit.

NautilusTrader uses increasingly more [Rust](https://www.rust-lang.org), so Rust should be installed on your system as well
([installation guide](https://www.rust-lang.org/tools/install)).

:::info
NautilusTrader *must* compile and run on **Linux, macOS, and Windows**. Please keep portability in
mind (use `std::path::Path`, avoid Bash-isms in shell scripts, etc.).
:::

## Setup

The following steps are for UNIX-like systems, and only need to be completed once.

1. Follow the [installation guide](../getting_started/installation.md) to set up the project with a modification to the final command to install development and test dependencies:

```bash
uv sync --active --all-groups --all-extras
```

or

```bash
make install
```

If you're developing and iterating frequently, then compiling in debug mode is often sufficient and *significantly* faster than a fully optimized build.
To install in debug mode, use:

```bash
make install-debug
```

2. Set up the pre-commit hook which will then run automatically at commit:

```bash
pre-commit install
```

Before opening a pull-request run the formatting and lint suite locally so that CI passes on the
first attempt:

```bash
make format
make pre-commit
```

Make sure the Rust compiler reports **zero errors** – broken builds slow everyone down.

3. **Optional**: For frequent Rust development, configure the `PYO3_PYTHON` variable in `.cargo/config.toml` with the path to the Python interpreter. This helps reduce recompilation times for IDE/rust-analyzer based `cargo check`:

```bash
PYTHON_PATH=$(which python)
echo -e "\n[env]\nPYO3_PYTHON = \"$PYTHON_PATH\"" >> .cargo/config.toml
```

Since `.cargo/config.toml` is tracked, configure git to skip any local modifications:

```bash
git update-index --skip-worktree .cargo/config.toml
```

To restore tracking: `git update-index --no-skip-worktree .cargo/config.toml`

## Builds

Following any changes to `.rs`, `.pyx` or `.pxd` files, you can re-compile by running:

```bash
uv run --no-sync python build.py
```

or

```bash
make build
```

If you're developing and iterating frequently, then compiling in debug mode is often sufficient and *significantly* faster than a fully optimized build.
To compile in debug mode, use:

```bash
make build-debug
```

## Faster builds

The cranelift backends reduces build time significantly for dev, testing and IDE checks. However, cranelift is available on the nightly toolchain and needs extra configuration. Install the nightly toolchain

```
rustup install nightly
rustup override set nightly
rustup component add rust-analyzer # install nightly lsp
rustup override set stable # reset to stable
```

Activate the nightly feature and use "cranelift" backend for dev and testing profiles in workspace `Cargo.toml`. You can apply the below patch using `git apply <patch>`. You can remove it using `git apply -R <patch>` before pushing changes.

```
diff --git a/Cargo.toml b/Cargo.toml
index 62b78cd8d0..beb0800211 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -1,3 +1,6 @@
+# This line needs to come before anything else in Cargo.toml
+cargo-features = ["codegen-backend"]
+
 [workspace]
 resolver = "2"
 members = [
@@ -140,6 +143,7 @@ lto = false
 panic = "unwind"
 incremental = true
 codegen-units = 256
+codegen-backend = "cranelift"

 [profile.test]
 opt-level = 0
@@ -150,11 +154,13 @@ strip = false
 lto = false
 incremental = true
 codegen-units = 256
+codegen-backend = "cranelift"

 [profile.nextest]
 inherits = "test"
 debug = false # Improves compile times
 strip = "debuginfo" # Improves compile times
+codegen-backend = "cranelift"

 [profile.release]
 opt-level = 3
```

Pass `RUSTUP_TOOLCHAIN=nightly` when running `make build-debug` like commands and include it in all [rust analyzer settings](#rust-analyzer-settings) for faster builds and IDE checks.

## Services

You can use `docker-compose.yml` file located in `.docker` directory
to bootstrap the Nautilus working environment. This will start the following services:

```bash
docker-compose up -d
```

If you only want specific services running (like `postgres` for example), you can start them with command:

```bash
docker-compose up -d postgres
```

Used services are:

- `postgres`: Postgres database with root user `POSTRES_USER` which defaults to `postgres`, `POSTGRES_PASSWORD` which defaults to `pass` and `POSTGRES_DB` which defaults to `postgres`.
- `redis`: Redis server.
- `pgadmin`: PgAdmin4 for database management and administration.

:::info
Please use this as development environment only. For production, use a proper and more secure setup.
:::

After the services has been started, you must log in with `psql` cli to create `nautilus` Postgres database.
To do that you can run, and type `POSTGRES_PASSWORD` from docker service setup

```bash
psql -h localhost -p 5432 -U postgres
```

After you have logged in as `postgres` administrator, run `CREATE DATABASE` command with target db name (we use `nautilus`):

```
psql (16.2, server 15.2 (Debian 15.2-1.pgdg110+1))
Type "help" for help.

postgres=# CREATE DATABASE nautilus;
CREATE DATABASE

```

## Nautilus CLI developer guide

## Introduction

The Nautilus CLI is a command-line interface tool for interacting with the NautilusTrader ecosystem.
It offers commands for managing the PostgreSQL database and handling various trading operations.

:::note
The Nautilus CLI command is only supported on UNIX-like systems.
:::

## Install

You can install the Nautilus CLI using the below Makefile target, which leverages `cargo install` under the hood.
This will place the nautilus binary in your system's PATH, assuming Rust's `cargo` is properly configured.

```bash
make install-cli
```

## Commands

You can run `nautilus --help` to view the CLI structure and available command groups:

### Database

These commands handle bootstrapping the PostgreSQL database.
To use them, you need to provide the correct connection configuration,
either through command-line arguments or a `.env` file located in the root directory or the current working directory.

- `--host` or `POSTGRES_HOST` for the database host
- `--port` or `POSTGRES_PORT` for the database port
- `--user` or `POSTGRES_USER` for the root administrator (typically the postgres user)
- `--password` or `POSTGRES_PASSWORD` for the root administrator's password
- `--database` or `POSTGRES_DATABASE` for both the database **name and the new user** with privileges to that database
    (e.g., if you provide `nautilus` as the value, a new user named nautilus will be created with the password from `POSTGRES_PASSWORD`, and the `nautilus` database will be bootstrapped with this user as the owner).

Example of `.env` file

```
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USERNAME=postgres
POSTGRES_PASSWORD=pass
POSTGRES_DATABASE=nautilus
```

List of commands are:

1. `nautilus database init`: Will bootstrap schema, roles and all sql files located in `schema` root directory (like `tables.sql`).
2. `nautilus database drop`: Will drop all tables, roles and data in target Postgres database.

## Rust analyzer settings

Rust analyzer is a popular language server for Rust and has integrations for many IDEs. It is recommended to configure rust analyzer to have same environment variables as `make build-debug` for faster compile times. Below tested configurations for VSCode and Astro Nvim are provided. For more information see [PR](https://github.com/nautechsystems/nautilus_trader/pull/2524) or rust analyzer [config docs](https://rust-analyzer.github.io/book/configuration.html).

### VSCode

You can add the following settings to your VSCode `settings.json` file:

```
    "rust-analyzer.restartServerOnConfigChange": true,
    "rust-analyzer.linkedProjects": [
        "Cargo.toml"
    ],
    "rust-analyzer.cargo.features": "all",
    "rust-analyzer.check.workspace": false,
    "rust-analyzer.check.extraEnv": {
        "VIRTUAL_ENV": "<path-to-your-virtual-environment>/.venv",
        "CC": "clang",
        "CXX": "clang++"
    },
    "rust-analyzer.cargo.extraEnv": {
        "VIRTUAL_ENV": "<path-to-your-virtual-environment>/.venv",
        "CC": "clang",
        "CXX": "clang++"
    },
    "rust-analyzer.runnables.extraEnv": {
        "VIRTUAL_ENV": "<path-to-your-virtual-environment>/.venv",
        "CC": "clang",
        "CXX": "clang++"
    },
    "rust-analyzer.check.features": "all",
    "rust-analyzer.testExplorer": true
```

### Astro Nvim (Neovim + AstroLSP)

You can add the following to your astro lsp config file:

```
    config = {
      rust_analyzer = {
        settings = {
          ["rust-analyzer"] = {
            restartServerOnConfigChange = true,
            linkedProjects = { "Cargo.toml" },
            cargo = {
              features = "all",
              extraEnv = {
                VIRTUAL_ENV = "<path-to-your-virtual-environment>/.venv",
                CC = "clang",
                CXX = "clang++",
              },
            },
            check = {
              workspace = false,
              command = "check",
              features = "all",
              extraEnv = {
                VIRTUAL_ENV = "<path-to-your-virtual-environment>/.venv",
                CC = "clang",
                CXX = "clang++",
              },
            },
            runnables = {
              extraEnv = {
                VIRTUAL_ENV = "<path-to-your-virtual-environment>/.venv",
                CC = "clang",
                CXX = "clang++",
              },
            },
            testExplorer = true,
          },
        },
      },
```

</document_content>
</document>
<document index="1466">
<source>docs/developer_guide/ffi.md</source>
<document_content>
# FFI Memory Contract

NautilusTrader exposes several **C-compatible** types so that compiled Rust code can be
consumed from C-extensions generated by Cython or by other native languages.  The most
important of these is `CVec` – a *thin* wrapper around a Rust `Vec<T>` that is passed across
the FFI boundary **by value**.

The rules below are *strict*; violating them results in undefined behaviour (usually a double-free or a memory leak).

## Fail-fast panics at the FFI boundary

Rust panics must never unwind across `extern "C"` functions. Unwinding into C or Python is
undefined behaviour and can corrupt the foreign stack or leave partially-dropped resources
behind. To enforce the fail-fast architecture we wrap every exported symbol in
`crate::ffi::abort_on_panic`, which executes the body and calls `process::abort()` if a panic
occurs. The panic message is still logged before the abort, so debugging output is preserved
while avoiding undefined behaviour.

When adding new FFI functions, call `abort_on_panic(|| { … })` around the implementation (or
use a helper that does so) to maintain this guarantee.

## CVec lifecycle

| Step  | Owner                         | Action |
|-------|-------------------------------|--------|
| **1** | Rust                          | Build a `Vec<T>` and convert it with `into()` – this *leaks* the vector and transfers ownership of the raw allocation to foreign code. |
| **2** | Foreign (Python / Cython / C) | Use the data while the `CVec` value is in scope. **Do not modify the fields `ptr`, `len`, `cap`.** |
| **3** | Foreign                       | Exactly once, call the *type-specific* drop helper exported by Rust (for example `vec_drop_book_levels`, `vec_drop_book_orders`, `vec_time_event_handlers_drop`). The helper reconstructs the original `Vec<T>` with `Vec::from_raw_parts` and lets it drop, freeing the memory. |

:::warning
If step **3** is forgotten the allocation is leaked for the remainder of the process; if it
is performed **twice** the program will double-free and likely crash.
:::

## Capsules created on the Python side

Several Cython helpers allocate temporary C buffers with `PyMem_Malloc`, wrap them into a
`CVec`, and return the address inside a `PyCapsule`. **Every such capsule is created with a
destructor** (`capsule_destructor` or `capsule_destructor_deltas`) that frees both the buffer
and the `CVec`. Callers must therefore *not* free the memory manually – doing so would double
free.

## Capsules created on the Rust side *(PyO3 bindings)*

When Rust code pushes a heap-allocated value into Python it **must** use
`PyCapsule::new_with_destructor` so that Python knows how to free the allocation
once the capsule becomes unreachable. The closure/destructor is responsible
for reconstructing the original `Box<T>` or `Vec<T>` and letting it drop.

```rust
Python::attach(|py| {
    // allocate the value on the heap
    let my_data = MyStruct::new();

    // move it into the capsule and register a destructor
    let capsule = pyo3::types::PyCapsule::new_with_destructor(py, my_data, None, |_, _| {})
        .expect("capsule creation failed");

    // ... pass `capsule` back to Python ...
});
```

Do **not** use `PyCapsule::new(…, None)`; that variant registers *no* destructor
and will leak memory unless the recipient manually extracts and frees the
pointer (something we never rely on). The codebase has been updated to follow
this rule everywhere – adding new FFI modules must follow the same pattern.

## Why there is no generic `cvec_drop` anymore

Earlier versions of the codebase shipped a generic `cvec_drop` function that always treated the
buffer as `Vec<u8>`. Using it with any other element type causes a size-mismatch during
deallocation and corrupts the allocator’s bookkeeping. Because the helper was not referenced
anywhere inside the project it has been removed to avoid accidental misuse.

## Box-backed `*_API` wrappers (owned Rust objects)

When the Rust core needs to hand a *complex* value (for example an
`OrderBook`, `SyntheticInstrument`, or `TimeEventAccumulator`) to foreign
code it allocates the value on the heap with `Box::new` and returns a
small `repr(C)` wrapper whose only field is that `Box`.

```rust
#[repr(C)]
pub struct OrderBook_API(Box<OrderBook>);

#[unsafe(no_mangle)]
pub extern "C" fn orderbook_new(id: InstrumentId, book_type: BookType) -> OrderBook_API {
    OrderBook_API(Box::new(OrderBook::new(id, book_type)))
}

#[unsafe(no_mangle)]
pub extern "C" fn orderbook_drop(book: OrderBook_API) {
    drop(book); // frees the heap allocation
}
```

Memory-safety requirements are therefore:

1. Every constructor (`*_new`) **must** have a matching `*_drop` exported
    next to it.
2. The *Python/Cython* binding must guarantee that `*_drop` is invoked
    exactly once. Two approaches are accepted:

    • Wrap the pointer in a `PyCapsule` created with
      `PyCapsule::new_with_destructor`, passing a destructor that calls
      the drop helper.

    • Call the helper explicitly in `__del__`/`__dealloc__` on the Python
      side.  This is the historical pattern for most v1 Cython modules:

      ```python
      cdef class OrderBook:
          cdef OrderBook_API _mem

          def __cinit__(self, ...):
              self._mem = orderbook_new(...)

          def __del__(self):
              if self._mem._0 != NULL:
                  orderbook_drop(self._mem)
      ```

Whichever style is used, remember: **forgetting the drop call leaks the
entire structure**, while calling it twice will double-free and crash.

New FFI code must follow this template before it can be merged.

</document_content>
</document>
<document index="1467">
<source>docs/developer_guide/index.md</source>
<document_content>
# Developer Guide

Welcome to the developer guide for NautilusTrader!

Here you'll find guidance on developing and extending NautilusTrader to meet your trading needs or to contribute improvements back to the project.

:::info
This guide is structured so that automated tooling can consume it alongside human readers.
:::

We believe in using the right tool for the job. The overall design philosophy is to fully utilize
the high level power of Python, with its rich eco-system of frameworks and libraries, whilst
overcoming some of its inherent shortcomings in performance and lack of built-in type safety
(with it being an interpreted dynamic language).

One of the advantages of Cython is that allocation and freeing of memory is handled by the C code
generator during the ‘cythonization’ step of the build (unless you’re specifically utilizing some of
its lower level features).

This approach combines Python’s simplicity with near-native C performance via compiled extensions.

The main development and runtime environment we are working in is Python. With the
introduction of Cython throughout the production codebase in `.pyx` and `.pxd` files, it's
important to be aware of how the CPython implementation of Python interacts with the underlying
CPython API, and the NautilusTrader C extension modules which Cython produces.

We recommend a thorough review of the [Cython docs](https://cython.readthedocs.io/en/latest/) to familiarize yourself with some of its core
concepts, and where C typing is being used.

It's not necessary to become a C language expert, however it's helpful to understand how Cython C
syntax is used in function and method definitions, in local code blocks, and the common primitive C
types and how these map to their corresponding `PyObject` types.

## Contents

- [Environment Setup](environment_setup.md)
- [Coding Standards](coding_standards.md)
- [Rust](rust.md)
- [Python](python.md)
- [Testing](testing.md)
- [Docs Style](docs.md)
- [Release Notes](releases.md)
- [Adapters](adapters.md)
- [Benchmarking](benchmarking.md)
- [Packaged Data](packaged_data.md)
- [FFI Memory Contract](ffi.md)

</document_content>
</document>
<document index="1468">
<source>docs/developer_guide/packaged_data.md</source>
<document_content>
# Packaged Data

Various data is contained internally in the `tests/test_kit/data` folder.

## Libor rates

The libor rates for 1 month USD can be updated by downloading the CSV data from <https://fred.stlouisfed.org/series/USD1MTD156N>.

Ensure you select `Max` for the time window.

## Short term interest rates

The interbank short term interest rates can be updated by downloading the CSV data at <https://data.oecd.org/interest/short-term-interest-rates.htm>.

## Economic events

The economic events can be updated from downloading the CSV data from fxstreet <https://www.fxstreet.com/economic-calendar>.

Ensure timezone is set to GMT.

A maximum 3 month range can be filtered and so yearly quarters must be downloaded manually and stitched together into a single CSV.
Use the calendar icon to filter the data in the following way;

- 01/01/xx - 31/03/xx
- 01/04/xx - 30/06/xx
- 01/07/xx - 30/09/xx
- 01/10/xx - 31/12/xx

Download each CSV.

</document_content>
</document>
<document index="1469">
<source>docs/developer_guide/python.md</source>
<document_content>
# Python

The [Python](https://www.python.org/) programming language is used for the majority of user-facing code in NautilusTrader.
Python provides a rich ecosystem of libraries and frameworks, making it ideal for strategy development, data analysis, and system integration.

## Code style

### PEP-8

The codebase generally follows the PEP-8 style guide. Even though C typing is taken advantage of in the Cython parts of the codebase, we still aim to be idiomatic of Python where possible.
One notable departure is that Python truthiness is not always taken advantage of to check if an argument is `None` for everything other than collections.

There are two reasons for this:

1. Cython can generate more efficient C code from `is None` and `is not None`, rather than entering the Python runtime to check the `PyObject` truthiness.

2. As per the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html) - it's discouraged to use truthiness to check if an argument is/is not `None`, when there is a chance an unexpected object could be passed into the function or method which will yield an unexpected truthiness evaluation (which could result in a logical error type bug).

*"Always use if foo is None: (or is not None) to check for a None value. E.g., when testing whether a variable or argument that defaults to None was set to some other value. The other value might be a value that's false in a boolean context!"*

There are still areas that aren't performance-critical where truthiness checks for `None` (`if foo is None:` vs `if not foo:`) will be acceptable for clarity.

:::note
Use truthiness to check for empty collections (e.g., `if not my_list:`) rather than comparing explicitly to `None` or empty.
:::

We welcome all feedback on where the codebase departs from PEP-8 for no apparent reason.

### Type hints

All function and method signatures *must* include comprehensive type annotations:

```python
def __init__(self, config: EMACrossConfig) -> None:
def on_bar(self, bar: Bar) -> None:
def on_save(self) -> dict[str, bytes]:
def on_load(self, state: dict[str, bytes]) -> None:
```

**Generic Types**: Use `TypeVar` for reusable components

```python
T = TypeVar("T")
class ThrottledEnqueuer(Generic[T]):
```

### Docstrings

The [NumPy docstring spec](https://numpydoc.readthedocs.io/en/latest/format.html) is used throughout the codebase.
This needs to be adhered to consistently to ensure the docs build correctly.

**Python** docstrings should be written in the **imperative mood** – e.g. *"Return a cached client."*

This convention aligns with the prevailing style of the Python ecosystem and makes generated
documentation feel natural to end-users.

#### Private methods

Do not add docstrings to private methods (prefixed with `_`):

- Docstrings generate public-facing API documentation.
- Docstrings on private methods incorrectly imply they are part of the public API.
- Private methods are implementation details not intended for end-users.

Exceptions where docstrings are acceptable:

- Very complex methods with non-trivial logic, multiple steps, or important edge cases.
- Methods requiring detailed parameter or return value documentation due to complexity.

When a private method needs context (such as a tricky precondition or side effect), prefer a short inline comment (`#`) near the relevant logic rather than a docstring.

### Test naming

Descriptive names explaining the scenario:

```python
def test_currency_with_negative_precision_raises_overflow_error(self):
def test_sma_with_no_inputs_returns_zero_count(self):
def test_sma_with_single_input_returns_expected_value(self):
```

### Ruff

[ruff](https://astral.sh/ruff) is utilized to lint the codebase. Ruff rules can be found in the top-level `pyproject.toml`, with ignore justifications typically commented.

## Cython

:::warning[Deprecation notice]
Cython is being phased out in favor of Rust implementations. This section will be removed in a future version.
:::

Here you will find guidance and tips for working on NautilusTrader using the Cython language.
More information on Cython syntax and conventions can be found by reading the [Cython docs](https://cython.readthedocs.io/en/latest/index.html).

### What is Cython?

Cython is a superset of Python that compiles to C extension modules, enabling optional static typing and optimized performance. NautilusTrader historically relied on Cython for its Python bindings and performance-critical components.

### Function and method signatures

Ensure that all functions and methods returning `void` or a primitive C type (such as `bint`, `int`, `double`) include the `except *` keyword in the signature.

This will ensure Python exceptions are not ignored, and instead are "bubbled up" to the caller as expected.

### Debugging

#### PyCharm

Improved debugging support for Cython has remained a highly up-voted PyCharm
feature for many years. Unfortunately, it's safe to assume that PyCharm will not
be receiving first class support for Cython debugging
<https://youtrack.jetbrains.com/issue/PY-9476>.

#### Cython docs

The following recommendations are contained in the Cython docs:
<https://cython.readthedocs.io/en/latest/src/userguide/debugging.html>

The summary is it involves manually running a specialized version of `gdb` from the command line.
We don't recommend this workflow.

#### Tips

When debugging and seeking to understand a complex system such as NautilusTrader, it can be
quite helpful to step through the code with a debugger. With this not being available
for the Cython part of the codebase, there are a few things which can help:

- Ensure `LogLevel.DEBUG` is configured for the backtesting or live system you are debugging.
  This is available on `BacktestEngineConfig(logging=LoggingConfig(log_level="DEBUG"))` or `TradingNodeConfig(logging=LoggingConfig=log_level="DEBUG"))`.
  With `DEBUG` mode active you will see more granular and verbose log traces which could be what you need to understand the flow.
- Beyond this, if you still require more granular visibility around a part of the system, we recommend some well-placed calls
  to a components logger (normally `self._log.debug(f"HERE {variable}"` is enough).

</document_content>
</document>
<document index="1470">
<source>docs/developer_guide/releases.md</source>
<document_content>
# Release Notes

This guide documents the standards for writing release notes in `RELEASES.md`.

## Sections

Use the following sections in this order:

1. Enhancements
2. Breaking Changes
3. Security
4. Fixes
5. Internal Improvements
6. Documentation Updates
7. Deprecations

Omit sections that have no items for a given release.

### Enhancements

New features and user-visible improvements.

**Format**:

```markdown
- Added `subscribe_order_fills(...)` and `unsubscribe_order_fills(...)` for `Actor`
- Added BitMEX conditional orders support
- Added support for `OrderBookDepth10` requests (#2955), thanks @faysou
```

**Guidelines**:

- Start with "Added".
- Use backticks for code elements.
- Be specific about what was added, not how.

### Breaking Changes

Changes that may break existing code.

**Format**:

```markdown
- Removed `nautilus_trader.analysis.statistics` subpackage - must import from `nautilus_trader.analysis`
- Renamed `BinanceAccountType.USDT_FUTURE` to `USDT_FUTURES`
- Changed `start` parameter to required for `Actor` data request methods
```

**Guidelines**:

- Start with "Removed", "Renamed", or "Changed".
- Explain migration path briefly.

### Security

Security hardening and fixes that prevent crashes, undefined behavior, or data corruption.
Includes significant hardening improvements elevated from Internal Improvements.

**Format**:

```markdown
- Fixed non-executable stack for Cython extensions to support hardened Linux systems
- Fixed divide-by-zero and overflow bugs in model crate that could cause crashes
- Fixed core arithmetic operations to reject NaN/Infinity values and improve overflow handling
```

**Guidelines**:

- Include overflow/underflow fixes, memory safety improvements, FFI guards, data integrity fixes.
- Focus on user impact: what could have happened.
- Exclude routine dependency updates, minor hardening, or test-only fixes.
- Omit this section entirely if there are no security items for the release.

### Fixes

Bug fixes that improve correctness but don't qualify as security issues.

**Format**:

```markdown
- Fixed reduce-only order panic when quantity exceeds position
- Fixed Binance order status parsing for external orders (#3006), thanks for reporting @bmlquant
```

**Guidelines**:

- Start with "Fixed".

### Internal Improvements

Implementation details and infrastructure changes.

**Format**:

```markdown
- Added ARM64 support to Docker builds
- Ported `PortfolioAnalyzer` to Rust
- Improved clock and timer thread safety
- Upgraded Rust (MSRV) to 1.90.0
- Upgraded `pyo3` crates to v0.26.0
```

**Guidelines**:

- Use "Added", "Implemented", "Improved", "Optimized", "Upgraded", "Refined", "Standardized".
- Include version numbers for dependency upgrades.

### Documentation Updates

Changes to guides and examples.

**Format**:

```markdown
- Added rate limit tables with links to official docs
- Improved dark and light themes for readability
- Fixed broken links
```

### Deprecations

Features marked for removal.

**Format**:

```markdown
- Deprecated `convert_quote_qty_to_base`; disable (`False`) to maintain consistent behaviour. Will be removed in future version
```

**Guidelines**:

- Explain migration path and provide alternatives.

## Attribution

- Credit external contributors: `thanks @username` or `thanks for reporting @username`.
- Include issue/PR numbers for community contributions and complex features: `(#1234)`.

## Style

- Use sentence case (capitalize first word only).
- Do not end with periods.
- Use backticks for code elements.
- Focus on **what** changed, not how.

**Be specific**:

```markdown
❌ Improved Binance adapter
✅ Improved Binance fill handling when instrument not cached
```

## Security classification

Include in Security if the change addresses:

- Memory safety (overflow, underflow, divide-by-zero that threatens stability).
- Undefined behavior or crashes that could corrupt state.
- Data integrity (NaN/Infinity propagation, race conditions leading to corruption).
- Input validation preventing injection or exploitation (SQL injection, command injection, path traversal).
- Build hardening (non-exec stack, FFI guards).
- Significant hardening that users should know about.

Otherwise use Fixes (for logic bugs and panics) or Internal Improvements (for minor hardening).

Note: Plain logic panics belong in Fixes unless they threaten system stability or data corruption.

## Examples

**Security** (could cause crashes/corruption):

```markdown
- Fixed divide-by-zero in margin calculations that could crash the engine
- Fixed non-executable stack for Cython extensions to support hardened systems
```

**Fixes** (incorrect but safe):

```markdown
- Fixed Binance order status parsing for external orders
- Fixed position purge logic to prevent purging re-opened position
```

**Enhancements** (user-facing):

```markdown
- Added BitMEX conditional orders support
```

**Internal** (implementation):

```markdown
- Implemented BitMEX ping/pong handling
```

## Release workflow

After publishing a release:

1. Update the published release section in `RELEASES.md` with the actual release date.
2. Add the horizontal separator `---` below the completed release.
3. Copy the template below and paste it at the top of `RELEASES.md` for the next version.
4. Update `<VERSION>` to the next version number.
5. Add items to sections as development progresses.

## Release notes template

```markdown
# NautilusTrader <VERSION> Beta

Released on TBD (UTC).

### Enhancements

### Breaking Changes

### Security

### Fixes

### Internal Improvements

### Documentation Updates

### Deprecations

---
```

</document_content>
</document>
<document index="1471">
<source>docs/developer_guide/testing.md</source>
<document_content>
# Testing

Our automated tests serve as executable specifications for the trading platform.
A healthy suite documents intended behaviour, gives contributors confidence to refactor, and catches regressions before they reach production.
Tests also double as living examples that clarify complex flows and provide rapid CI feedback so issues surface early.

The suite covers these categories:

- Unit tests
- Integration tests
- Acceptance tests
- Performance tests
- Memory leak tests

Performance tests help evolve performance-critical components.

Run tests with [pytest](https://docs.pytest.org), our primary test runner.
Use parametrized tests and fixtures (e.g., `@pytest.mark.parametrize`) to avoid repetitive code and improve clarity.

## Running tests

### Python tests

From the repository root:

```bash
make pytest
# or
uv run --active --no-sync pytest --new-first --failed-first
# or simply
pytest
```

For performance tests:

```bash
make test-performance
# or
uv run --active --no-sync pytest tests/performance_tests --benchmark-disable-gc --codspeed
```

### Rust tests

```bash
make cargo-test
# or
cargo nextest run --workspace --features "python,ffi,high-precision,defi" --cargo-profile nextest
```

#### Testing with optional features

Use `EXTRA_FEATURES` to include optional features like `capnp` or `hypersync`:

```bash
# Test with capnp feature
make cargo-test EXTRA_FEATURES="capnp"

# Test with multiple features
make cargo-test EXTRA_FEATURES="capnp hypersync"

# Legacy shorthand for hypersync
make cargo-test HYPERSYNC=true

# Test specific crate with features
make cargo-test-crate-nautilus-serialization FEATURES="capnp"
```

### IDE integration

- **PyCharm**: Right-click the tests folder or file → "Run pytest".
- **VS Code**: Use the Python Test Explorer extension.

## Test style

- Name test functions after what they exercise; you do not need to encode the expected assertions in the name.
- Add docstrings when they clarify setup, scenarios, or expectations.
- Prefer pytest-style free functions for Python tests instead of test classes with setup methods.
- **Group assertions** when possible: perform all setup/act steps first, then assert together to avoid the act-assert-act smell.
- Use `unwrap`, `expect`, or direct `panic!`/`assert` calls inside tests; clarity and conciseness matter more than defensive error handling here.

## Waiting for asynchronous effects

When waiting for background work to complete, prefer the polling helpers `await eventually(...)` from `nautilus_trader.test_kit.functions` and `wait_until_async(...)` from `nautilus_common::testing` instead of arbitrary sleeps. They surface failures faster and reduce flakiness in CI because they stop as soon as the condition is satisfied or time out with a useful error.

## Mocks

Use lightweight collaborators as mocks to keep the suite simple and avoid heavy mocking frameworks.
We still rely on `MagicMock` in specific cases where it provides the most convenient tooling.

## Code coverage

We generate coverage reports with `coverage` and publish them to [codecov](https://about.codecov.io/).

Aim for high coverage without sacrificing appropriate error handling or causing "test induced damage" to the architecture.

Some branches remain untestable without modifying production behaviour.
For example, a final condition in a defensive if-else block may only trigger for unexpected values; leave these checks in place so future changes can exercise them if needed.

Design-time exceptions can also be impractical to test, so 100% coverage is not the target.

## Excluded code coverage

We use `pragma: no cover` comments to [exclude code from coverage](https://coverage.readthedocs.io/en/coverage-4.3.3/excluding.html) when tests would be redundant.
Typical examples include:

- Asserting an abstract method raises `NotImplementedError` when called.
- Asserting the final condition check of an if-else block when impossible to test (as above).

Such tests are expensive to maintain because they must track refactors while providing little value.
Ensure concrete implementations of abstract methods remain fully covered.
Remove `pragma: no cover` when it no longer applies and restrict its use to the cases above.

## Debugging Rust tests

Use the default test configuration to debug Rust tests.

To run the full suite with debug symbols for later, run `make cargo-test-debug` instead of `make cargo-test`.

In IntelliJ IDEA, adjust the run configuration for parametrised `#[rstest]` cases so it reads `test --package nautilus-model --lib data::bar::tests::test_get_time_bar_start::case_1`
(remove `-- --exact` and append `::case_n` where `n` starts at 1). This workaround matches the behaviour explained [here](https://github.com/rust-lang/rust-analyzer/issues/8964#issuecomment-871592851).

In VS Code you can pick the specific test case to debug directly.

## Python + Rust Mixed Debugging

This workflow lets you debug Python and Rust code simultaneously from a Jupyter notebook inside VS Code.

### Setup

Install these VS Code extensions: Rust Analyzer, CodeLLDB, Python, Jupyter.

### Step 0: Compile `nautilus_trader` with debug symbols

   ```bash
   cd nautilus_trader && make build-debug-pyo3
   ```

### Step 1: Set up debugging configuration

```python
from nautilus_trader.test_kit.debug_helpers import setup_debugging

setup_debugging()
```

This command creates the required VS Code debugging configurations and starts a `debugpy` server for the Python debugger.

By default `setup_debugging()` expects the `.vscode` folder one level above the `nautilus_trader` root directory.
Adjust the target location if your workspace layout differs.

### Step 2: Set breakpoints

- **Python breakpoints:** Set in VS Code in the Python source files.
- **Rust breakpoints:** Set in VS Code in the Rust source files.

### Step 3: Start mixed debugging

1. In VS Code select the **"Debug Jupyter + Rust (Mixed)"** configuration.
2. Start debugging (F5) or press the green run arrow.
3. Both Python and Rust debuggers attach to your Jupyter session.

### Step 4: Execute code

Run Jupyter notebook cells that call Rust functions. The debugger stops at breakpoints in both Python and Rust code.

### Available configurations

`setup_debugging()` creates these VS Code configurations:

- **`Debug Jupyter + Rust (Mixed)`** - Mixed debugging for Jupyter notebooks.
- **`Jupyter Mixed Debugging (Python)`** - Python-only debugging for notebooks.
- **`Rust Debugger (for Jupyter debugging)`** - Rust-only debugging for notebooks.

### Example

Open and run the example notebook: `debug_mixed_jupyter.ipynb`.

### Reference

- [PyO3 debugging](https://pyo3.rs/v0.25.1/debugging.html?highlight=deb#debugging-from-jupyter-notebooks)

</document_content>
</document>
<document index="1473">
<source>docs/getting_started/backtest_high_level.md</source>
<document_content>
# Backtest (high-level API)

This guide is generated from the Jupyter notebook [backtest_high_level.ipynb](backtest_high_level.ipynb).

</document_content>
</document>
<document index="1475">
<source>docs/getting_started/backtest_low_level.md</source>
<document_content>
# Backtest (low-level API)

This guide is generated from the Jupyter notebook [backtest_low_level.ipynb](backtest_low_level.ipynb).

</document_content>
</document>
<document index="1476">
<source>docs/getting_started/index.md</source>
<document_content>
# Getting Started

To get started with NautilusTrader, you will need:

- A Python 3.12–3.14 environment with the `nautilus_trader` package installed.
- A way to run Python scripts or Jupyter notebooks for backtesting and/or live trading.

## [Installation](installation.md)

The **Installation** guide will help to ensure that NautilusTrader is properly installed on your machine.

## [Quickstart](quickstart.md)

The **Quickstart** provides a step-by-step walk through for setting up your first backtest.

## Examples in repository

The [online documentation](https://nautilustrader.io/docs/latest/) shows just a subset of examples. For the full set, see this repository on GitHub.

The following table lists example locations ordered by recommended learning progression:

| Directory                   | Contains                                                                                                                    |
|:----------------------------|:----------------------------------------------------------------------------------------------------------------------------|
| [examples/](https://github.com/nautechsystems/nautilus_trader/tree/develop/examples)                 | Fully runnable, self-contained Python examples.                                                                                     |
| [docs/tutorials/](../tutorials/)           | Jupyter notebook tutorials demonstrating common workflows.                                                                              |
| [docs/concepts/](../concepts/)            | Concept guides with concise code snippets illustrating key features. |
| [nautilus_trader/examples/](../../nautilus_trader/examples/) | Pure-Python examples of basic strategies, indicators, and execution algorithms.                                     |
| [tests/unit_tests/](../../tests/unit_tests/)         | Unit tests covering core functionality and edge cases.                      |

## Backtesting API levels

NautilusTrader provides two different API levels for backtesting:

| API Level      | Description                           | Characteristics                                                                                                                                                                                                                                                                                                                                                        |
|:---------------|:--------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| High-Level API | Uses `BacktestNode` and `TradingNode` | Recommended for production: easier transition to live trading; requires a Parquet-based data catalog. |
| Low-Level API  | Uses `BacktestEngine`                 | Intended for library development: no live-trading path; direct component access; may encourage non–live-compatible patterns. |

:::warning **One node per process**
Running multiple `BacktestNode` or `TradingNode` instances concurrently in the same process is not supported due to global singleton state.
Sequential execution with proper disposal between runs is supported.

See [Processes and threads](../concepts/architecture.md#processes-and-threads) for details.
:::

Backtesting involves running simulated trading systems on historical data.

To get started backtesting with NautilusTrader you need to first understand the two different API
levels which are provided, and which one may be more suitable for your intended use case.

:::info
For more information on which API level to choose, refer to the [Backtesting](../concepts/backtesting.md) guide.
:::

### [Backtest (low-level API)](backtest_low_level.md)

This tutorial runs through how to load raw data (external to Nautilus) using data loaders and wranglers,
and then use this data with a `BacktestEngine` to run a single backtest.

### [Backtest (high-level API)](backtest_high_level.md)

This tutorial runs through how to load raw data (external to Nautilus) into the data catalog,
and then use this data with a `BacktestNode` to run a single backtest.

## Running in docker

Alternatively, you can download a self-contained dockerized Jupyter notebook server, which requires no setup or
installation. This is the fastest way to get up and running to try out NautilusTrader. Note that deleting the container will also delete any data.

- To get started, install docker:
  - Go to [Docker installation guide](https://docs.docker.com/get-docker/) and follow the instructions.
- From a terminal, download the latest image:
  - `docker pull ghcr.io/nautechsystems/jupyterlab:nightly --platform linux/amd64`
- Run the docker container, exposing the jupyter port:
  - `docker run -p 8888:8888 ghcr.io/nautechsystems/jupyterlab:nightly`
- Open your web browser to `localhost:{port}`:
  - <http://localhost:8888>

:::info
NautilusTrader currently exceeds the rate limit for Jupyter notebook logging (stdout output),
therefore we set `log_level` to `ERROR` in the examples. Lowering this level to see
more logging will cause the notebook to hang during cell execution. We are currently
investigating a fix that involves either raising the configured rate limits for
Jupyter, or throttling the log flushing from Nautilus.

- <https://github.com/jupyterlab/jupyterlab/issues/12845>
- <https://github.com/deshaw/jupyterlab-limit-output>

:::

</document_content>
</document>
<document index="1477">
<source>docs/getting_started/installation.md</source>
<document_content>
# Installation

NautilusTrader is officially supported for Python 3.12-3.14 on the following 64-bit platforms:

| Operating System       | Supported Versions | CPU Architecture  |
|------------------------|--------------------|-------------------|
| Linux (Ubuntu)         | 22.04 and later    | x86_64            |
| Linux (Ubuntu)         | 22.04 and later    | ARM64             |
| macOS                  | 15.0 and later     | ARM64             |
| Windows Server         | 2022 and later     | x86_64            |

:::note
NautilusTrader may work on other platforms, but only those listed above are regularly used by developers and tested in CI.
:::

Continuous CI coverage comes from the GitHub Actions runners we build on:

- `Linux (Ubuntu)` builds currently pin to `ubuntu-22.04` to keep glibc 2.35 compatibility even as `ubuntu-latest` moves ahead.
- `macOS (ARM64)` builds run on `macos-latest`, so support tracks that runner image as it moves ahead.
- `Windows (x86_64)` builds run on `windows-latest`, so support tracks that runner image as it moves ahead.

On Linux, confirm your glibc version with `ldd --version` and ensure it reports 2.35 or newer before proceeding.

We recommend using the latest supported version of Python and installing [nautilus_trader](https://pypi.org/project/nautilus_trader/) inside a virtual environment to isolate dependencies.

**There are two supported ways to install**:

1. Pre-built binary wheel from PyPI *or* the Nautech Systems package index.
2. Build from source.

:::tip
We highly recommend installing using the [uv](https://docs.astral.sh/uv) package manager with a "vanilla" CPython.

Conda and other Python distributions *may* work but aren’t officially supported.
:::

## From PyPI

To install the latest [nautilus_trader](https://pypi.org/project/nautilus_trader/) binary wheel (or sdist package) from PyPI:

```bash
uv pip install nautilus_trader
```

## Extras

Install optional dependencies as 'extras' for specific integrations:

- `betfair`: Betfair adapter (integration) dependencies.
- `docker`: Needed for Docker when using the IB gateway (with the Interactive Brokers adapter).
- `dydx`: dYdX adapter (integration) dependencies.
- `ib`: Interactive Brokers adapter (integration) dependencies.
- `polymarket`: Polymarket adapter (integration) dependencies.
- `visualization`: Plotly-based interactive tearsheets and charts.

To install with specific extras:

```bash
uv pip install "nautilus_trader[docker,ib]"
```

## From the Nautech Systems package index

The Nautech Systems package index (`packages.nautechsystems.io`) complies with [PEP-503](https://peps.python.org/pep-0503/) and hosts both stable and development binary wheels for `nautilus_trader`.
This enables users to install either the latest stable release or pre-release versions for testing.

### Stable wheels

Stable wheels correspond to official releases of `nautilus_trader` on PyPI, and use standard versioning.

To install the latest stable release:

```bash
uv pip install nautilus_trader --index-url=https://packages.nautechsystems.io/simple
```

:::tip
Use `--extra-index-url` instead of `--index-url` if you want uv to fall back to PyPI automatically:

:::

### Development wheels

Development wheels are published from both the `nightly` and `develop` branches,
allowing users to test features and fixes ahead of stable releases.

This process also helps preserve compute resources and provides easy access to the exact binaries tested in CI pipelines,
while adhering to [PEP-440](https://peps.python.org/pep-0440/) versioning standards:

- `develop` wheels use the version format `dev{date}+{build_number}` (e.g., `1.208.0.dev20241212+7001`).
- `nightly` wheels use the version format `a{date}` (alpha) (e.g., `1.208.0a20241212`).

| Platform           | Nightly | Develop |
| :----------------- | :------ | :------ |
| `Linux (x86_64)`   | ✓       | ✓       |
| `Linux (ARM64)`    | ✓       | -       |
| `macOS (ARM64)`    | ✓       | ✓       |
| `Windows (x86_64)` | ✓       | ✓       |

**Note**: Development wheels from the `develop` branch publish for every supported platform except Linux ARM64.
Skipping that target keeps CI feedback fast while avoiding unnecessary build resource usage.

:::warning
We do not recommend using development wheels in production environments, such as live trading controlling real capital.
:::

### Installation commands

By default, uv will install the latest stable release. Adding the `--pre` flag ensures that pre-release versions, including development wheels, are considered.

To install the latest available pre-release (including development wheels):

```bash
uv pip install nautilus_trader --pre --index-url=https://packages.nautechsystems.io/simple
```

To install a specific development wheel (e.g., `1.221.0a20250912` for September 12, 2025):

```bash
uv pip install nautilus_trader==1.221.0a20250912 --index-url=https://packages.nautechsystems.io/simple
```

### Available versions

You can view all available versions of `nautilus_trader` on the [package index](https://packages.nautechsystems.io/simple/nautilus-trader/index.html).

To programmatically request and list available versions:

```bash
curl -s https://packages.nautechsystems.io/simple/nautilus-trader/index.html | grep -oP '(?<=<a href=")[^"]+(?=")' | awk -F'#' '{print $1}' | sort
```

### Branch updates

- `develop` branch wheels (`.dev`): Build and publish continuously with every merged commit.
- `nightly` branch wheels (`a`): Build and publish daily when we automatically merge the `develop` branch at **14:00 UTC** (if there are changes).

### Retention policies

- `develop` branch wheels (`.dev`): We retain only the most recent wheel build.
- `nightly` branch wheels (`a`): We retain only the 30 most recent wheel builds.

### Verifying build provenance

All release artifacts (wheels and source distributions) published to PyPI, GitHub Releases,
and the Nautech Systems package index include cryptographic attestations that prove their authenticity and build provenance.

These attestations are generated automatically during the CI/CD pipeline using [SLSA](https://slsa.dev/) build provenance, and can be verified to ensure:

- The artifact was built by the official NautilusTrader GitHub Actions workflow.
- The artifact corresponds to a specific commit SHA in the repository.
- The artifact hasn't been tampered with since it was built.

To verify a wheel file using the GitHub CLI:

```bash
gh attestation verify nautilus_trader-1.220.0-*.whl --owner nautechsystems
```

This provides supply chain security by allowing you to cryptographically verify that the installed package came from the official NautilusTrader build process.

:::note
Attestation verification requires the [GitHub CLI](https://cli.github.com/) (`gh`) to be installed.
Development wheels from `develop` and `nightly` branches are also attested and can be verified the same way.
:::

## From source

It's possible to install from source using pip if you first install the build dependencies as specified in the `pyproject.toml`.

1. Install [rustup](https://rustup.rs/) (the Rust toolchain installer):
   - Linux and macOS:

     ```bash
     curl https://sh.rustup.rs -sSf | sh
     ```

   - Windows:
     - Download and install [`rustup-init.exe`](https://win.rustup.rs/x86_64)
     - Install "Desktop development with C++" using [Build Tools for Visual Studio 2022](https://visualstudio.microsoft.com/visual-cpp-build-tools/)
   - Verify (any system): From a terminal session run `rustc --version`

2. Enable `cargo` in the current shell:
   - Linux and macOS:

     ```bash
     source $HOME/.cargo/env
     ```

   - Windows: Start a new PowerShell

3. Install [clang](https://clang.llvm.org/) (a C language frontend for LLVM):
   - Linux:

     ```bash
     sudo apt-get install clang
     ```

   - Windows:
     1. Add Clang to your [Build Tools for Visual Studio 2022](https://visualstudio.microsoft.com/visual-cpp-build-tools/):
        - Start | Visual Studio Installer | Modify | C++ Clang tools for Windows (latest) = checked | Modify
     2. Enable `clang` in the current shell:

        ```powershell
        [System.Environment]::SetEnvironmentVariable('path', "C:\Program Files\Microsoft Visual Studio\2022\BuildTools\VC\Tools\Llvm\x64\bin\;" + $env:Path,"User")
        ```

   - Verify (any system): From a terminal session run `clang --version`

4. Install uv (see the [uv installation guide](https://docs.astral.sh/uv/getting-started/installation) for more details):
   - Linux and macOS:

     ```bash
     curl -LsSf https://astral.sh/uv/install.sh | sh
     ```

   - Windows (PowerShell):

     ```powershell
     irm https://astral.sh/uv/install.ps1 | iex
     ```

5. Clone the source with `git`, and install from the project's root directory:

```bash
git clone --branch develop --depth 1 https://github.com/nautechsystems/nautilus_trader
cd nautilus_trader
uv sync --all-extras
```

:::note
The `--depth 1` flag fetches just the latest commit for a faster, lightweight clone.
:::

6. Set environment variables for PyO3 compilation (Linux and macOS only):

```bash
# Set the library path for the Python interpreter (in this case Python 3.13.4)
export LD_LIBRARY_PATH="$HOME/.local/share/uv/python/cpython-3.13.4-linux-x86_64-gnu/lib:$LD_LIBRARY_PATH"

# Set the Python executable path for PyO3
export PYO3_PYTHON=$(pwd)/.venv/bin/python
```

:::note
Adjust the Python version and architecture in the `LD_LIBRARY_PATH` to match your system.
Use `uv python list` to find the exact path for your Python installation.
:::

## From GitHub release

To install a binary wheel from GitHub, first navigate to the [latest release](https://github.com/nautechsystems/nautilus_trader/releases/latest).
Download the appropriate `.whl` for your operating system and Python version, then run:

```bash
uv pip install <file-name>.whl
```

## Versioning and releases

NautilusTrader is still under active development. Some features may be incomplete, and while
the API is becoming more stable, breaking changes can occur between releases.
We strive to document these changes in the release notes on a **best-effort basis**.

We aim to follow a **bi-weekly release schedule**, though experimental or larger features may cause delays.

Use NautilusTrader only if you are prepared to adapt to these changes.

## Redis

Using [Redis](https://redis.io) with NautilusTrader is **optional** and only required if configured as the backend for a cache database or [message bus](../concepts/message_bus.md).

:::info
The minimum supported Redis version is 6.2 (required for [streams](https://redis.io/docs/latest/develop/data-types/streams/) functionality).
:::

For a quick setup, we recommend using a [Redis Docker container](https://hub.docker.com/_/redis/). You can find an example setup in the `.docker` directory,
or run the following command to start a container:

```bash
docker run -d --name redis -p 6379:6379 redis:latest
```

This command will:

- Pull the latest version of Redis from Docker Hub if it's not already downloaded.
- Run the container in detached mode (`-d`).
- Name the container `redis` for easy reference.
- Expose Redis on the default port 6379, making it accessible to NautilusTrader on your machine.

To manage the Redis container:

- Start it with `docker start redis`
- Stop it with `docker stop redis`

:::tip
We recommend using [Redis Insight](https://redis.io/insight/) as a GUI to visualize and debug Redis data efficiently.
:::

## Precision mode

NautilusTrader supports two precision modes for its core value types (`Price`, `Quantity`, `Money`),
which differ in their internal bit-width and maximum decimal precision.

- **High-precision**: 128-bit integers with up to 16 decimals of precision, and a larger value range.
- **Standard-precision**: 64-bit integers with up to 9 decimals of precision, and a smaller value range.

:::note
By default, the official Python wheels **ship** in high-precision (128-bit) mode on Linux and macOS.
On Windows, only standard-precision (64-bit) is available due to the lack of native 128-bit integer support.

For the Rust crates, the default is standard-precision unless you explicitly enable the `high-precision` feature flag.
:::

The performance tradeoff is that standard-precision is ~3–5% faster in typical backtests,
but has lower decimal precision and a smaller representable value range.

:::note
Performance benchmarks comparing the modes are pending.
:::

### Build configuration

The precision mode is determined by:

- Setting the `HIGH_PRECISION` environment variable during compilation, **and/or**
- Enabling the `high-precision` Rust feature flag explicitly.

#### High-precision mode (128-bit)

```bash
export HIGH_PRECISION=true
make install-debug
```

#### Standard-precision mode (64-bit)

```bash
export HIGH_PRECISION=false
make install-debug
```

### Rust feature flag

To enable high-precision (128-bit) mode in Rust, add the `high-precision` feature to your `Cargo.toml`:

```toml
[dependencies]
nautilus_core = { version = "*", features = ["high-precision"] }
```

:::info
See the [Value Types](../concepts/overview.md#value-types) specifications for more details.
:::

</document_content>
</document>
<document index="1478">
<source>docs/getting_started/quickstart.md</source>
<document_content>
# Quickstart

This guide is generated from the Jupyter notebook [quickstart.ipynb](quickstart.ipynb).

</document_content>
</document>
<document index="1479">
<source>docs/integrations/betfair.md</source>
<document_content>
# Betfair

Founded in 2000, Betfair operates the world’s largest online betting exchange,
with its headquarters in London and satellite offices across the globe.

NautilusTrader provides an adapter for integrating with the Betfair REST API and
Exchange Streaming API.

## Installation

Install NautilusTrader with Betfair support:

```bash
uv pip install "nautilus_trader[betfair]"
```

To build from source with Betfair extras:

```bash
uv sync --all-extras
```

## Examples

You can find live example scripts [here](https://github.com/nautechsystems/nautilus_trader/tree/develop/examples/live/betfair/).

## Betfair documentation

For API details and troubleshooting, see the official [Betfair Developer Documentation](https://developer.betfair.com/en/get-started/).

## Application keys

Betfair requires an Application Key to authenticate API requests. After registering and funding your account, obtain your key using the [API-NG Developer AppKeys Tool](https://apps.betfair.com/visualisers/api-ng-account-operations/).

:::info
See also the [Betfair Getting Started - Application Keys](https://betfair-developer-docs.atlassian.net/wiki/spaces/1smk3cen4v3lu3yomq5qye0ni/pages/2687105/Application+Keys) guide.
:::

## API credentials

Supply your Betfair credentials via environment variables or client configuration:

```bash
export BETFAIR_USERNAME=<your_username>
export BETFAIR_PASSWORD=<your_password>
export BETFAIR_APP_KEY=<your_app_key>
export BETFAIR_CERTS_DIR=<path_to_certificate_dir>
```

:::tip
We recommend using environment variables to manage your credentials.
:::

## Overview

The Betfair adapter provides three primary components:

- `BetfairInstrumentProvider`: loads Betfair markets and converts them into Nautilus instruments.
- `BetfairDataClient`: streams real-time market data from the Exchange Streaming API.
- `BetfairExecutionClient`: submits orders (bets) and tracks execution status via the REST API.

## Orders capability

Betfair operates as a betting exchange with unique characteristics compared to traditional financial exchanges:

### Order types

| Order Type             | Supported | Notes                               |
|------------------------|-----------|-------------------------------------|
| `MARKET`               | -         | Not applicable to betting exchange. |
| `LIMIT`                | ✓         | Orders placed at specific odds.     |
| `STOP_MARKET`          | -         | *Not supported*.                    |
| `STOP_LIMIT`           | -         | *Not supported*.                    |
| `MARKET_IF_TOUCHED`    | -         | *Not supported*.                    |
| `LIMIT_IF_TOUCHED`     | -         | *Not supported*.                    |
| `TRAILING_STOP_MARKET` | -         | *Not supported*.                    |

### Execution instructions

| Instruction   | Supported | Notes                               |
|---------------|-----------|-------------------------------------|
| `post_only`   | -         | Not applicable to betting exchange. |
| `reduce_only` | -         | Not applicable to betting exchange. |

### Time in force options

| Time in force | Supported | Notes                               |
|---------------|-----------|-------------------------------------|
| `GTC`         | -         | Betting exchange uses different model. |
| `GTD`         | -         | Betting exchange uses different model. |
| `FOK`         | -         | Betting exchange uses different model. |
| `IOC`         | -         | Betting exchange uses different model. |

### Advanced order features

| Feature            | Supported | Notes                                    |
|--------------------|-----------|------------------------------------------|
| Order Modification | ✓         | Limited to non-exposure changing fields. |
| Bracket/OCO Orders | -         | *Not supported*.                         |
| Iceberg Orders     | -         | *Not supported*.                         |

### Batch operations

| Operation          | Supported | Notes                |
|--------------------|-----------|----------------------|
| Batch Submit       | -         | *Not supported*.     |
| Batch Modify       | -         | *Not supported*.     |
| Batch Cancel       | -         | *Not supported*.     |

### Position management

| Feature             | Supported | Notes                                   |
|---------------------|-----------|-----------------------------------------|
| Query positions     | -         | Betting exchange model differs.         |
| Position mode       | -         | Not applicable to betting exchange.     |
| Leverage control    | -         | No leverage in betting exchange.        |
| Margin mode         | -         | No margin in betting exchange.          |

### Order querying

| Feature              | Supported | Notes                                   |
|----------------------|-----------|-----------------------------------------|
| Query open orders    | ✓         | List all active bets.                   |
| Query order history  | ✓         | Historical betting data.                |
| Order status updates | ✓         | Real-time bet state changes.            |
| Trade history        | ✓         | Bet matching and settlement reports.    |

### Contingent orders

| Feature             | Supported | Notes                                  |
|---------------------|-----------|------------------------------------------|
| Order lists         | -         | *Not supported*.                        |
| OCO orders          | -         | *Not supported*.                        |
| Bracket orders      | -         | *Not supported*.                        |
| Conditional orders  | -         | Basic bet conditions only.              |

## Configuration

### Data client configuration options

| Option                    | Default   | Description |
|---------------------------|-----------|-------------|
| `account_currency`        | Required  | Betfair account currency for data and price feeds. |
| `username`                | `None`    | Betfair account username; taken from environment when omitted. |
| `password`                | `None`    | Betfair account password; taken from environment when omitted. |
| `app_key`                 | `None`    | Betfair application key used for API authentication. |
| `certs_dir`               | `None`    | Directory containing Betfair SSL certificates for login. |
| `instrument_config`       | `None`    | Optional `BetfairInstrumentProviderConfig` to scope available markets. |
| `subscription_delay_secs` | `3`       | Delay (seconds) before initial market subscription request is sent. |
| `keep_alive_secs`         | `36,000`  | Keep-alive interval (seconds) for the Betfair session. |
| `stream_conflate_ms`      | `None`    | Explicit stream conflation interval in milliseconds (`0` disables conflation). |
| `proxy_url`               | `None`    | Optional proxy URL for HTTP requests. |

### Execution client configuration options

| Option                       | Default  | Description |
|------------------------------|----------|-------------|
| `account_currency`           | Required | Betfair account currency for order placement and balances. |
| `username`                   | `None`   | Betfair account username; taken from environment when omitted. |
| `password`                   | `None`   | Betfair account password; taken from environment when omitted. |
| `app_key`                    | `None`   | Betfair application key used for API authentication. |
| `certs_dir`                  | `None`   | Directory containing Betfair SSL certificates for login. |
| `instrument_config`          | `None`   | Optional `BetfairInstrumentProviderConfig` to scope reconciliation. |
| `calculate_account_state`    | `True`   | Calculate account state locally from events when `True`. |
| `request_account_state_secs` | `300`    | Interval (seconds) to poll Betfair for account state (`0` disables). |
| `reconcile_market_ids_only`  | `False`  | When `True`, reconciliation requests only cover configured market IDs. |
| `ignore_external_orders`     | `False`  | When `True`, ignore stream orders missing from the local cache. |
| `proxy_url`                  | `None`   | Optional proxy URL for HTTP requests. |

Here is a minimal example showing how to configure a live `TradingNode` with Betfair clients:

```python
from nautilus_trader.adapters.betfair import BETFAIR
from nautilus_trader.adapters.betfair import BetfairLiveDataClientFactory
from nautilus_trader.adapters.betfair import BetfairLiveExecClientFactory
from nautilus_trader.config import TradingNodeConfig
from nautilus_trader.live.node import TradingNode

# Configure Betfair data and execution clients (using AUD account currency)
config = TradingNodeConfig(
    data_clients={BETFAIR: {"account_currency": "AUD"}},
    exec_clients={BETFAIR: {"account_currency": "AUD"}},
)

# Build the TradingNode with Betfair adapter factories
node = TradingNode(config)
node.add_data_client_factory(BETFAIR, BetfairLiveDataClientFactory)
node.add_exec_client_factory(BETFAIR, BetfairLiveExecClientFactory)
node.build()
```

:::info
For additional features or to contribute to the Betfair adapter, please see our
[contributing guide](https://github.com/nautechsystems/nautilus_trader/blob/develop/CONTRIBUTING.md).
:::

</document_content>
</document>
<document index="1480">
<source>docs/integrations/blockchain.md</source>
<document_content>
# Blockchain

## Core Primitives

Nautilus Trader's blockchain integration is built on foundational primitives defined in the DeFi domain model (`nautilus_model::defi`). These building blocks provide type-safe abstractions for working with EVM-based blockchains.

### Chain

The `Chain` struct represents a blockchain network with its connection endpoints and metadata. Each chain instance contains:

**Fields:**

- `name` (`Blockchain`): The blockchain network type (enum of 80+ supported chains)
- `chain_id` (`u32`): Unique EVM chain identifier (e.g., 1 for Ethereum, 42161 for Arbitrum)
- `hypersync_url` (`String`): Endpoint for high-performance Hypersync data streaming
- `rpc_url` (`Option<String>`): Optional HTTP/WSS RPC endpoint for direct node communication
- `native_currency_decimals` (`u8`): Decimal precision for the chain's native gas token (typically 18)

**Chain Retrieval:**

Chains can be retrieved by numeric ID or string name (case-insensitive):

- **By Chain ID:** Lookup using EVM chain identifier with `from_chain_id`
- **By Name:** Lookup using blockchain name (case-insensitive: "ethereum", "Ethereum", "ETHEREUM" all work) with `from_chain_name`
- **Static Instances:** Pre-configured chains available as constants

Each chain has a native currency used for gas fees. The `native_currency()` method returns a properly configured Currency instance:

| Chain Family                                    | Code | Name         | Decimals |
|-------------------------------------------------|------|--------------|----------|
| Ethereum & L2s (Arbitrum, Base, Optimism, etc.) | ETH  | Ethereum     | 18       |
| Polygon                                         | POL  | Polygon      | 18       |
| Avalanche                                       | AVAX | Avalanche    | 18       |
| BSC                                             | BNB  | Binance Coin | 18       |

## Contracts

High-performance interface for querying EVM smart contracts with type-safe Rust abstractions. Supports token metadata, DEX pools, and DeFi protocols through efficient batch operations.

### Base (Multicall3)

Batches multiple contract calls into a single RPC request using Multicall3 (`0xcA11bde05977b3631167028862bE2a173976CA11`).

- Always uses `allow_failure: true` for partial success and detailed errors
- Executes atomically in the same block
- Errors: `RpcError` (network issues), `AbiDecodingError` (decode failures)

### ERC20

Inherits from `BaseContract` to leverage Multicall3 for efficient batch operations. Fetches token metadata with robust handling for non-standard implementations.

**Methods:**

- `fetch_token_info`: Single token metadata (uses multicall internally for name, symbol, decimals)
- `batch_fetch_token_info`: Multiple tokens in one multicall (3 calls per token)
- `enforce_token_fields`: Validate non-empty name/symbol

**Error Types:**

1. **`CallFailed`** - Contract missing or function not implemented → Skip token
2. **`DecodingError`** - Raw bytes instead of ABI encoding (e.g., `0x5269636f...`) → Skip token
3. **`EmptyTokenField`** - Function returns empty string → Skip if enforced

**Best Practices:**

- Skip pools with any token errors
- `raw_data` field preserves original response for debugging
- Non-standard tokens often have other issues (transfer fees, rebasing)

## Configuration

| Option                          | Default | Description |
|---------------------------------|---------|-------------|
| `chain`                         | Required | `nautilus_trader.model.Chain` to synchronize (e.g., `Chain.ETHEREUM`). |
| `dex_ids`                       | Required | Sequence of `DexType` identifiers describing which DEX integrations to enable. |
| `http_rpc_url`                  | Required | HTTPS RPC endpoint used for EVM calls and Multicall requests. |
| `wss_rpc_url`                   | `None`  | Optional WSS endpoint for streaming live updates. |
| `rpc_requests_per_second`       | `None`  | Optional throttle for outbound RPC calls (requests per second). |
| `multicall_calls_per_rpc_request` | `100` | Maximum number of Multicall targets batched per RPC request. |
| `use_hypersync_for_live_data`   | `True`  | When `True`, bootstrap and stream using Hypersync for lower-latency diffs. |
| `from_block`                    | `None`  | Optional starting block height for historical backfill. |
| `pool_filters`                  | `DexPoolFilters()` | Filtering rules applied when selecting DEX pools to monitor. |
| `postgres_cache_database_config`| `None`  | Optional `PostgresConnectOptions` enabling on-disk caching of decoded pool state. |
| `http_proxy_url`                | `None`  | Optional HTTP proxy URL for RPC requests. |
| `ws_proxy_url`                  | `None`  | Optional WebSocket proxy URL for RPC connections. |

</document_content>
</document>
<document index="1481">
<source>docs/integrations/bybit.md</source>
<document_content>
# Bybit

Founded in 2018, Bybit is one of the largest cryptocurrency exchanges in terms
of daily trading volume, and open interest of crypto assets and crypto
derivative products. This integration supports live market data ingest and order
execution with Bybit.

## Examples

You can find live example scripts [here](https://github.com/nautechsystems/nautilus_trader/tree/develop/examples/live/bybit/).

## Overview

This guide assumes a trader is setting up for both live market data feeds, and trade execution.
The Bybit adapter includes multiple components, which can be used together or separately depending
on the use case.

- `BybitHttpClient`: Low-level HTTP API connectivity.
- `BybitWebSocketClient`: Low-level WebSocket API connectivity.
- `BybitInstrumentProvider`: Instrument parsing and loading functionality.
- `BybitDataClient`: A market data feed manager.
- `BybitExecutionClient`: An account management and trade execution gateway.
- `BybitLiveDataClientFactory`: Factory for Bybit data clients (used by the trading node builder).
- `BybitLiveExecClientFactory`: Factory for Bybit execution clients (used by the trading node builder).

:::note
Most users will simply define a configuration for a live trading node (as below),
and won't need to necessarily work with these lower level components directly.
:::

## Bybit documentation

Bybit provides extensive documentation for users which can be found in the [Bybit help center](https://www.bybit.com/en/help-center).
It’s recommended you also refer to the Bybit documentation in conjunction with this NautilusTrader integration guide.

## Products

A product is an umbrella term for a group of related instrument types.

:::note
Product is also referred to as `category` in the Bybit v5 API.
:::

The following product types are supported on Bybit:

| Product Type                | Supported | Notes                                    |
|-----------------------------|-----------|------------------------------------------|
| Spot cryptocurrencies       | ✓         | Native spot markets with margin support. |
| Linear perpetual contracts  | ✓         | USDT/USDC margined perpetual swaps.      |
| Linear futures contracts    | ✓         | Delivery-settled linear futures.         |
| Inverse perpetual contracts | ✓         | Coin-margined perpetual swaps.           |
| Inverse futures contracts   | ✓         | Coin-margined delivery futures.          |
| Option contracts            | ✓         | USDC-settled options.                    |

## Symbology

To distinguish between different product types on Bybit, Nautilus uses specific product category suffixes for symbols:

- `-SPOT`: Spot cryptocurrencies
- `-LINEAR`: Perpetual and futures contracts
- `-INVERSE`: Inverse perpetual and inverse futures contracts
- `-OPTION`: Option contracts

These suffixes must be appended to the Bybit raw symbol string to identify the specific product type
for the instrument ID. For example:

- The Ether/Tether spot currency pair is identified with `-SPOT`, such as `ETHUSDT-SPOT`.
- The BTCUSDT perpetual futures contract is identified with `-LINEAR`, such as `BTCUSDT-LINEAR`.
- The BTCUSD inverse perpetual futures contract is identified with `-INVERSE`, such as `BTCUSD-INVERSE`.

## Orders capability

Bybit offers a flexible combination of trigger types, enabling a broader range of Nautilus orders.
All the order types listed below can be used as *either* entries or exits, except for trailing stops
(which utilize a position-related API).

### Order types

| Order Type             | Spot | Linear | Inverse | Notes                     |
|------------------------|------|--------|---------|---------------------------|
| `MARKET`               | ✓    | ✓      | ✓       | Supports quote quantity.  |
| `LIMIT`                | ✓    | ✓      | ✓       |                           |
| `STOP_MARKET`          | ✓    | ✓      | ✓       |                           |
| `STOP_LIMIT`           | ✓    | ✓      | ✓       |                           |
| `MARKET_IF_TOUCHED`    | ✓    | ✓      | ✓       |                           |
| `LIMIT_IF_TOUCHED`     | ✓    | ✓      | ✓       |                           |
| `TRAILING_STOP_MARKET` | -    | ✓      | ✓       | *Not supported for Spot*. |

### Execution instructions

| Instruction   | Spot | Linear | Inverse | Notes                              |
|---------------|------|--------|---------|------------------------------------|
| `post_only`   | ✓    | ✓      | ✓       | Only supported on `LIMIT` orders.  |
| `reduce_only` | -    | ✓      | ✓       | *Not supported for Spot*.          |

### Time in force

| Time in force | Spot | Linear | Inverse | Notes                        |
|---------------|------|--------|---------|------------------------------|
| `GTC`         | ✓    | ✓      | ✓       | Good Till Canceled.          |
| `GTD`         | -    | -      | -       | *Not supported*.             |
| `FOK`         | ✓    | ✓      | ✓       | Fill or Kill.                |
| `IOC`         | ✓    | ✓      | ✓       | Immediate or Cancel.         |

### Advanced order features

| Feature            | Spot | Linear | Inverse | Notes                                  |
|--------------------|------|--------|---------|----------------------------------------|
| Order Modification | ✓    | ✓      | ✓       | Price and quantity modification.       |
| Bracket/OCO Orders | ✓    | ✓      | ✓       | UI only; API users implement manually. |
| Iceberg Orders     | ✓    | ✓      | ✓       | Max 10 per account, 1 per symbol.      |

### Batch operations

| Operation          | Spot | Linear | Inverse | Notes                                     |
|--------------------|------|--------|---------|-------------------------------------------|
| Batch Submit       | ✓    | ✓      | ✓       | Submit multiple orders in single request. |
| Batch Modify       | ✓    | ✓      | ✓       | Modify multiple orders in single request. |
| Batch Cancel       | ✓    | ✓      | ✓       | Cancel multiple orders in single request. |

### Position management

| Feature             | Spot | Linear | Inverse | Notes                                    |
|---------------------|------|--------|---------|------------------------------------------|
| Query positions     | -    | ✓      | ✓       | Real-time position updates.              |
| Position mode       | -    | ✓      | ✓       | One-Way vs Hedge mode.                   |
| Leverage control    | -    | ✓      | ✓       | Dynamic leverage adjustment per symbol.  |
| Margin mode         | -    | ✓      | ✓       | Cross vs Isolated margin.                |

### Order querying

| Feature             | Spot | Linear | Inverse | Notes                                   |
|---------------------|------|--------|---------|-----------------------------------------|
| Query open orders   | ✓    | ✓      | ✓       | List all active orders.                 |
| Query order history | ✓    | ✓      | ✓       | Historical order data.                  |
| Order status updates| ✓    | ✓      | ✓       | Real-time order state changes.          |
| Trade history       | ✓    | ✓      | ✓       | Execution and fill reports.             |

### Contingent orders

| Feature             | Spot | Linear | Inverse | Notes                                   |
|---------------------|------|--------|---------|-----------------------------------------|
| Order lists         | -    | -      | -       | *Not supported*.                        |
| OCO orders          | ✓    | ✓      | ✓       | UI only; API users implement manually.  |
| Bracket orders      | ✓    | ✓      | ✓       | UI only; API users implement manually.  |
| Conditional orders  | ✓    | ✓      | ✓       | Stop and limit-if-touched orders.       |

### Order parameters

Individual orders can be customized using the `params` dictionary when submitting orders:

| Parameter     | Type   | Description                                                                    |
|---------------|--------|--------------------------------------------------------------------------------|
| `is_leverage` | `bool` | For Spot products only. If `True`, enables margin trading (borrowing) for the order. Default: `False`. See [Bybit's isLeverage documentation](https://bybit-exchange.github.io/docs/v5/order/create-order#request-parameters). |

#### Example: Spot margin trading

```python
# Submit a Spot order with margin enabled
order = strategy.order_factory.market(
    instrument_id=InstrumentId.from_str("BTCUSDT-SPOT.BYBIT"),
    order_side=OrderSide.BUY,
    quantity=Quantity.from_str("0.1"),
    params={"is_leverage": True}  # Enable margin for this order
)
strategy.submit_order(order)
```

:::note
Without `is_leverage=True` in the params, Spot orders will only use your available balance
and won't borrow funds, even if you have auto-borrow enabled on your Bybit account.
:::

For a complete example of using order parameters including `is_leverage`, see the
[bybit_exec_tester.py](https://github.com/nautechsystems/nautilus_trader/tree/develop/examples/live/bybit/bybit_exec_tester.py) example.

## Spot margin borrowing and repayment

NautilusTrader provides automated spot margin borrow repayment functionality to prevent interest accrual after closing short positions on Bybit.

### Background

When trading Spot with margin enabled (`is_leverage=True`), Bybit automatically borrows coins when you execute short positions.
However, after you close the short position (BUY order fills), the borrowed coins are **NOT automatically repaid** - they continue accruing hourly interest charges until manually repaid.
This can result in significant interest costs if left unattended.

### Automatic repayment (recommended)

NautilusTrader automatically repays spot margin borrows immediately after BUY orders fill on Spot instruments.
This feature is **enabled by default** via the `auto_repay_spot_borrows` configuration flag.

**How it works:**

1. When a Spot BUY order fills, the execution client automatically attempts to repay any outstanding borrows for that coin.
2. The repayment uses Bybit's `no-convert-repay` endpoint, which repays the full outstanding borrow amount.
3. If the repayment fails (e.g., API error), it logs the error but does not crash the execution client.
4. Repayments are automatically skipped during Bybit's UTC blackout window (see below).

**Example:**

```python
from nautilus_trader.adapters.bybit import BybitExecClientConfig

config = BybitExecClientConfig(
    api_key="YOUR_API_KEY",
    api_secret="YOUR_API_SECRET",
    product_types=[BybitProductType.SPOT],
    auto_repay_spot_borrows=True,  # Default is True
)
```

### UTC blackout window

Bybit blocks `no-convert-repay` operations daily during **04:00-05:30 UTC** for interest calculation processing. NautilusTrader automatically detects this window and skips repayment attempts, logging a warning instead.

During the blackout window, any BUY order fills will trigger a warning like:

```
Skipping borrow repayment for BTC due to Bybit blackout window (04:00-05:30 UTC daily). Will need manual repayment.
```

**Important:** If your BUY orders fill during the blackout window, you'll need to manually repay the borrows after 05:30 UTC to stop interest accrual, or wait for the next BUY order fill outside the blackout window.

### Configuration options

| Option                    | Type   | Default | Description                                                                 |
|---------------------------|--------|---------|-----------------------------------------------------------------------------|
| `auto_repay_spot_borrows` | `bool` | `True`  | If `True`, automatically repay spot margin borrows after BUY orders fill. Prevents interest accrual on borrowed coins. Repayment is skipped during blackout window. |

### Important notes

- Auto-repayment only triggers on **Spot BUY orders**, not derivatives.
- Repayment uses the `no-convert-repay` endpoint which repays the full outstanding borrow by default.
- The feature gracefully handles API errors and logs failures without crashing.
- Bybit is planning to release an auto-repay mode at the venue level (end of month), which may make this feature redundant in the future.
- Manual borrowing is still required before opening short positions unless auto-borrow is enabled on your Bybit account.

### Spot trading limitations

The following limitations apply to Spot products, as positions are not tracked on the venue side:

- `reduce_only` orders are *not supported*.
- Trailing stop orders are *not supported*.

### Trailing stops

Trailing stops on Bybit do not have a client order ID on the venue side (though there is a `venue_order_id`).
This is because trailing stops are associated with a netted position for an instrument.
Consider the following points when using trailing stops on Bybit:

- `reduce_only` instruction is available
- When the position associated with a trailing stop is closed, the trailing stop is automatically "deactivated" (closed) on the venue side.
- You cannot query trailing stop orders that are not already open (the `venue_order_id` is unknown until then).
- You can manually adjust the trigger price in the GUI, which will update the Nautilus order.

## Rate limiting

Every HTTP call consumes the global token bucket as well as any keyed quota(s). When usage exceeds a bucket, requests are queued automatically, so manual throttling is rarely required.

| Key / Endpoint            | Limit (requests/sec) | Notes                                                |
|---------------------------|----------------------|------------------------------------------------------|
| `bybit:global`            | 120                  | Exchange-wide 600 req / 5 s ceiling.                 |
| `/v5/market/kline`        | 20                   | Historical sweeps throttled slightly below global.   |
| `/v5/market/trades`       | 24                   | Matches the global quota.                            |
| `/v5/order/create`        | 10                   | Standard order placement.                            |
| `/v5/order/cancel`        | 10                   | Single-order cancellation.                           |
| `/v5/order/create-batch`  | 5                    | Batch placement endpoints.                           |
| `/v5/order/cancel-batch`  | 5                    | Batch cancellation endpoints.                        |
| `/v5/order/cancel-all`    | 2                    | Full book cancel to mirror Bybit guidance.           |

:::warning
Bybit responds with error code `10016` when the rate limit is exceeded and may temporarily block the IP if requests continue without back-off.
:::

:::info
For more details on rate limiting, see the official documentation: <https://bybit-exchange.github.io/docs/v5/rate-limit>.
:::

### Data clients

If no product types are specified then all product types will be loaded and available.

### Execution clients

The adapter automatically determines the account type based on configured product types:

- **Spot only**: Uses `CASH` account type with borrowing support enabled
- **Derivatives or mixed products**: Uses `MARGIN` account type (UTA - Unified Trading Account)

This allows you to trade Spot alongside derivatives in a single Unified Trading Account, which is the standard account type for most Bybit users.

:::info
**Unified Trading Accounts (UTA) and Spot margin trading**

Most Bybit users now have Unified Trading Accounts (UTA) as Bybit steers new users to this account type.
Classic accounts are considered legacy.

For Spot margin trading on UTA accounts:

- Borrowing is **NOT automatically enabled** - it requires explicit API configuration
- To use Spot margin via API, you must submit orders with `is_leverage=True` in the parameters (see [Bybit docs](https://bybit-exchange.github.io/docs/v5/order/create-order#request-parameters))
- If auto-borrow/auto-repay is enabled on your Bybit account, the venue will automatically borrow/repay funds for those margin orders
- Without auto-borrow enabled, you'll need to manually manage borrowing through Bybit's interface

**Important**: The Nautilus Bybit adapter defaults to `is_leverage=False` for Spot orders,
meaning they won't use margin unless you explicitly enable it.
:::

## Fee currency logic

Understanding how Bybit determines the currency for trading fees is important for accurate accounting and position tracking. The fee currency rules vary between Spot and derivatives products.

### Spot trading fees

For Spot trading, the fee currency depends on the order side and whether the fee is a rebate (negative fee for maker orders):

#### Normal fees (positive)

- **BUY orders**: Fee is charged in the **base currency** (e.g., BTC for BTCUSDT)
- **SELL orders**: Fee is charged in the **quote currency** (e.g., USDT for BTCUSDT)

#### Maker rebates (negative fees)

When maker fees are negative (rebates), the currency logic is **inverted**:

- **BUY orders with maker rebate**: Rebate is paid in the **quote currency** (e.g., USDT for BTCUSDT)
- **SELL orders with maker rebate**: Rebate is paid in the **base currency** (e.g., BTC for BTCUSDT)

:::note
**Taker orders never have inverted logic**, even if the maker fee rate is negative. Taker fees always follow the normal fee currency rules.
:::

#### Example: BTCUSDT Spot

- **Buy 1 BTC as taker (0.1% fee)**: Pay 0.001 BTC in fees
- **Sell 1 BTC as taker (0.1% fee)**: Pay equivalent USDT in fees
- **Buy 1 BTC as maker (-0.01% rebate)**: Receive USDT rebate (inverted)
- **Sell 1 BTC as maker (-0.01% rebate)**: Receive BTC rebate (inverted)

### Derivatives trading fees

For all derivatives products (LINEAR, INVERSE, OPTION), fees are always charged in the **settlement currency**:

| Product Type | Settlement Currency                   | Fee Currency |
|--------------|---------------------------------------|--------------|
| LINEAR       | USDT (typically)                      | USDT         |
| INVERSE      | Base coin (e.g., BTC for BTCUSD)      | Base coin    |
| OPTION       | USDC (legacy) or USDT (post Feb 2025) | USDC/USDT    |

### Fee calculation

When the WebSocket execution message doesn't provide the exact fee amount (`execFee`), the adapter calculates fees as follows:

#### Spot products

- **BUY orders**: `fee = base_quantity × fee_rate`
- **SELL orders**: `fee = notional_value × fee_rate` (where `notional_value = quantity × price`)

#### Derivatives

- All derivatives: `fee = notional_value × fee_rate`

### Official documentation

For complete details on Bybit's fee structure and currency rules, refer to:

- [Bybit WebSocket Private Execution](https://bybit-exchange.github.io/docs/v5/websocket/private/execution)
- [Bybit Spot Fee Currency Instruction](https://bybit-exchange.github.io/docs/v5/enum#spot-fee-currency-instruction)

## Configuration

The product types for each client must be specified in the configurations.

### Data client configuration options

| Option                           | Default | Description |
|----------------------------------|---------|-------------|
| `api_key`                        | `None`  | API key; loaded from `BYBIT_API_KEY`/`BYBIT_TESTNET_API_KEY` when omitted. |
| `api_secret`                     | `None`  | API secret; loaded from `BYBIT_API_SECRET`/`BYBIT_TESTNET_API_SECRET` when omitted. |
| `product_types`                  | `None`  | Sequence of `BybitProductType` values to enable; loads all products when `None`. |
| `base_url_http`                  | `None`  | Override for the REST base URL. |
| `http_proxy_url`                 | `None` | Optional HTTP proxy URL. |
| `ws_proxy_url`                   | `None` | Optional WebSocket proxy URL (not yet implemented). |
| `demo`                           | `False` | Connect to the Bybit demo environment when `True`. |
| `testnet`                        | `False` | Connect to the Bybit testnet when `True`. |
| `update_instruments_interval_mins` | `60` | Interval (minutes) between instrument catalogue refreshes. |
| `recv_window_ms`                 | `5,000`| Receive window (milliseconds) for signed REST requests. |
| `bars_timestamp_on_close`        | `True` | Timestamp bars on the close (`True`) or open (`False`) of the interval. |
| `max_retries`                    | `None` | Maximum retry attempts for REST/WebSocket recovery. |
| `retry_delay_initial_ms`         | `None` | Initial delay (milliseconds) between retries. |
| `retry_delay_max_ms`             | `None` | Maximum delay (milliseconds) between retries. |

### Execution client configuration options

| Option                           | Default | Description |
|----------------------------------|---------|-------------|
| `api_key`                        | `None`  | API key; loaded from `BYBIT_API_KEY`/`BYBIT_TESTNET_API_KEY` when omitted. |
| `api_secret`                     | `None`  | API secret; loaded from `BYBIT_API_SECRET`/`BYBIT_TESTNET_API_SECRET` when omitted. |
| `product_types`                  | `None`  | Sequence of `BybitProductType` values to enable (Spot cannot be mixed with derivatives for execution). |
| `base_url_http`                  | `None`  | Override for the REST base URL. |
| `base_url_ws_private`            | `None`  | Override for the private WebSocket base URL. |
| `base_url_ws_trade`              | `None`  | Override for the trade WebSocket base URL. |
| `http_proxy_url`                 | `None` | Optional HTTP proxy URL. |
| `ws_proxy_url`                   | `None` | Optional WebSocket proxy URL (not yet implemented). |
| `demo`                           | `False` | Connect to the Bybit demo environment when `True`. |
| `testnet`                        | `False` | Connect to the Bybit testnet when `True`. |
| `use_gtd`                        | `False` | Remap GTD orders to GTC when `True` (Bybit lacks native GTD support). |
| `use_ws_execution_fast`          | `False` | Subscribe to the low-latency execution stream. |
| `use_http_batch_api`             | `False` | Use Bybit's HTTP batch trading API (deprecated). |
| `use_spot_position_reports`      | `False` | Report Spot wallet balances as positions when `True`. |
| `auto_repay_spot_borrows`        | `True`  | Automatically repay Spot margin borrows after BUY orders fully fill (Spot only). |
| `ignore_uncached_instrument_executions` | `False` | Ignore execution messages for instruments not yet cached. |
| `max_retries`                    | `None` | Maximum retry attempts for order submission/cancel/modify calls. |
| `retry_delay_initial_ms`         | `None` | Initial delay (milliseconds) between retries. |
| `retry_delay_max_ms`             | `None` | Maximum delay (milliseconds) between retries. |
| `recv_window_ms`                 | `5,000`| Receive window (milliseconds) for signed REST requests. |
| `ws_trade_timeout_secs`          | `5.0`  | Timeout (seconds) waiting for trade WebSocket acknowledgements. |
| `ws_auth_timeout_secs`           | `5.0`  | Timeout (seconds) waiting for auth WebSocket acknowledgements. |
| `futures_leverages`              | `None` | Mapping of `BybitSymbol` to leverage settings. |
| `position_mode`                  | `None` | Mapping of `BybitSymbol` to position mode (one-way vs hedge). |
| `margin_mode`                    | `None` | Margin mode setting for the account. |

The most common use case is to configure a live `TradingNode` to include Bybit
data and execution clients. To achieve this, add a `BYBIT` section to your client
configuration(s):

```python
from nautilus_trader.adapters.bybit import BYBIT
from nautilus_trader.adapters.bybit import BybitProductType
from nautilus_trader.live.node import TradingNode

config = TradingNodeConfig(
    ...,  # Omitted
    data_clients={
        BYBIT: {
            "api_key": "YOUR_BYBIT_API_KEY",
            "api_secret": "YOUR_BYBIT_API_SECRET",
            "base_url_http": None,  # Override with custom endpoint
            "product_types": [BybitProductType.LINEAR]
            "testnet": False,
        },
    },
    exec_clients={
        BYBIT: {
            "api_key": "YOUR_BYBIT_API_KEY",
            "api_secret": "YOUR_BYBIT_API_SECRET",
            "base_url_http": None,  # Override with custom endpoint
            "product_types": [BybitProductType.LINEAR]
            "testnet": False,
        },
    },
)
```

Then, create a `TradingNode` and add the client factories:

```python
from nautilus_trader.adapters.bybit import BYBIT
from nautilus_trader.adapters.bybit import BybitLiveDataClientFactory
from nautilus_trader.adapters.bybit import BybitLiveExecClientFactory
from nautilus_trader.live.node import TradingNode

# Instantiate the live trading node with a configuration
node = TradingNode(config=config)

# Register the client factories with the node
node.add_data_client_factory(BYBIT, BybitLiveDataClientFactory)
node.add_exec_client_factory(BYBIT, BybitLiveExecClientFactory)

# Finally build the node
node.build()
```

### API credentials

There are two options for supplying your credentials to the Bybit clients.
Either pass the corresponding `api_key` and `api_secret` values to the configuration objects, or
set the following environment variables:

For Bybit live clients, you can set:

- `BYBIT_API_KEY`
- `BYBIT_API_SECRET`

For Bybit demo clients, you can set:

- `BYBIT_DEMO_API_KEY`
- `BYBIT_DEMO_API_SECRET`

For Bybit testnet clients, you can set:

- `BYBIT_TESTNET_API_KEY`
- `BYBIT_TESTNET_API_SECRET`

:::tip
We recommend using environment variables to manage your credentials.
:::

When starting the trading node, you'll receive immediate confirmation of whether your
credentials are valid and have trading permissions.

:::info
For additional features or to contribute to the Bybit adapter, please see our
[contributing guide](https://github.com/nautechsystems/nautilus_trader/blob/develop/CONTRIBUTING.md).
:::

</document_content>
</document>
<document index="1482">
<source>docs/integrations/coinbase_intx.md</source>
<document_content>
# Coinbase International

[Coinbase International Exchange](https://www.coinbase.com/en/international-exchange) provides non-US institutional clients with access to cryptocurrency perpetual futures and spot markets.
The exchange serves European and international traders by providing leveraged crypto derivatives, often restricted or unavailable in these regions.

Coinbase International brings a high standard of customer protection, a robust risk management framework and high-performance trading technology, including:

- Real-time 24/7/365 risk management.
- Liquidity from external market makers (no proprietary trading).
- Dynamic margin requirements and collateral assessments.
- Liquidation framework that meets rigorous compliance standards.
- Well-capitalized exchange to support tail market events.
- Collaboration with top-tier global regulators.

:::info
See the [Introducing Coinbase International Exchange](https://www.coinbase.com/en-au/blog/introducing-coinbase-international-exchange) blog article for more details.
:::

## Installation

:::note
No additional `coinbase_intx` installation is required; the adapter’s core components, written in Rust, are automatically compiled and linked during the build.
:::

## Examples

You can find live example scripts [here](https://github.com/nautechsystems/nautilus_trader/tree/develop/examples/live/coinbase_intx).
These examples demonstrate how to set up live market data feeds and execution clients for trading on Coinbase International.

## Overview

The following products are supported on the Coinbase International exchange:

- Perpetual Futures contracts
- Spot cryptocurrencies

This guide assumes a trader is setting up for both live market data feeds, and trade execution.
The Coinbase International adapter includes multiple components, which can be used together or
separately depending on the use case. These components work together to connect to Coinbase International’s APIs
for market data and execution.

- `CoinbaseIntxHttpClient`: REST API connectivity.
- `CoinbaseIntxWebSocketClient`: WebSocket API connectivity.
- `CoinbaseIntxInstrumentProvider`: Instrument parsing and loading functionality.
- `CoinbaseIntxDataClient`: A market data feed manager.
- `CoinbaseIntxExecutionClient`: An account management and trade execution gateway.
- `CoinbaseIntxLiveDataClientFactory`: Factory for Coinbase International data clients.
- `CoinbaseIntxLiveExecClientFactory`: Factory for Coinbase International execution clients.

:::note
Most users will simply define a configuration for a live trading node (described below),
and won't necessarily need to work with the above components directly.
:::

## Coinbase documentation

Coinbase International provides extensive API documentation for users which can be found in the [Coinbase Developer Platform](https://docs.cdp.coinbase.com/intx/docs/welcome).
We recommend also referring to the Coinbase International documentation in conjunction with this NautilusTrader integration guide.

## Data

### Instruments

On startup, the adapter automatically loads all available instruments from the Coinbase International REST API
and subscribes to the `INSTRUMENTS` WebSocket channel for updates. This ensures that the cache and clients requiring
up-to-date definitions for parsing always have the latest instrument data.

Available instrument types include:

- `CurrencyPair` (Spot cryptocurrencies)
- `CryptoPerpetual`

:::note
Index products have not yet been implemented.
:::

The following data types are available:

- `OrderBookDelta` (L2 market-by-price)
- `QuoteTick` (L1 top-of-book best bid/ask)
- `TradeTick`
- `Bar`
- `MarkPriceUpdate`
- `IndexPriceUpdate`

:::note
Historical data requests have not yet been implemented.
:::

### WebSocket market data

The data client connects to Coinbase International's WebSocket feed to stream real-time market data.
The WebSocket client handles automatic reconnection and re-subscribes to active subscriptions upon reconnecting.

## Execution

**The adapter is designed to trade one Coinbase International portfolio per execution client.**

### Selecting a Portfolio

To identify your available portfolios and their IDs, use the REST client by running the following script:

```bash
python nautilus_trader/adapters/coinbase_intx/scripts/list_portfolios.py
```

This will output a list of portfolio details, similar to the example below:

```bash
[{'borrow_disabled': False,
  'cross_collateral_enabled': False,
  'is_default': False,
  'is_lsp': False,
  'maker_fee_rate': '-0.00008',
  'name': 'hrp5587988499',
  'portfolio_id': '3mnk59ap-1-22',  # Your portfolio ID
  'portfolio_uuid': 'dd0958ad-0c9d-4445-a812-1870fe40d0e1',
  'pre_launch_trading_enabled': False,
  'taker_fee_rate': '0.00012',
  'trading_lock': False,
  'user_uuid': 'd4fbf7ea-9515-1068-8d60-4de91702c108'}]
```

### Configuring the Portfolio

To specify a portfolio for trading, set the `COINBASE_INTX_PORTFOLIO_ID` environment variable to
the desired `portfolio_id`. If you're using multiple execution clients, you can alternatively define
the `portfolio_id` in the execution configuration for each client.

## Orders capability

Coinbase International offers market, limit, and stop order types, enabling a broad range of strategies.

### Order Types

| Order Type             | Derivatives | Spot | Notes                                   |
|------------------------|-------------|------|-----------------------------------------|
| `MARKET`               | ✓           | ✓    | Must use `IOC` or `FOK` time-in-forc    |
| `LIMIT`                | ✓           | ✓    |                                         |
| `STOP_MARKET`          | ✓           | ✓    |                                         |
| `STOP_LIMIT`           | ✓           | ✓    |                                         |
| `MARKET_IF_TOUCHED`    | -           | -    | *Not supported*.                        |
| `LIMIT_IF_TOUCHED`     | -           | -    | *Not supported*.                        |
| `TRAILING_STOP_MARKET` | -           | -    | *Not supported*.                        |

### Execution Instructions

| Instruction   | Derivatives | Spot | Notes                                            |
|---------------|-------------|------|--------------------------------------------------|
| `post_only`   | ✓           | ✓    | Ensures orders only provide liquidity.           |
| `reduce_only` | ✓           | ✓    | Ensures orders only reduce existing positions.   |

### Time in force options

| Time in force | Derivatives | Spot | Notes                                            |
|---------------|-------------|------|--------------------------------------------------|
| `GTC`         | ✓           | ✓    | Good Till Canceled.                              |
| `GTD`         | ✓           | ✓    | Good Till Date.                                  |
| `FOK`         | ✓           | ✓    | Fill or Kill.                                    |
| `IOC`         | ✓           | ✓    | Immediate or Cancel.                             |

### Advanced Order Features

| Feature            | Derivatives | Spot | Notes                                       |
|--------------------|-------------|------|---------------------------------------------|
| Order Modification | ✓           | ✓    | Price and quantity modification.             |
| Bracket/OCO Orders | ?           | ?    | Requires further investigation.              |
| Iceberg Orders     | ✓           | ✓    | Available via FIX protocol.                 |

### Batch operations

| Operation          | Derivatives | Spot | Notes                                       |
|--------------------|-------------|------|---------------------------------------------|
| Batch Submit       | -           | -    | *Not supported*.                            |
| Batch Modify       | -           | -    | *Not supported*.                            |
| Batch Cancel       | -           | -    | *Not supported*.                            |

### Position management

| Feature              | Derivatives | Spot | Notes                                       |
|--------------------|-------------|------|---------------------------------------------|
| Query positions     | ✓           | -    | Real-time position updates for derivatives.  |
| Position mode       | -           | -    | Single position mode only.                   |
| Leverage control    | ✓           | -    | Per-portfolio leverage settings.             |
| Margin mode         | ✓           | -    | Cross margin only.                           |

### Order querying

| Feature             | Derivatives | Spot | Notes                                       |
|---------------------|-------------|------|---------------------------------------------|
| Query open orders   | ✓           | ✓    | List all active orders.                      |
| Query order history | ✓           | ✓    | Historical order data.                       |
| Order status updates| ✓           | ✓    | Real-time updates via FIX drop copy.       |
| Trade history       | ✓           | ✓    | Execution and fill reports.                 |

### Contingent orders

| Feature              | Derivatives | Spot | Notes                                       |
|--------------------|-------------|------|---------------------------------------------|
| Order lists         | -           | -    | *Not supported*.                            |
| OCO orders          | ?           | ?    | Requires further investigation.              |
| Bracket orders      | ?           | ?    | Requires further investigation.              |
| Conditional orders  | ✓           | ✓    | Stop and stop-limit orders.                |

### FIX drop copy integration

The Coinbase International adapter includes a FIX (Financial Information eXchange) [drop copy](https://docs.cdp.coinbase.com/intx/docs/fix-msg-drop-copy) client.
This provides reliable, low-latency execution updates directly from Coinbase's matching engine.

:::note
This approach is necessary because execution messages are not provided over the WebSocket feed, and delivers faster and more reliable order execution updates than polling the REST API.
:::

The FIX client:

- Establishes a secure TCP/TLS connection and logs on automatically when the trading node starts.
- Handles connection monitoring and automatic reconnection and logon if the connection is interrupted.
- Properly logs out and closes the connection when the trading node stops.

The client processes several types of execution messages:

- Order status reports (canceled, expired, triggered).
- Fill reports (partial and complete fills).

The FIX credentials are automatically managed using the same API credentials as the REST and WebSocket clients.
No additional configuration is required beyond providing valid API credentials.

:::note
The REST client handles processing `REJECTED` and `ACCEPTED` status execution messages on order submission.
:::

### Account and position management

On startup, the execution client requests and loads your current account and execution state including:

- Available balances across all assets.
- Open orders.
- Open positions.

This provides your trading strategies with a complete picture of your account before placing new orders.

## Configuration

### Strategies

:::warning
Coinbase International has a strict specification for client order IDs.
Nautilus can meet the spec by using UUID4 values for client order IDs.
To comply, set the `use_uuid_client_order_ids=True` config option in your strategy configuration (otherwise, order submission will trigger an API error).

See the Coinbase International [Create order](https://docs.cdp.coinbase.com/intx/reference/createorder) REST API documentation for further details.
:::

### Data client configuration options

| Option            | Default        | Description |
|-------------------|----------------|-------------|
| `venue`           | `COINBASE_INTX`| Venue identifier registered for the data client. |
| `api_key`         | `None`         | API key; loaded from `COINBASE_INTX_API_KEY` (or testnet variant) when omitted. |
| `api_secret`      | `None`         | API secret; loaded from `COINBASE_INTX_API_SECRET` (or testnet variant) when omitted. |
| `api_passphrase`  | `None`         | API passphrase; loaded from `COINBASE_INTX_API_PASSPHRASE` when omitted. |
| `base_url_http`   | `None`         | Override for the REST base URL. |
| `base_url_ws`     | `None`         | Override for the WebSocket base URL. |
| `http_timeout_secs` | `60`        | Default timeout (seconds) applied to REST calls. |

### Execution client configuration options

| Option             | Default        | Description |
|--------------------|----------------|-------------|
| `venue`            | `COINBASE_INTX`| Venue identifier registered for the execution client. |
| `api_key`          | `None`         | API key; loaded from `COINBASE_INTX_API_KEY` (or testnet variant) when omitted. |
| `api_secret`       | `None`         | API secret; loaded from `COINBASE_INTX_API_SECRET` (or testnet variant) when omitted. |
| `api_passphrase`   | `None`         | API passphrase; loaded from `COINBASE_INTX_API_PASSPHRASE` when omitted. |
| `portfolio_id`     | `None`         | Portfolio identifier to trade; required for order submission. |
| `base_url_http`    | `None`         | Override for the REST base URL. |
| `base_url_ws`      | `None`         | Override for the WebSocket base URL. |
| `http_timeout_secs`| `60`           | Default timeout (seconds) applied to REST calls. |

An example configuration could be:

```python
from nautilus_trader.adapters.coinbase_intx import COINBASE_INTX, CoinbaseIntxDataClientConfig, CoinbaseIntxExecClientConfig
from nautilus_trader.live.node import TradingNode

config = TradingNodeConfig(
    ...,  # Further config omitted
    data_clients={
        COINBASE_INTX: CoinbaseIntxDataClientConfig(
            instrument_provider=InstrumentProviderConfig(load_all=True),
        ),
    },
    exec_clients={
        COINBASE_INTX: CoinbaseIntxExecClientConfig(
            instrument_provider=InstrumentProviderConfig(load_all=True),
        ),
    },
)

strat_config = TOBQuoterConfig(
    use_uuid_client_order_ids=True,  # <-- Necessary for Coinbase Intx
    instrument_id=instrument_id,
    external_order_claims=[instrument_id],
    ...,  # Further config omitted
)
```

Then, create a `TradingNode` and add the client factories:

```python
from nautilus_trader.adapters.coinbase_intx import COINBASE_INTX, CoinbaseIntxLiveDataClientFactory, CoinbaseIntxLiveExecClientFactory
from nautilus_trader.live.node import TradingNode

# Instantiate the live trading node with a configuration
node = TradingNode(config=config)

# Register the client factories with the node
node.add_data_client_factory(COINBASE_INTX, CoinbaseIntxLiveDataClientFactory)
node.add_exec_client_factory(COINBASE_INTX, CoinbaseIntxLiveExecClientFactory)

# Finally build the node
node.build()
```

### API Credentials

Provide credentials to the clients using one of the following methods.

Either pass values for the following configuration options:

- `api_key`
- `api_secret`
- `api_passphrase`
- `portfolio_id`

Or, set the following environment variables:

- `COINBASE_INTX_API_KEY`
- `COINBASE_INTX_API_SECRET`
- `COINBASE_INTX_API_PASSPHRASE`
- `COINBASE_INTX_PORTFOLIO_ID`

:::tip
We recommend using environment variables to manage your credentials.
:::

When starting the trading node, you'll receive immediate confirmation of whether your
credentials are valid and have trading permissions.

## Implementation notes

- **Heartbeats**: The adapter maintains heartbeats on both the WebSocket and FIX connections to ensure reliable connectivity.
- **Rate Limits**: The REST API client is configured to limit requests to 100 per second, matching the Coinbase International REST allowance. See <https://docs.cdp.coinbase.com/intx/docs/rate-limits> for the official guidance.

:::warning
Coinbase International returns HTTP 429 when you exceed the 100 requests/sec allowance and can throttle the API key for several seconds, so keep bursts below the documented ceiling.
:::

- **Graceful Shutdown**: The adapter properly handles graceful shutdown, ensuring all pending messages are processed before disconnecting.
- **Thread Safety**: All adapter components are thread-safe, allowing them to be used from multiple threads concurrently.
- **Execution Model**: The adapter can be configured with a single Coinbase International portfolio per execution client. For trading multiple portfolios, you can create multiple execution clients.

</document_content>
</document>
<document index="1483">
<source>docs/integrations/dydx.md</source>
<document_content>
# dYdX

dYdX is one of the largest decentralized cryptocurrency exchanges in terms of daily trading volume
for crypto derivative products. dYdX runs on smart contracts on the Ethereum blockchain, and allows
users to trade with no intermediaries. This integration supports live market data ingestion and order
execution with dYdX v4, which is the first version of the protocol to be fully decentralized with no
central components.

## Installation

To install NautilusTrader with dYdX support:

```bash
uv pip install "nautilus_trader[dydx]"
```

To build from source with all extras (including dYdX):

```bash
uv sync --all-extras
```

## Examples

You can find live example scripts [here](https://github.com/nautechsystems/nautilus_trader/tree/develop/examples/live/dydx/).

## Overview

This guide assumes a trader is setting up for both live market data feeds, and trade execution.
The dYdX adapter includes multiple components, which can be used together or separately depending
on the use case.

- `DYDXHttpClient`: Low-level HTTP API connectivity.
- `DYDXWebSocketClient`: Low-level WebSocket API connectivity.
- `DYDXAccountGRPCAPI`: Low-level gRPC API connectivity for account updates.
- `DYDXInstrumentProvider`: Instrument parsing and loading functionality.
- `DYDXDataClient`: A market data feed manager.
- `DYDXExecutionClient`: An account management and trade execution gateway.
- `DYDXLiveDataClientFactory`: Factory for dYdX data clients (used by the trading node builder).
- `DYDXLiveExecClientFactory`: Factory for dYdX execution clients (used by the trading node builder).

:::note
Most users will simply define a configuration for a live trading node (as below),
and won't need to necessarily work with these lower level components directly.
:::

:::warning First-time account activation
A dYdX v4 trading account (sub-account 0) is created **only after** the wallet’s first deposit or trade.
Until then, every gRPC/Indexer query returns `NOT_FOUND`, so `DYDXExecutionClient.connect()` fails.

**Action →** Before starting a live `TradingNode`, send any positive amount of USDC (≥ 1 wei) or other supported collateral from the same wallet **on the same network** (mainnet / testnet).
Once the transaction has finalised (a few blocks) restart the node; the client will connect cleanly.
:::

## Troubleshooting

### `StatusCode.NOT_FOUND` — account … /0 not found

**Cause** *The wallet/sub-account has never been funded and therefore does not yet exist on-chain.*

**Fix**

1. Deposit any positive amount of USDC to sub-account 0 on the correct network.
2. Wait for finality (≈ 30 s on mainnet, longer on testnet).
3. Restart the `TradingNode`; the connection should now succeed.

:::tip
In unattended deployments, wrap the `connect()` call in an exponential-backoff loop so the client retries until the deposit appears.
:::

## Symbology

Only perpetual contracts are available on dYdX. To be consistent with other adapters and to be
futureproof in case other products become available on dYdX, NautilusTrader appends `-PERP` for all
available perpetual symbols. For example, the Bitcoin/USD-C perpetual futures contract is identified
as `BTC-USD-PERP`. The quote currency for all markets is USD-C. Therefore, dYdX abbreviates it to USD.

## Short-term and long-term orders

dYdX makes a distinction between short-term orders and long-term orders (or stateful orders).
Short-term orders are meant to be placed immediately and belongs in the same block the order was received.
These orders stay in-memory up to 20 blocks, with only their fill amount and expiry block height being committed to state.
Short-term orders are mainly intended for use by market makers with high throughput or for market orders.

By default, all orders are sent as short-term orders. To construct long-term orders, you can attach a tag to
an order like this:

```python
from nautilus_trader.adapters.dydx import DYDXOrderTags

order: LimitOrder = self.order_factory.limit(
    instrument_id=self.instrument_id,
    order_side=OrderSide.BUY,
    quantity=self.instrument.make_qty(self.trade_size),
    price=self.instrument.make_price(price),
    time_in_force=TimeInForce.GTD,
    expire_time=self.clock.utc_now() + pd.Timedelta(minutes=10),
    post_only=True,
    emulation_trigger=self.emulation_trigger,
    tags=[DYDXOrderTags(is_short_term_order=False).value],
)
```

To specify the number of blocks that an order is active:

```python
from nautilus_trader.adapters.dydx import DYDXOrderTags

order: LimitOrder = self.order_factory.limit(
    instrument_id=self.instrument_id,
    order_side=OrderSide.BUY,
    quantity=self.instrument.make_qty(self.trade_size),
    price=self.instrument.make_price(price),
    time_in_force=TimeInForce.GTD,
    expire_time=self.clock.utc_now() + pd.Timedelta(seconds=5),
    post_only=True,
    emulation_trigger=self.emulation_trigger,
    tags=[DYDXOrderTags(is_short_term_order=True, num_blocks_open=5).value],
)
```

## Market orders

Market orders require specifying a price to for price slippage protection and use hidden orders.
By setting a price for a market order, you can limit the potential price slippage. For example,
if you set the price of $100 for a market buy order, the order will only be executed if the market price
is at or below $100. If the market price is above $100, the order will not be executed.

Some exchanges, including dYdX, support hidden orders. A hidden order is an order that is not visible
to other market participants, but is still executable. By setting a price for a market order, you can
create a hidden order that will only be executed if the market price reaches the specified price.

If the market price is not specified, a default value of 0 is used.

To specify the price when creating a market order:

```python
order = self.order_factory.market(
    instrument_id=self.instrument_id,
    order_side=OrderSide.BUY,
    quantity=self.instrument.make_qty(self.trade_size),
    time_in_force=TimeInForce.IOC,
    tags=[DYDXOrderTags(is_short_term_order=True, market_order_price=Price.from_str("10_000")).value],
)
```

## Stop limit and stop market orders

Both stop limit and stop market conditional orders can be submitted. dYdX only supports long-term orders
for conditional orders.

## Orders capability

dYdX supports perpetual futures trading with a comprehensive set of order types and execution features.

### Order Types

| Order Type             | Perpetuals | Notes                                   |
|------------------------|------------|-----------------------------------------|
| `MARKET`               | ✓          | Requires price for slippage protection. Quote quantity not supported. |
| `LIMIT`                | ✓          |                                         |
| `STOP_MARKET`          | ✓          | Long-term orders only.                  |
| `STOP_LIMIT`           | ✓          | Long-term orders only.                  |
| `MARKET_IF_TOUCHED`    | -          | *Not supported*.                        |
| `LIMIT_IF_TOUCHED`     | -          | *Not supported*.                        |
| `TRAILING_STOP_MARKET` | -          | *Not supported*.                        |

### Execution Instructions

| Instruction   | Perpetuals | Notes                          |
|---------------|------------|--------------------------------|
| `post_only`   | ✓          | Supported on all order types.  |
| `reduce_only` | ✓          | Supported on all order types.  |

### Time in force options

| Time in force| Perpetuals | Notes                |
|--------------|------------|----------------------|
| `GTC`        | ✓          | Good Till Canceled.  |
| `GTD`        | ✓          | Good Till Date.      |
| `FOK`        | ✓          | Fill or Kill.        |
| `IOC`        | ✓          | Immediate or Cancel. |

### Advanced Order Features

| Feature            | Perpetuals | Notes                                          |
|--------------------|------------|------------------------------------------------|
| Order Modification | ✓          | Short-term orders only; cancel-replace method. |
| Bracket/OCO Orders | -          | *Not supported*.                               |
| Iceberg Orders     | -          | *Not supported*.                               |

### Batch operations

| Operation          | Perpetuals | Notes                                          |
|--------------------|------------|------------------------------------------------|
| Batch Submit       | -          | *Not supported*.                               |
| Batch Modify       | -          | *Not supported*.                               |
| Batch Cancel       | -          | *Not supported*.                               |

### Position management

| Feature              | Perpetuals | Notes                                          |
|--------------------|------------|------------------------------------------------|
| Query positions     | ✓          | Real-time position updates.                    |
| Position mode       | -          | Net position mode only.                       |
| Leverage control    | ✓          | Per-market leverage settings.                 |
| Margin mode         | -          | Cross margin only.                             |

### Order querying

| Feature              | Perpetuals | Notes                                          |
|----------------------|------------|------------------------------------------------|
| Query open orders    | ✓          | List all active orders.                        |
| Query order history  | ✓          | Historical order data.                         |
| Order status updates | ✓          | Real-time order state changes.                |
| Trade history        | ✓          | Execution and fill reports.                   |

### Contingent orders

| Feature             | Perpetuals | Notes                                          |
|---------------------|------------|------------------------------------------------|
| Order lists         | -          | *Not supported*.                               |
| OCO orders          | -          | *Not supported*.                               |
| Bracket orders      | -          | *Not supported*.                               |
| Conditional orders  | ✓          | Stop market and stop limit orders.           |

### Order classification

dYdX classifies orders as either **short-term** or **long-term** orders:

- **Short-term orders**: Default for all orders; intended for high-frequency trading and market orders.
- **Long-term orders**: Required for conditional orders; use `DYDXOrderTags` to specify.

## Configuration

The product types for each client must be specified in the configurations.

### Data client configuration options

| Option                           | Default | Description |
|----------------------------------|---------|-------------|
| `wallet_address`                 | `None`  | Wallet address; loaded from `DYDX_WALLET_ADDRESS`/`DYDX_TESTNET_WALLET_ADDRESS` when omitted. |
| `is_testnet`                     | `False` | Connect to the dYdX testnet when `True`. |
| `update_instruments_interval_mins` | `60`  | Interval (minutes) between instrument catalogue refreshes. |
| `max_retries`                    | `None`  | Maximum retry attempts for REST/WebSocket recovery. |
| `retry_delay_initial_ms`         | `None`  | Initial delay (milliseconds) between retries. |
| `retry_delay_max_ms`             | `None`  | Maximum delay (milliseconds) between retries. |
| `proxy_url`                      | `None`  | Optional proxy URL for HTTP requests. |

### Execution client configuration options

| Option                   | Default | Description |
|--------------------------|---------|-------------|
| `wallet_address`         | `None`  | Wallet address; loaded from `DYDX_WALLET_ADDRESS`/`DYDX_TESTNET_WALLET_ADDRESS` when omitted. |
| `subaccount`             | `0`     | Subaccount number (dYdX provisions subaccount `0` by default). |
| `mnemonic`               | `None`  | Mnemonic used to derive the signing key; loaded from environment when omitted. |
| `base_url_http`          | `None`  | Override for the REST base URL. |
| `base_url_ws`            | `None`  | Override for the WebSocket base URL. |
| `is_testnet`             | `False` | Connect to the dYdX testnet when `True`. |
| `max_retries`            | `None`  | Maximum retry attempts for order submission/cancel/modify calls. |
| `retry_delay_initial_ms` | `None`  | Initial delay (milliseconds) between retries. |
| `retry_delay_max_ms`     | `None`  | Maximum delay (milliseconds) between retries. |
| `proxy_url`              | `None`  | Optional proxy URL for HTTP requests. |

### Execution clients

The account type must be a margin account to trade the perpetual futures contracts.

The most common use case is to configure a live `TradingNode` to include dYdX
data and execution clients. To achieve this, add a `DYDX` section to your client
configuration(s):

```python
from nautilus_trader.live.node import TradingNode

config = TradingNodeConfig(
    ...,  # Omitted
    data_clients={
        "DYDX": {
            "wallet_address": "YOUR_DYDX_WALLET_ADDRESS",
            "is_testnet": False,
        },
    },
    exec_clients={
        "DYDX": {
            "wallet_address": "YOUR_DYDX_WALLET_ADDRESS",
            "subaccount": "YOUR_DYDX_SUBACCOUNT_NUMBER"
            "mnemonic": "YOUR_MNEMONIC",
            "is_testnet": False,
        },
    },
)
```

Then, create a `TradingNode` and add the client factories:

```python
from nautilus_trader.adapters.dydx import DYDXLiveDataClientFactory
from nautilus_trader.adapters.dydx import DYDXLiveExecClientFactory
from nautilus_trader.live.node import TradingNode

# Instantiate the live trading node with a configuration
node = TradingNode(config=config)

# Register the client factories with the node
node.add_data_client_factory("DYDX", DYDXLiveDataClientFactory)
node.add_exec_client_factory("DYDX", DYDXLiveExecClientFactory)

# Finally build the node
node.build()
```

### API credentials

There are two options for supplying your credentials to the dYdX clients.
Either pass the corresponding `wallet_address` and `mnemonic` values to the configuration objects, or
set the following environment variables:

For dYdX live clients, you can set:

- `DYDX_WALLET_ADDRESS`
- `DYDX_MNEMONIC`

For dYdX testnet clients, you can set:

- `DYDX_TESTNET_WALLET_ADDRESS`
- `DYDX_TESTNET_MNEMONIC`

:::tip
We recommend using environment variables to manage your credentials.
:::

The data client is using the wallet address to determine the trading fees. The trading fees are used during back tests only.

### Testnets

It's also possible to configure one or both clients to connect to the dYdX testnet.
Simply set the `is_testnet` option to `True` (this is `False` by default):

```python
config = TradingNodeConfig(
    ...,  # Omitted
    data_clients={
        "DYDX": {
            "wallet_address": "YOUR_DYDX_WALLET_ADDRESS",
            "is_testnet": True,
        },
    },
    exec_clients={
        "DYDX": {
            "wallet_address": "YOUR_DYDX_WALLET_ADDRESS",
            "subaccount": "YOUR_DYDX_SUBACCOUNT_NUMBER"
            "mnemonic": "YOUR_MNEMONIC",
            "is_testnet": True,
        },
    },
)
```

### Parser warnings

Some dYdX instruments are unable to be parsed into Nautilus objects if they
contain enormous field values beyond what can be handled by the platform.
In these cases, a *warn and continue* approach is taken (the instrument will not be available).

## Order books

Order books can be maintained at full depth or top-of-book quotes depending on the
subscription. The venue does not provide quotes, but the adapter subscribes to order
book deltas and sends new quotes to the `DataEngine` when there is a top-of-book price or size change.

:::info
For additional features or to contribute to the dYdX adapter, please see our
[contributing guide](https://github.com/nautechsystems/nautilus_trader/blob/develop/CONTRIBUTING.md).
:::

</document_content>
</document>
<document index="1484">
<source>docs/integrations/hyperliquid.md</source>
<document_content>
# Hyperliquid

Hyperliquid is a decentralized perpetual futures exchange built on the Arbitrum blockchain,
offering a fully on-chain order book and matching engine. This integration supports live market
data feeds and order execution on Hyperliquid.

:::warning
The Hyperliquid integration is under active development. Some features may be incomplete.
:::

## Overview

This adapter is implemented in Rust with Python bindings. It provides direct integration
with Hyperliquid's REST and WebSocket APIs without requiring external client libraries.

The Hyperliquid adapter includes multiple components:

- `HyperliquidHttpClient`: Low-level HTTP API connectivity.
- `HyperliquidWebSocketClient`: Low-level WebSocket API connectivity.
- `HyperliquidInstrumentProvider`: Instrument parsing and loading functionality.
- `HyperliquidDataClient`: Market data feed manager.
- `HyperliquidExecutionClient`: Account management and trade execution gateway.
- `HyperliquidLiveDataClientFactory`: Factory for Hyperliquid data clients (used by the trading node builder).
- `HyperliquidLiveExecClientFactory`: Factory for Hyperliquid execution clients (used by the trading node builder).

:::note
Most users will define a configuration for a live trading node (as shown below)
and won't need to work directly with these lower-level components.
:::

## Examples

You can find live example scripts [here](https://github.com/nautechsystems/nautilus_trader/tree/develop/examples/live/hyperliquid/).

## Testnet setup

Hyperliquid provides a testnet environment for testing strategies without risking real funds.

### Getting testnet credentials

1. Visit the [Hyperliquid testnet portal](https://app.hyperliquid-testnet.xyz/)
2. Connect your wallet (MetaMask or WalletConnect)
3. The testnet will automatically create an account for your wallet address
4. Request testnet funds from the faucet (if available)

### Exporting your private key

To use your testnet account with NautilusTrader, you need to export your wallet's private key:

**MetaMask:**

1. Click the three dots menu next to your account
2. Select "Account details"
3. Click "Show private key"
4. Enter your password and copy the private key

:::warning
**Never share your private keys**
Store private keys securely using environment variables, never commit them to version control.
:::

### Setting environment variables

Set your testnet credentials as environment variables:

```bash
export HYPERLIQUID_TESTNET_PK="your_private_key_here"
# Optional: for vault trading
export HYPERLIQUID_TESTNET_VAULT="vault_address_here"
```

The adapter will automatically load these when `testnet=True` in the configuration.

## Product support

Hyperliquid currently supports perpetual futures contracts.

| Product Type        | Data Feed | Trading | Notes                           |
|---------------------|-----------|---------|----------------------------------|
| Perpetual Futures   | ✓         | ✓       | Both PERP and SPOT instruments. |
| Spot                | ✓         | ✓       | Native spot markets.             |

:::note
All instruments on Hyperliquid are settled in USDC.
:::

## Symbology

Hyperliquid uses a specific symbol format for instruments:

### Perpetual futures

Format: `{Base}-USD-PERP`

Examples:

- `BTC-USD-PERP` - Bitcoin perpetual futures
- `ETH-USD-PERP` - Ethereum perpetual futures
- `SOL-USD-PERP` - Solana perpetual futures

To subscribe in your strategy:

```python
InstrumentId.from_str("BTC-USD-PERP.HYPERLIQUID")
InstrumentId.from_str("ETH-USD-PERP.HYPERLIQUID")
```

### Spot markets

Format: `{Base}-{Quote}-SPOT`

Examples:

- `PURR-USDC-SPOT` - PURR/USDC spot pair
- `HYPE-USDC-SPOT` - HYPE/USDC spot pair

To subscribe in your strategy:

```python
InstrumentId.from_str("PURR-USDC-SPOT.HYPERLIQUID")
```

:::note
Spot instruments may include vault tokens (prefixed with `vntls:`). These are automatically
handled by the instrument provider.
:::

## Orders capability

Hyperliquid supports a comprehensive set of order types and execution options.

### Order types

| Order Type             | Perpetuals | Spot | Notes                                  |
|------------------------|------------|------|----------------------------------------|
| `MARKET`               | ✓          | ✓    | Executed as IOC limit order.           |
| `LIMIT`                | ✓          | ✓    |                                        |
| `STOP_MARKET`          | ✓          | ✓    | Stop loss orders.                      |
| `STOP_LIMIT`           | ✓          | ✓    | Stop loss with limit execution.        |
| `MARKET_IF_TOUCHED`    | ✓          | ✓    | Take profit at market.                 |
| `LIMIT_IF_TOUCHED`     | ✓          | ✓    | Take profit with limit execution.      |

:::info
Conditional orders (stop and if-touched) are implemented using Hyperliquid's native trigger
order functionality with automatic TP/SL mode detection.
:::

### Time in force

| Time in force | Perpetuals | Spot | Notes                        |
|---------------|------------|------|------------------------------|
| `GTC`         | ✓          | ✓    | Good Till Canceled.          |
| `IOC`         | ✓          | ✓    | Immediate or Cancel.         |
| `FOK`         | -          | -    | *Not supported*.             |
| `GTD`         | -          | -    | *Not supported*.             |

### Execution instructions

| Instruction   | Perpetuals | Spot | Notes                              |
|---------------|------------|------|------------------------------------|
| `post_only`   | ✓          | ✓    | Equivalent to ALO time in force.   |
| `reduce_only` | ✓          | ✓    | Close-only orders.                 |

### Order operations

| Operation        | Perpetuals | Spot | Notes                                  |
|------------------|------------|------|----------------------------------------|
| Submit order     | ✓          | ✓    | Single order submission.               |
| Submit order list| ✓          | ✓    | Batch order submission.                |
| Modify order     | ✓          | ✓    | Price and quantity modification.       |
| Cancel order     | ✓          | ✓    | Cancel by client order ID.             |
| Cancel all orders| ✓          | ✓    | Cancel all orders for instrument/side. |
| Batch cancel     | ✓          | ✓    | Cancel multiple orders in one request. |

## Configuration

### Data client configuration options

| Option                   | Default | Description                                      |
|--------------------------|---------|--------------------------------------------------|
| `base_url_http`          | `None`  | Override for the REST base URL.                  |
| `base_url_ws`            | `None`  | Override for the WebSocket base URL.             |
| `testnet`                | `False` | Connect to the Hyperliquid testnet when `True`.  |
| `http_timeout_secs`      | `10`    | Timeout (seconds) applied to REST calls.         |
| `http_proxy_url`         | `None`  | Optional HTTP proxy URL.                         |
| `ws_proxy_url`           | `None`  | Optional WebSocket proxy URL.                    |

### Execution client configuration options

| Option                   | Default | Description                                                |
|--------------------------|---------|-------------------------------------------------------------|
| `private_key`            | `None`  | EVM private key; loaded from `HYPERLIQUID_PK` or `HYPERLIQUID_TESTNET_PK` when omitted. |
| `vault_address`          | `None`  | Vault address for delegated trading; loaded from `HYPERLIQUID_VAULT` or `HYPERLIQUID_TESTNET_VAULT` when omitted. |
| `base_url_http`          | `None`  | Override for the REST base URL.                             |
| `base_url_ws`            | `None`  | Override for the WebSocket base URL.                        |
| `testnet`                | `False` | Connect to the Hyperliquid testnet when `True`.             |
| `max_retries`            | `None`  | Maximum retry attempts for order submission/cancel/modify.  |
| `retry_delay_initial_ms` | `None`  | Initial delay (milliseconds) between retries.               |
| `retry_delay_max_ms`     | `None`  | Maximum delay (milliseconds) between retries.               |
| `http_timeout_secs`      | `10`    | Timeout (seconds) applied to REST calls.                    |
| `http_proxy_url`         | `None`  | Optional HTTP proxy URL.                                    |
| `ws_proxy_url`           | `None`  | Optional WebSocket proxy URL.                               |

### Configuration example

```python
from nautilus_trader.adapters.hyperliquid import HYPERLIQUID
from nautilus_trader.adapters.hyperliquid import HyperliquidDataClientConfig
from nautilus_trader.adapters.hyperliquid import HyperliquidExecClientConfig
from nautilus_trader.config import InstrumentProviderConfig
from nautilus_trader.config import TradingNodeConfig

config = TradingNodeConfig(
    data_clients={
        HYPERLIQUID: HyperliquidDataClientConfig(
            instrument_provider=InstrumentProviderConfig(load_all=True),
            testnet=True,  # Use testnet
        ),
    },
    exec_clients={
        HYPERLIQUID: HyperliquidExecClientConfig(
            private_key=None,  # Loads from HYPERLIQUID_TESTNET_PK env var
            vault_address=None,  # Optional: loads from HYPERLIQUID_TESTNET_VAULT
            instrument_provider=InstrumentProviderConfig(load_all=True),
            testnet=True,  # Use testnet
        ),
    },
)
```

:::note
When `testnet=True`, the adapter automatically uses testnet environment variables
(`HYPERLIQUID_TESTNET_PK` and `HYPERLIQUID_TESTNET_VAULT`) instead of mainnet variables.
:::

</document_content>
</document>
<document index="1485">
<source>docs/integrations/index.md</source>
<document_content>
# Integrations

NautilusTrader uses modular *adapters* to connect to trading venues and data providers, translating raw APIs into a unified interface and normalized domain model.

The following integrations are currently supported:

| Name                                                                         | ID                    | Type                    | Status                                                  | Docs                      |
| :--------------------------------------------------------------------------- | :-------------------- | :---------------------- | :------------------------------------------------------ | :------------------------ |
| [Betfair](https://betfair.com)                                               | `BETFAIR`             | Sports Betting Exchange | ![status](https://img.shields.io/badge/stable-green)    | [Guide](betfair.md)       |
| [Binance](https://binance.com)                                               | `BINANCE`             | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](binance.md)       |
| [BitMEX](https://www.bitmex.com)                                             | `BITMEX`              | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](bitmex.md)        |
| [Bybit](https://www.bybit.com)                                               | `BYBIT`               | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](bybit.md)         |
| [Coinbase International](https://www.coinbase.com/en/international-exchange) | `COINBASE_INTX`       | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](coinbase_intx.md) |
| [Databento](https://databento.com)                                           | `DATABENTO`           | Data Provider           | ![status](https://img.shields.io/badge/stable-green)    | [Guide](databento.md)     |
| [dYdX](https://dydx.exchange/)                                               | `DYDX`                | Crypto Exchange (DEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](dydx.md)          |
| [Hyperliquid](https://hyperliquid.xyz)                                       | `HYPERLIQUID`         | Crypto Exchange (DEX)   | ![status](https://img.shields.io/badge/building-orange) | [Guide](hyperliquid.md)   |
| [Interactive Brokers](https://www.interactivebrokers.com)                    | `INTERACTIVE_BROKERS` | Brokerage (multi-venue) | ![status](https://img.shields.io/badge/stable-green)    | [Guide](ib.md)            |
| [Kraken](https://kraken.com)                                                 | `KRAKEN`              | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/building-orange) | [Guide](kraken.md)        |
| [OKX](https://okx.com)                                                       | `OKX`                 | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](okx.md)           |
| [Polymarket](https://polymarket.com)                                         | `POLYMARKET`          | Prediction Market (DEX) | ![status](https://img.shields.io/badge/stable-green)    | [Guide](polymarket.md)    |
| [Tardis](https://tardis.dev)                                                 | `TARDIS`              | Crypto Data Provider    | ![status](https://img.shields.io/badge/stable-green)    | [Guide](tardis.md)        |

- **ID**: The default client ID for the integrations adapter clients.
- **Type**: The type of integration (often the venue type).

## Status

- `building`: Under construction and likely not in a usable state.
- `beta`: Completed to a minimally working state and in a 'beta' testing phase.
- `stable`: Stabilized feature set and API, the integration has been tested by both developers and users to a reasonable level (some bugs may still remain).

## Implementation goals

The primary goal of NautilusTrader is to provide a unified trading system for
use with a variety of integrations. To support the widest range of trading
strategies, priority will be given to *standard* functionality:

- Requesting historical market data.
- Streaming live market data.
- Reconciling execution state.
- Submitting standard order types with standard execution instructions.
- Modifying existing orders (if possible on an exchange).
- Canceling orders.

The implementation of each integration aims to meet the following criteria:

- Low-level client components should match the exchange API as closely as possible.
- The full range of an exchange's functionality (where applicable to NautilusTrader) should *eventually* be supported.
- Exchange specific data types will be added to support the functionality and return types which are reasonably expected by a user.
- Actions unsupported by an exchange or NautilusTrader will be logged as a warning or error when invoked.

## API unification

All integrations must conform to NautilusTrader’s system API, requiring normalization and standardization:

- Symbols should use the venue’s native symbol format unless disambiguation is required (e.g., Binance Spot vs. Binance Futures).
- Timestamps must use UNIX epoch nanoseconds. If milliseconds are used, field/property names should explicitly end with `_ms`.

</document_content>
</document>
<document index="1486">
<source>docs/integrations/kraken.md</source>
<document_content>
# Kraken

Founded in 2011, Kraken is one of the most established cryptocurrency exchanges
globally and the largest exchange in Europe by euro trading volume. The platform
offers spot and derivatives trading across a wide range of digital assets. This
integration connects to Kraken Pro and supports live market data ingest for both
Kraken Spot and Kraken Derivatives markets.

:::warning
The Kraken integration is under active development.
:::

</document_content>
</document>
<document index="1491">
<source>docs/tutorials/index.md</source>
<document_content>
# Tutorials

The tutorials provide a guided learning experience with a series of comprehensive step-by-step walkthroughs.
Each tutorial targets specific features or workflows, enabling hands-on learning.
From basic tasks to more advanced operations, these tutorials cater to a wide range of skill levels.

:::info
Each tutorial is generated from a Jupyter notebook located in the docs [tutorials directory](https://github.com/nautechsystems/nautilus_trader/tree/develop/docs/tutorials). These notebooks serve as valuable learning aids and let you execute the code interactively.
:::

:::tip

- Make sure you are using the tutorial docs that match your NautilusTrader version:
- **Latest**: These docs are built from the HEAD of the `master` branch and work with the latest stable release. See <https://nautilustrader.io/docs/latest/tutorials/>.
- **Nightly**: These docs are built from the HEAD of the `nightly` branch and work with bleeding-edge and experimental features. See <https://nautilustrader.io/docs/nightly/tutorials/>.

:::

## Running in docker

Alternatively, a self-contained dockerized Jupyter notebook server is available for download, which requires no setup or
installation. This is the fastest way to get up and running to try out NautilusTrader. Note that deleting the container will also delete any data.

- To get started, install docker:
  - Go to [Docker installation guide](https://docs.docker.com/get-docker/) and follow the instructions.
- From a terminal, download the latest image:
  - `docker pull ghcr.io/nautechsystems/jupyterlab:nightly --platform linux/amd64`
- Run the docker container, exposing the Jupyter port:
  - `docker run -p 8888:8888 ghcr.io/nautechsystems/jupyterlab:nightly`
- When the container starts, a URL with an access token will be printed in the terminal. Copy that URL and open it in your browser, for example:
  - <http://localhost:8888>

:::info
NautilusTrader currently exceeds the rate limit for Jupyter notebook logging (stdout output),
therefore we set `log_level` to `ERROR` in the examples. Lowering this level to see
more logging will cause the notebook to hang during cell execution. We are currently
investigating a fix that involves either raising the configured rate limits for
Jupyter, or throttling the log flushing from Nautilus.

- <https://github.com/jupyterlab/jupyterlab/issues/12845>
- <https://github.com/deshaw/jupyterlab-limit-output>

:::

</document_content>
</document>
<document index="1494">
<source>examples/README.md</source>
<document_content>
# Examples

The following code examples are organized by system environment context:

- **Backtest**: Historical data with simulated venues.
- **Sandbox**: Real-time data with simulated venues.
- **Live**: Real-time data with live venues (paper trading or real accounts).
- **Other**: Various examples beyond strategies.

Scripts within each environment context directory are organized by integration.

Ensure that the `nautilus_trader` package is either compiled from source or installed via pip before
running the examples. See the [installation guide](https://nautilustrader.io/docs/latest/getting_started/installation)
for more information.

To execute an example script from the `examples` directory, use a command similar to the following:

```
python backtest/crypto_ema_cross_ethusdt_trade_ticks.py
```

</document_content>
</document>
<document index="1508">
<source>examples/backtest/example_02_use_clock_timer/README.md</source>
<document_content>
This is a simple example of how to use NautilusTrader's **Timer** feature in a strategy.

The strategy works by running action at regular time intervals while also handling market data events.
It shows how **timer events** and **market data** can work separately at the same time.

**What this strategy does:**

- Uses **NautilusTrader’s timer** to trigger events on schedule.
- Handles **market data** and **timer events** independently.

This helps you see how timers work alongside market data processing without interfering with each other.

</document_content>
</document>
<document index="1511">
<source>examples/backtest/example_03_bar_aggregation/README.md</source>
<document_content>
# Bar aggregation example

This example demonstrates how to use NautilusTrader's **bar aggregation** features to create higher timeframe bars
from lower timeframe data.

The strategy shows how to:

- Load 1-minute bar data from a CSV file.
- Create 5-minute bars from 1-minute data using internal aggregation.
- Handle both timeframes independently in the same strategy.

This helps you understand how bar aggregation works in NautilusTrader and how to handle multiple timeframes
in your strategies.

</document_content>
</document>
<document index="1514">
<source>examples/backtest/example_04_using_data_catalog/README.md</source>
<document_content>
# Nautilus Data Catalog Example

This example provides a basic introduction to using the data catalog within the NautilusTrader framework.
It demonstrates how to register, access, and manage market data sources, providing a foundation for building more
complex trading strategies. This serves as a starting point to understand the core concepts of data management within NautilusTrader.

</document_content>
</document>
<document index="1517">
<source>examples/backtest/example_05_using_portfolio/README.md</source>
<document_content>
# Portfolio Example

A simple strategy demonstrating how to use Portfolio in NautilusTrader.

The Portfolio is a central component that tracks the state of your trading account.
It connects directly to the broker to get real-time positions, balances, and P&L.

## Example Highlights

The strategy shows portfolio information at four key points:

1. **Initial State**: Before any trades are executed.
2. **Position Open**: When a new position is created.
3. **Mid-Trade**: Two minutes after position opening.
4. **Final State**: After all positions are closed (when strategy stops).

To simulate these specific portfolio states, the strategy fires bracket order (a combination of an entry order
with associated take-profit and stop-loss orders), allowing us to demonstrate the complete lifecycle of portfolio states.

## Additional info

Key differences between `Portfolio` and `Cache`:

`Portfolio`:

- Gets data directly from broker for maximum accuracy.
- Best for real-time position and risk management.
- Provides authoritative account state (margins, balances).
- Should be used for critical trading decisions.

`Cache`:

- Stores all trading data in system memory.
- Useful for quick access to historical data and market state.
- More efficient for frequent queries as it avoids broker round-trips.
- Updates automatically as new data arrives.
- Might have minimal delay compared to broker data.

## Additional Resources

For more information about Portfolio in NautilusTrader, see:

- Portfolio API documentation - search the codebase for `Portfolio` class.
- Portfolio concept guide - see the "Portfolio" section in the documentation for more details.

</document_content>
</document>
<document index="1520">
<source>examples/backtest/example_06_using_cache/README.md</source>
<document_content>
# Cache Usage Example

This example demonstrates how to use NautilusTrader's **Cache** system for storing and managing trading data and state.

**The strategy shows how to use Cache for:**

- Storing and retrieving **custom objects** for strategy state.
- Accessing **instrument information** and specifications.
- Managing **trading accounts** and their states.
- Tracking **orders** and **positions** in the system.

This helps you understand how to use Cache effectively in your trading strategies
for data management and state tracking.

</document_content>
</document>
<document index="1523">
<source>examples/backtest/example_07_using_indicators/README.md</source>
<document_content>
# Example: Simple use of technical indicators

This example demonstrates how to use technical indicators in a **NautilusTrader** strategy.

The example shows how to set up and use a simple Exponential Moving Average (EMA) indicator within a trading strategy,
demonstrating proper initialization, updating, and accessing latest / previous indicator values.

**What this example demonstrates:**

- Creating and configuring a technical indicator (EMA).
- Registering the indicator to receive bar data.
- Accessing indicator values in the strategy.
- Storing historical indicator values.
- Accessing latest / previous indicator values.

</document_content>
</document>
<document index="1526">
<source>examples/backtest/example_08_cascaded_indicator/README.md</source>
<document_content>
# Example: Using cascaded technical indicators

This example demonstrates how to use cascaded technical indicators in a **NautilusTrader** strategy.

The example shows how to set up and use two Exponential Moving Average (EMA) indicators in a cascaded manner,
where the second indicator (EMA-20) is calculated using values from the first indicator (EMA-10),
demonstrating proper initialization, updating, and accessing indicator values in a cascaded setup.

**What this example demonstrates:**

- Creating and configuring multiple technical indicators (EMAs).
- Setting up a cascaded indicator relationship.
- Registering the primary indicator to receive bar data.
- Manually updating the cascaded indicator.
- Storing and accessing historical values for both indicators.
- Proper handling of indicator initialization in a cascaded setup.

</document_content>
</document>
<document index="1529">
<source>examples/backtest/example_09_messaging_with_msgbus/README.md</source>
<document_content>
# Example: Self-Communication Using Message Bus

A practical demonstration of using NautilusTrader's message bus for self-communication within a strategy.
The example implements a "10th bar notification system" where the strategy:

1. Creates a custom event (using Python's dataclass) to represent the 10th bar occurrence.
2. Publishes this event to the message bus when the 10th bar arrives.
3. Subscribes to and handles these events within the same strategy.

**Key learning points**:

- Creating custom events with the message bus.
- Implementing publish/subscribe pattern for self-communication.
- Using events for condition-based notifications.
- Handling state changes through message bus events.

This pattern provides a clean, event-driven approach to handle conditional notifications
and state changes within your trading strategies.

**Note:**
While this example shows both publisher and subscriber roles within a single strategy, in practice these roles
can be distributed - any component can be a publisher and any other component can be a subscriber of events.

</document_content>
</document>
<document index="1532">
<source>examples/backtest/example_10_messaging_with_actor_data/README.md</source>
<document_content>
# Example - Messaging with Actor Data

This example demonstrates how to work with custom data classes
and the Actor's publish/subscribe mechanism in NautilusTrader.

## What You'll Learn

- How to create custom data classes (both serializable and non-serializable).
- How to publish and subscribe to custom data using Actor methods.
- How to handle custom data events in your strategy.

## Implementation Details

The strategy showcases two approaches to custom data classes:

- `Last10BarsStats`: A simple non-serializable data.
- `Last10BarsStatsSerializable`: A serializable data showing proper setup for data persistence and transfer between nodes.

</document_content>
</document>
<document index="1535">
<source>examples/backtest/example_11_messaging_with_actor_signals/README.md</source>
<document_content>
# Actor-Based Signal Messaging Example

This example demonstrates the simplest form of messaging in NautilusTrader using *actor-based signals*.
It shows how to implement lightweight notifications between components using *string-based signals*.

## What You'll Learn

- How to use signals for simple notifications (price extremes in this case).
- How to publish signals with single string values.
- How to subscribe to signals and handle them in `on_signal` callback.

## Implementation Highlights

- Uses `SimpleNamespace` for signal name constants.
- Shows both signal publishing and subscription.
- Demonstrates signal handling with pattern matching in `on_signal`.

</document_content>
</document>
<document index="1560">
<source>examples/live/bybit/README_options_data_collector.md</source>
<document_content>
# Bybit Options Data Collector

This script discovers all available options for a given underlying asset (e.g., BTC) on Bybit,
subscribes to their quote and orderbook data, and stores the data in parquet files.

## Features

- **Automatic Discovery**: Connects to Bybit and discovers all available options for the
  specified underlying asset.
- **Complete Data Collection**: Fetches both quote ticks and orderbook deltas for all discovered options.
- **Spot Data**: Also collects data for the underlying spot instrument.
- **Organized Storage**: Saves data in a hierarchical directory structure with separate files
  for each instrument.
- **Real-time Processing**: Processes and stores data in real-time with configurable batch sizes.
- **Comprehensive Logging**: Provides detailed logging of discovered instruments and data
  collection statistics.

## Requirements

- Python 3.8+
- NautilusTrader
- Bybit API credentials (for live data access)

## Setup

1. Set your Bybit API credentials as environment variables:

```bash
export BYBIT_API_KEY="your_api_key"
export BYBIT_API_SECRET="your_api_secret"
```

2. Run the script:

```bash
python examples/live/bybit/bybit_options_data_collector.py
```

## Configuration

The script can be configured by modifying the `BybitOptionsDataCollectorConfig` in the script:

```python
strategy_config = BybitOptionsDataCollectorConfig(
    underlying_asset="BTC",  # The underlying asset to collect options for
    spot_instrument_id=InstrumentId.from_str("BTCUSDT-SPOT.BYBIT"),
    depth=25,  # Orderbook depth (25 or 100 levels)
    batch_size=1000,  # Records to batch before writing to parquet
    data_dir="data",  # Directory to store parquet files
    log_interval=60.0,  # Log and save data every N seconds
)
```

## Data structure

The script creates the following directory structure:

```
data/
└── BTC/
    └── USDT/
        ├── spot/
        │   ├── BTCUSDT-SPOT_BYBIT_quote.parquet
        │   └── BTCUSDT-SPOT_BYBIT_orderbook.parquet
        └── options/
            ├── BTC-15SEP26-45000-C-USDT-OPTION_BYBIT_quote.parquet
            ├── BTC-15SEP26-45000-C-USDT-OPTION_BYBIT_orderbook.parquet
            ├── BTC-15SEP26-45000-P-USDT-OPTION_BYBIT_quote.parquet
            ├── BTC-15SEP26-45000-P-USDT-OPTION_BYBIT_orderbook.parquet
            └── ... (one file pair per option)
```

## Data formats

### Quote ticks data

Each quote tick record contains:

- `timestamp`: When the data was received
- `instrument_id`: The instrument identifier
- `bid_price`: Best bid price
- `ask_price`: Best ask price
- `bid_size`: Best bid size
- `ask_size`: Best ask size
- `ts_event`: Event timestamp
- `ts_init`: Initialization timestamp

### Orderbook deltas data

Each orderbook delta record contains:

- `timestamp`: When the data was received
- `instrument_id`: The instrument identifier
- `sequence`: Sequence number
- `delta_count`: Number of deltas in this update
- `best_bid`: Best bid price after applying deltas
- `best_ask`: Best ask price after applying deltas
- `bid_size`: Best bid size after applying deltas
- `ask_size`: Best ask size after applying deltas

## Usage examples

### Basic usage

```bash
# Collect data for all BTC options
python examples/live/bybit/bybit_options_data_collector.py
```

### Custom configuration

You can modify the script to:

- Change the underlying asset (e.g., ETH instead of BTC).
- Adjust the orderbook depth.
- Change the data storage directory.
- Modify the logging interval.

## Monitoring

The script provides real-time monitoring through logs:

- Discovery phase: Shows all found options grouped by expiry.
- Data collection: Shows statistics every 60 seconds (configurable).
- File operations: Logs when data is written to parquet files.

## Output example

```
2025-07-31T14:47:55.003958000Z [INFO] OPTIONS-COLLECTOR-001.BybitOptionsDataCollector: Discovering all available BTC options...
2025-07-31T14:47:55.004032000Z [INFO] OPTIONS-COLLECTOR-001.BybitOptionsDataCollector: Found 150 BTC options instruments
2025-07-31T14:47:55.004097000Z [INFO] OPTIONS-COLLECTOR-001.BybitOptionsDataCollector: BTC options grouped by expiry (8 expiry dates):
2025-07-31T14:47:55.004159000Z [INFO] OPTIONS-COLLECTOR-001.BybitOptionsDataCollector:   15SEP26: 25 options
2025-07-31T14:47:55.004247000Z [INFO] OPTIONS-COLLECTOR-001.BybitOptionsDataCollector:   15OCT26: 25 options
2025-07-31T14:47:55.004300000Z [INFO] OPTIONS-COLLECTOR-001.BybitOptionsDataCollector:   15NOV26: 25 options
...
2025-07-31T14:47:55.004357000Z [INFO] OPTIONS-COLLECTOR-001.BybitOptionsDataCollector: Total BTC options to monitor: 150
2025-07-31T14:47:55.004413000Z [INFO] OPTIONS-COLLECTOR-001.BybitOptionsDataCollector: === 60.0 SECOND UPDATE ===
2025-07-31T14:47:55.004470000Z [INFO] OPTIONS-COLLECTOR-001.BybitOptionsDataCollector: BTC-15SEP26-45000-C-USDT-OPTION.BYBIT: 150 quotes, 41 deltas
2025-07-31T14:47:55.004503000Z [INFO] OPTIONS-COLLECTOR-001.BybitOptionsDataCollector: BTC-15SEP26-45000-P-USDT-OPTION.BYBIT: 148 quotes, 137 deltas
...
2025-07-31T14:47:55.004515000Z [INFO] OPTIONS-COLLECTOR-001.BybitOptionsDataCollector: BTCUSDT-SPOT.BYBIT: 1076 quotes, 523 deltas
2025-07-31T14:47:55.006441000Z [INFO] OPTIONS-COLLECTOR-001.BybitOptionsDataCollector: TOTAL: 15000 quotes, 8000 deltas
2025-07-31T14:47:55.006517000Z [INFO] OPTIONS-COLLECTOR-001.BybitOptionsDataCollector: OPTIONS: 13924 quotes, 7477 deltas
2025-07-31T14:47:55.006522000Z [INFO] OPTIONS-COLLECTOR-001.BybitOptionsDataCollector: SPOT: 1076 quotes, 523 deltas
```

## Notes

- The script will automatically discover and subscribe to all available options for the
  specified underlying asset.
- Data is stored in parquet format for efficient storage and querying.
- The script handles connection issues and will attempt to reconnect.
- All data is timestamped and can be used for backtesting or analysis.
- The script can be stopped with Ctrl+C and will save any remaining data before exiting.

## Troubleshooting

1. **No options found**: Check that the underlying asset is correct and that Bybit has options
   available for that asset.
2. **Connection issues**: Verify your API credentials and internet connection.
3. **Memory issues**: Reduce the batch_size if collecting data for many options.
4. **Disk space**: Monitor disk usage as the script can generate large amounts of data.

</document_content>
</document>
<document index="1593">
<source>examples/other/minimal_reproducible_example/README.md</source>
<document_content>
# Minimal Reproducible Example

A bare-minimum template for reproducing and reporting issues with NautilusTrader.

## Why This Template?

- **Self-contained**: Includes artificial data generation - no need to attach market data files
- **Minimal**: Contains only essential components to demonstrate an issue
- **Simple and easy to modify**: Well-structured code that serves as a starting point for testing variations

## Using This Template

1. Copy these files
2. Modify the code to demonstrate your issue
3. Submit the modified version with your bug report

The artificial data generation makes it easy to share reproductions without needing to attach sensitive
or proprietary trading data.

</document_content>
</document>
<document index="1596">
<source>examples/other/state_machine/README.md</source>
<document_content>
# Finite State Machine Demo

A simple demonstration of using the Finite State Machine (FSM). This example shows how to create and manage
application states using FSM pattern already implemented in NautilusTrader.

</document_content>
</document>
<document index="2218">
<source>python/README.md</source>
<document_content>
# NautilusTrader v2

Welcome to the next generation of NautilusTrader!

> [!WARNING]
>
> **Under active development and not yet considered usable.**

This directory contains the pure Python package for `nautilus_trader` v2, which is built entirely
with PyO3 bindings.

This approach removes the legacy Cython layer, providing a cleaner architecture, direct integration
with the Rust core, and a more streamlined development experience.

**To reduce confusion we are following some simple rules:**

- The `python/` directory is self contained, everything Python related for v2 will be under here.
- This directory will remain when we transition completely away from v1 (the top level `nautilus_trader/` will be removed).
- Nothing outside of this directory should refer to anything within this directory for now.

## Project structure

The v2 package is structured to provide a clean separation between the public Python API and the internal compiled core.
This enables first-class IDE/editor support through type stubs and allows for a mix of pure Python and high-performance Rust modules.

```
python/
├── README.md                   # This file
├── generate_stubs.py           # Automatic generation of Python type stubs
├── pyproject.toml              # Maturin-based build configuration for the v2 package
├── uv.lock                     # UV lock file for the v2 package
└── nautilus_trader/
    ├── __init__.py             # Main package entry point, re-exports from _libnautilus
    ├── _libnautilus.so         # The *single* compiled Rust extension (created by the build)
    ├── core/
    │   ├── __init__.py         # Re-exports from `_libnautilus.core`
    │   └── __init__.pyi        # Type stubs for the core module (WIP)
    ├── model/
    │   ├── __init__.py         # Re-exports from `_libnautilus.model`
    │   └── __init__.pyi        # Type stubs for the model module (WIP)
    └── ...                     # Other submodules follow the same pattern
```

## Development setup

All commands should be run from within this `python/` directory.

### Prerequisites

- Rust toolchain (via `rustup`).
- Python 3.12-3.14
- A virtual environment activated at the project root (e.g., `.venv`).
- `patchelf` (Linux only) - required for setting rpath on the compiled extension. Install with `uv pip install patchelf`.

### Quick start

To set up your development environment, run the following command. It will compile the Rust extension, install it in "editable" mode, and install all necessary development and test dependencies.

```bash
uv run --active maturin develop --extras dev,test
```

This is the only command you need to get started. If you make changes to the Rust code, simply run it again to recompile.

## How it works

The `nautilus_trader` Python package acts as a "facade" over the compiled Rust core.

1. **The build**: `maturin develop` compiles all the Rust code into a single native library, `nautilus_trader/_libnautilus.so`.
2. **The facade**: The `nautilus_trader/__init__.py` file imports all the functionality from the `_libnautilus.so` file.
3. **The submodules**: Each subdirectory (e.g., `nautilus_trader/model/`) uses its `__init__.py` to re-export the relevant components from `_libnautilus`, creating a clean, organized public API.
4. **Type hints**: The `.pyi` stub files provide full type information to your IDE and tools like `mypy`, giving you autocompletion and static analysis, even for the compiled Rust code.

## Usage

Once the package is installed, you can import and use it like any other Python library. The underlying Rust implementation is completely transparent.

```python
from nautilus_trader.core import UUID4

# Use the bindings directly
UUID4()
# ...
```

## Installation

### From source

To build and install from source, you need Rust and Python 3.12+ installed. You can use either uv or Poetry:

**Using uv:**

```bash
# Clone the repository
git clone https://github.com/nautechsystems/nautilus_trader.git
cd nautilus_trader/python

# Install dependencies and build
uv run --active maturin develop --extras dev,test
```

### Development wheels (pre-release)

While v2 is still under heavy development, every successful build from the `develop` or `nightly` branches publishes a wheel to our private package v2 index.

```bash
pip install --index-url https://packages.nautechsystems.io/v2/simple/ --pre nautilus-trader
```

| Platform         | Python  | Develop | Nightly |
| :--------------- | :------ | :------ | :------ |
| `Linux (x86_64)` | 3.12-14 | ✓       | ✓       |
| `macOS (ARM64)`  | 3.12-14 | ✓       | ✓       |

The `--pre` flag is required because wheels are tagged as development releases (e.g., `0.2.0.dev20250601`).

## Python type stubs

Type stubs (`.pyi` files) provide full type information for the compiled Rust extension, enabling IDE autocompletion and static type checking with tools like `mypy`.

Stubs are automatically generated using [`pyo3-stub-gen`](https://github.com/Jij-Inc/pyo3-stub-gen). To regenerate them after modifying Rust bindings:

```bash
python generate_stubs.py
```

> [!NOTE]
> Automatic stub generation is a work in progress and may not cover all exported types yet.

</document_content>
</document>
<document index="2219">
<source>python/examples/README.md</source>
<document_content>
# Examples

The examples in this directory are specific to `nautilus_trader` v2.

</document_content>
</document>
<document index="2276">
<source>scripts/README.md</source>
<document_content>
# Scripts directory

This directory contains assorted helper scripts used by NautilusTrader’s
developer tooling and CI pipeline. Only one of them (`curate-dataset.sh`)
needs a brief explanation because it is meant to be executed manually when
curating test-fixture datasets.

---

## `curate-dataset.sh` – package an external dataset for the test-data bucket

`curate-dataset.sh` automates the small but repetitive tasks required when we
bring a third-party file into the NautilusTrader *test-data* bucket:

- download the raw file from its original URL (with retries)
- create a versioned directory (`v1/<slug>/`)
- copy the file into that directory
- write a `LICENSE.txt` file holding the SPDX identifier or licence URL
- compute size and SHA-256 checksum and store them in `metadata.json`

The result is a self-contained directory ready to upload one-for-one to the
S3 bucket (or to commit into the repository if the data size is small).

### Usage

```bash
scripts/curate-dataset.sh <slug> <filename> <download-url> <licence>
```

- **`slug`** – sub-directory name (e.g. `fi2010_all`)
- **`filename`** – the basename you want inside the directory (e.g. `Fi2010.zip`)
- **`download-url`** – original public URL of the file
- **`licence`** – short ID or full URL (e.g. `CC-BY-SA-4.0`)

Example – curate the full FI-2010 limit-order-book dataset (all 10 trading
days) from a Dropbox mirror:

```bash
scripts/curate-dataset.sh fi2010_all Fi2010.zip \
  "https://www.dropbox.com/s/6ywf3td7zdrp1n5/Fi2010.zip?dl=1" \
  CC-BY-SA-4.0
```

After the script finishes you will have the following structure ready to
commit or upload:

```
v1/fi2010_all/
 ├── Fi2010.zip          # ≈230 MB, contains day_1 … day_10
 ├── LICENSE.txt         # CC-BY-SA-4.0
 └── metadata.json       # size, sha256, provenance
```

You can now reference `v1/fi2010_all/Fi2010.zip` from tests or example code,
and downstream tooling can verify the checksum.

### Notes

- The script uses `curl -L --fail --retry 3`, so transient network hiccups are
  handled automatically.
- Re-running the script with the same arguments simply overwrites the existing
  files – useful when the upstream file is updated and you want to bump the
  checksum.
- Only basic validation is performed; ensure that the licence you specify
  indeed permits redistribution.

---

For details on the other helper scripts, run them with `-h` or read the
inline comments; they are mostly invoked from CI and rarely need manual
execution.

</document_content>
</document>
<document index="2639">
<source>tests/mem_leak_tests/README.md</source>
<document_content>
# Performance tests

This subpackage provides a suite of performance tests, including scripts which can be run
to profile memory and thread resource usage.

Memory profiling is conducted using [memray](https://github.com/bloomberg/memray).
The package is not a development dependency because it doesn't currently support windows.

You can install the package via PyPI:

```bash
pip install memray
```

To profile using memray, first invoke the script using the memray CLI:

```bash
memray run --live-port 8100 --live-remote tests/mem_leak_tests/memray_backtest.py
```

Then from another shell, connect to the memray profiler dashboard:

```bash
memray live 8100
```

</document_content>
</document>
<document index="2735">
<source>tests/test_data/xcme/README.md</source>
<document_content>
# File: `6EH4.XCME_1min_bars_20240101_20240131.csv.gz`

- Instrument: 6E
- Expiration: H4 (March 2024)
- Exchange:   XCME (MIC code)
- Period      2024-01-01 --> 2024-01-31 (UTC timestamp, no contract rollover occurs in this period)
- Bar type:   1-minute bars

# Zipped format

We used zipped data, because they are 9x smaller than original CSV file and can be DIRECTLY read by [pandas](https://pandas.pydata.org/)
using code like this:

```python
import pandas as pd

df = pd.read_csv(
    "6EH4.XCME_1min_bars_20240101_20240131.csv.gz",  # update path as needed
    header=0,
    index_col=False,
)
```

</document_content>
</document></documents>